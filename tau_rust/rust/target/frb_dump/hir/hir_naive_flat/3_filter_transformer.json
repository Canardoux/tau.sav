{
  "items": [
    {
      "meta": {
        "namespace": "crate",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [prelude_import] use std :: prelude :: rust_2021 :: * ;"
    },
    {
      "meta": {
        "namespace": "crate",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [macro_use] extern crate std ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" {@category api}\"] # [doc = \" {@subCategory Information displays}\"] # [doc = \" My taylor is rich\"] use trace :: trace ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: cell :: Cell ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use log :: { info as i , trace as t , warn as w , error as e , debug as d , LevelFilter , } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: Once ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use simple_log :: * ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_logger :: logger :: log ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "const DEPTH : :: std :: thread :: LocalKey < Cell < usize > > = { # [inline] fn __init () -> Cell < usize > { Cell :: new (0) } # [inline] unsafe fn __getit (init : :: std :: option :: Option < & mut :: std :: option :: Option < Cell < usize > > >) -> :: std :: option :: Option < & 'static Cell < usize > > { # [thread_local] static __KEY : :: std :: thread :: local_impl :: Key < Cell < usize > > = :: std :: thread :: local_impl :: Key :: < Cell < usize > > :: new () ; unsafe { __KEY . get (move | | { if let :: std :: option :: Option :: Some (init) = init { if let :: std :: option :: Option :: Some (value) = init . take () { return value ; } if true { { :: core :: panicking :: panic_fmt (format_args ! (\"internal error: entered unreachable code: {0}\" , format_args ! (\"missing default value\"))) ; } ; } } __init () }) } } unsafe { :: std :: thread :: LocalKey :: new (__getit) } } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: frb_generated ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use flutter_logger :: LogEntry ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use log :: Level ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub fn trace_logger (sink : frb_generated :: StreamSink < flutter_logger :: LogEntry >) { flutter_logger :: init (sink , LevelFilter :: Trace) . unwrap () ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl flutter_logger :: logger :: LogSink for frb_generated :: StreamSink < flutter_logger :: LogEntry > { fn send (& self , entry : flutter_logger :: LogEntry) { self . add (entry) . unwrap () ; } }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [frb (mirror (LogEntry))] struct _LogEntry { pub time_millis : i64 , pub msg : String , pub log_level : log :: Level , pub lbl : String , }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [frb (mirror (Level))] enum _LogLevel { Error , Warn , Info , Debug , Trace , }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "const I_TO_FILTER : [LevelFilter ; 11] = [LevelFilter :: Trace , LevelFilter :: Trace , LevelFilter :: Trace , LevelFilter :: Debug , LevelFilter :: Info , LevelFilter :: Warn , LevelFilter :: Error , LevelFilter :: Error , LevelFilter :: Error , LevelFilter :: Off , LevelFilter :: Off] ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Initialisation of the tau_core rust library\"] pub async fn init_tau_core () -> bool { { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"titi\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 86u32 , ()) ; } } ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Commencing yak shaving for yak:?\") , lvl , & (\"yak_events\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 87u32 , ()) ; } } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Deug!!!\") , lvl , & (\"zozo\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 88u32 , ()) ; } } ; { let lvl = :: log :: Level :: Error ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"An error!!!\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 89u32 , ()) ; } } ; { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"etc..\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 90u32 , ()) ; } } ; { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"a warning\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 91u32 , ()) ; } } ; log (Level :: Trace , \"boubou\" , \"hello I am a log from Rust\") ; return true ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: context :: { AudioContext , AudioContextLatencyCategory , AudioContextOptions , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: node :: { AudioNode , AudioScheduledSourceNode } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub fn rust_set_log_level (level : i32) { log :: set_max_level (I_TO_FILTER [level as usize]) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Greeting the user.\"] # [doc = \" Calls several trace functions and call a rust program to play sinusoid sounds.\"] pub fn greet (name : String) -> String { log (Level :: Trace , \"boubou\" , \"hello I am a log from Rust\") ; { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"titi\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 126u32 , ()) ; } } ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"An Info, Commencing yak shaving for yak:?\") , lvl , & (\"yak_events\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 127u32 , ()) ; } } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Debug!!!\") , lvl , & (\"zozo\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 128u32 , ()) ; } } ; { let lvl = :: log :: Level :: Error ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"An error!!!\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 129u32 , ()) ; } } ; { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Trace etc..\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 130u32 , ()) ; } } ; { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"a warning\") , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 131u32 , ()) ; } } ; let latency_hint = match std :: env :: var (\"WEB_AUDIO_LATENCY\") . as_deref () { Ok (\"playback\") => AudioContextLatencyCategory :: Playback , _ => AudioContextLatencyCategory :: default () , } ; let context = AudioContext :: new (AudioContextOptions { latency_hint , .. AudioContextOptions :: default () }) ; { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"{0:?}\" , context) , lvl , & (\"tau::api::simple\" , \"tau::api::simple\" , \"src/api/simple.rs\") , 177u32 , ()) ; } } ; log (Level :: Trace , \"coucou\" , \"{context:?}\") ; let panner_1 = context . create_stereo_panner () ; let mut pan_1 = - 1. ; panner_1 . set_channel_count (1) ; panner_1 . connect (& context . destination ()) ; panner_1 . pan () . set_value (pan_1) ; let mut osc_1 = context . create_oscillator () ; osc_1 . connect (& panner_1) ; osc_1 . frequency () . set_value (200.) ; osc_1 . start () ; let panner_2 = context . create_stereo_panner () ; let mut pan_2 = 1. ; panner_2 . set_channel_count (1) ; panner_2 . connect (& context . destination ()) ; panner_2 . pan () . set_value (pan_2) ; let mut osc_2 = context . create_oscillator () ; osc_2 . connect (& panner_2) ; osc_2 . frequency () . set_value (300.) ; osc_2 . start () ; std :: thread :: sleep (std :: time :: Duration :: from_secs (4)) ; let mut i = 0 ; while i < 3 { i += 1 ; let now = context . current_time () ; panner_1 . pan () . set_value_at_time (pan_1 , now) ; pan_1 = if pan_1 == 1. { - 1. } else { 1. } ; panner_1 . pan () . linear_ramp_to_value_at_time (pan_1 , now + 1.) ; panner_2 . pan () . set_value_at_time (pan_2 , now) ; pan_2 = if pan_2 == 1. { - 1. } else { 1. } ; panner_2 . pan () . linear_ramp_to_value_at_time (pan_2 , now + 1.) ; std :: thread :: sleep (std :: time :: Duration :: from_secs (4)) ; } osc_1 . stop () ; osc_2 . stop () ; { let res = :: alloc :: fmt :: format (format_args ! (\"Bonjour, {0}!\" , name)) ; res } }"
    },
    {
      "meta": {
        "namespace": "crate::api::simple",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [frb (init)] pub fn init_app () { flutter_rust_bridge :: setup_default_user_utils () ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" {@category api}\"] # [doc = \" {@subCategory Information displays}\"] use trace :: trace ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: cell :: Cell ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use log :: Level ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use log :: { info as i , trace as t , warn as w , error as e , debug as d } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use simple_log :: * ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_logger :: logger :: log ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "const DEPTH : :: std :: thread :: LocalKey < Cell < usize > > = { # [inline] fn __init () -> Cell < usize > { Cell :: new (0) } # [inline] unsafe fn __getit (init : :: std :: option :: Option < & mut :: std :: option :: Option < Cell < usize > > >) -> :: std :: option :: Option < & 'static Cell < usize > > { # [thread_local] static __KEY : :: std :: thread :: local_impl :: Key < Cell < usize > > = :: std :: thread :: local_impl :: Key :: < Cell < usize > > :: new () ; unsafe { __KEY . get (move | | { if let :: std :: option :: Option :: Some (init) = init { if let :: std :: option :: Option :: Some (value) = init . take () { return value ; } if true { { :: core :: panicking :: panic_fmt (format_args ! (\"internal error: entered unreachable code: {0}\" , format_args ! (\"missing default value\"))) ; } ; } } __init () }) } } unsafe { :: std :: thread :: LocalKey :: new (__getit) } } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub fn toto () -> String { { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"DANS TOTO\") , lvl , & (\"tau::api::toto\" , \"tau::api::toto\" , \"src/api/toto.rs\") , 41u32 , ()) ; } } ; log (Level :: Trace , \"coucou\" , \"hello I am a log from toto\") ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"yak shaving for toto:?\") , lvl , & (\"yak\" , \"tau::api::toto\" , \"src/api/toto.rs\") , 43u32 , ()) ; } } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Dou Gou Dou GOU!!!\") , lvl , & (\"totoxxx\" , \"tau::api::toto\" , \"src/api/toto.rs\") , 44u32 , ()) ; } } ; \"bobo\" . to_string () }"
    },
    {
      "meta": {
        "namespace": "crate::api::toto",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub fn zozo () -> String { { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"DANS ZOZO\") , lvl , & (\"tau::api::toto\" , \"tau::api::toto\" , \"src/api/toto.rs\") , 54u32 , ()) ; } } ; \"bobo\" . to_string () }"
    },
    {
      "meta": {
        "namespace": "crate::api::zozo",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: { time :: Duration , usize } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::zozo",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [no_mangle] pub extern \"C\" fn sum (a : usize , b : usize) -> usize { a + b }"
    },
    {
      "meta": {
        "namespace": "crate::api::zozo",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [no_mangle] pub extern \"C\" fn sum_long_running (a : usize , b : usize) -> usize { std :: thread :: sleep (Duration :: from_secs (5)) ; a + b }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: api :: media_element :: MyMediaElement ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: frb_generated :: FLUTTER_RUST_BRIDGE_HANDLER ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use extend :: ext ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: for_generated :: anyhow ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: { frb , BaseAsyncRuntime , DartFnFuture } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: context :: { AudioContext , BaseAudioContext , OfflineAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: media_streams :: { MediaStream , MediaStreamTrack } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: node :: * ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: { AudioBuffer , AudioParam , Event , OfflineAudioCompletionEvent , } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait AudioContextExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_decode_audio_data_sync (& self , input_path : String) -> anyhow :: Result < AudioBuffer > ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_create_media_element_source (& self , media_element : & mut MyMediaElement) -> MediaElementAudioSourceNode ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_sink_id (& self , sink_id : String) -> anyhow :: Result < () > ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_state_change (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + Sync + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioContextExt for AudioContext { fn frb_override_decode_audio_data_sync (& self , input_path : String) -> anyhow :: Result < AudioBuffer > { let input = std :: fs :: File :: open (input_path) ? ; self . decode_audio_data_sync (input) . map_err (| e | :: anyhow :: Error :: msg ({ let res = :: alloc :: fmt :: format (format_args ! (\"{0:?}\" , e)) ; res })) } fn frb_override_create_media_element_source (& self , media_element : & mut MyMediaElement) -> MediaElementAudioSourceNode { self . create_media_element_source (& mut media_element . 0 . lock () . unwrap ()) } fn set_sink_id (& self , sink_id : String) -> anyhow :: Result < () > { self . set_sink_id_sync (sink_id) . map_err (| e | :: anyhow :: Error :: msg ({ let res = :: alloc :: fmt :: format (format_args ! (\"{0:?}\" , e)) ; res })) } fn set_on_state_change (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + Sync + 'static) { let callback = Arc :: new (callback) ; self . set_onstatechange (move | event | { let callback_cloned = callback . clone () ; FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback_cloned (event) . await }) ; }) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait OfflineAudioContextExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_complete (& self , callback : impl Fn (OfflineAudioCompletionEvent) -> DartFnFuture < () > + Send + Sync + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl OfflineAudioContextExt for OfflineAudioContext { fn set_on_complete (& self , callback : impl Fn (OfflineAudioCompletionEvent) -> DartFnFuture < () > + Send + Sync + 'static) { self . set_oncomplete (move | event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event) . await }) ; }) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "macro_rules ! handle_audio_node_trait_impls_override { ($ name : ident) => { # [ext] pub impl $ name { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static ,) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } } } ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait AudioParamExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioParamExt for AudioParam { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait AnalyserNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AnalyserNodeExt for AnalyserNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait AudioBufferSourceNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioBufferSourceNodeExt for AudioBufferSourceNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait AudioDestinationNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioDestinationNodeExt for AudioDestinationNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait BiquadFilterNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl BiquadFilterNodeExt for BiquadFilterNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait ChannelMergerNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl ChannelMergerNodeExt for ChannelMergerNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait ChannelSplitterNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl ChannelSplitterNodeExt for ChannelSplitterNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait ConstantSourceNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl ConstantSourceNodeExt for ConstantSourceNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait ConvolverNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl ConvolverNodeExt for ConvolverNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait DelayNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl DelayNodeExt for DelayNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait DynamicsCompressorNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl DynamicsCompressorNodeExt for DynamicsCompressorNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait GainNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl GainNodeExt for GainNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait IIRFilterNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl IIRFilterNodeExt for IIRFilterNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait MediaElementAudioSourceNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaElementAudioSourceNodeExt for MediaElementAudioSourceNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait MediaStreamAudioDestinationNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaStreamAudioDestinationNodeExt for MediaStreamAudioDestinationNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait MediaStreamAudioSourceNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaStreamAudioSourceNodeExt for MediaStreamAudioSourceNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait MediaStreamTrackAudioSourceNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaStreamTrackAudioSourceNodeExt for MediaStreamTrackAudioSourceNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait OscillatorNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl OscillatorNodeExt for OscillatorNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait PannerNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl PannerNodeExt for PannerNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait ScriptProcessorNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl ScriptProcessorNodeExt for ScriptProcessorNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait StereoPannerNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl StereoPannerNodeExt for StereoPannerNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait WaveShaperNodeExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_connect (& self , dest : & dyn AudioNode) ; # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl WaveShaperNodeExt for WaveShaperNode { fn frb_override_connect (& self , dest : & dyn AudioNode) { self . connect (dest) ; } fn set_on_processor_error (& self , callback : impl Fn (String) -> DartFnFuture < () > + Send + 'static) { self . set_onprocessorerror (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event . message) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "macro_rules ! handle_audio_scheduled_source_node_trait_impls_override { ($ name : ident) => { paste :: paste ! { # [ext (name = [<$ name ScheduledSourceNodeMiscExt >])] pub impl $ name { fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static ,) { self . set_onended (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event) . await }) ; })) } } } } ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait ConstantSourceNodeScheduledSourceNodeMiscExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl ConstantSourceNodeScheduledSourceNodeMiscExt for ConstantSourceNode { fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static) { self . set_onended (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait OscillatorNodeScheduledSourceNodeMiscExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl OscillatorNodeScheduledSourceNodeMiscExt for OscillatorNode { fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static) { self . set_onended (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait AudioBufferSourceNodeScheduledSourceNodeMiscExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static) ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioBufferSourceNodeScheduledSourceNodeMiscExt for AudioBufferSourceNode { fn set_on_ended (& self , callback : impl Fn (Event) -> DartFnFuture < () > + Send + 'static) { self . set_onended (Box :: new (| event | { FLUTTER_RUST_BRIDGE_HANDLER . async_runtime () . spawn (async move { callback (event) . await }) ; })) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait EventExt { # [frb (sync , getter)] # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn type_ (& self) -> String ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl EventExt for Event { # [frb (sync , getter)] fn type_ (& self) -> String { self . type_ . to_owned () } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait MediaStreamExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_get_tracks (& self) -> Vec < MediaStreamTrack > ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaStreamExt for MediaStream { fn frb_override_get_tracks (& self) -> Vec < MediaStreamTrack > { self . get_tracks () . to_owned () } }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [allow (non_camel_case_types)] pub trait WaveShaperNodeMiscExt { # [allow (patterns_in_fns_without_body , clippy :: inline_fn_without_body , unused_attributes)] fn frb_override_curve (& self) -> Option < Vec < f32 > > ; }"
    },
    {
      "meta": {
        "namespace": "crate::api::override_web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl WaveShaperNodeMiscExt for WaveShaperNode { fn frb_override_curve (& self) -> Option < Vec < f32 > > { self . curve () . map (| x | x . to_owned ()) } }"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" {@category api}\"] # [doc = \" {@subCategory Information displays}\"] use trace :: trace ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: cell :: Cell ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use log :: Level ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use log :: { info as i , trace as t , warn as w , error as e , debug as d } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use simple_log :: * ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_logger :: logger :: log ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "const DEPTH : :: std :: thread :: LocalKey < Cell < usize > > = { # [inline] fn __init () -> Cell < usize > { Cell :: new (0) } # [inline] unsafe fn __getit (init : :: std :: option :: Option < & mut :: std :: option :: Option < Cell < usize > > >) -> :: std :: option :: Option < & 'static Cell < usize > > { # [thread_local] static __KEY : :: std :: thread :: local_impl :: Key < Cell < usize > > = :: std :: thread :: local_impl :: Key :: < Cell < usize > > :: new () ; unsafe { __KEY . get (move | | { if let :: std :: option :: Option :: Some (init) = init { if let :: std :: option :: Option :: Some (value) = init . take () { return value ; } if true { { :: core :: panicking :: panic_fmt (format_args ! (\"internal error: entered unreachable code: {0}\" , format_args ! (\"missing default value\"))) ; } ; } } __init () }) } } unsafe { :: std :: thread :: LocalKey :: new (__getit) } } ;"
    },
    {
      "meta": {
        "namespace": "crate::api::mimi",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub fn mimi () -> String { { let lvl = :: log :: Level :: Trace ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"DANS MIMI\") , lvl , & (\"tau::api::mimi\" , \"tau::api::mimi\" , \"src/api/mimi.rs\") , 41u32 , ()) ; } } ; log (Level :: Trace , \"coucou\" , \"hello I am a log from toto\") ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"yak shaving for toto:?\") , lvl , & (\"yak\" , \"tau::api::mimi\" , \"src/api/mimi.rs\") , 43u32 , ()) ; } } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Dou Gou Dou GOU!!!\") , lvl , & (\"totoxxx\" , \"tau::api::mimi\" , \"src/api/mimi.rs\") , 44u32 , ()) ; } } ; \"bobo\" . to_string () }"
    },
    {
      "meta": {
        "namespace": "crate::api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use delegate_attr :: delegate ;"
    },
    {
      "meta": {
        "namespace": "crate::api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "crate::api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: Mutex ;"
    },
    {
      "meta": {
        "namespace": "crate::api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [frb (opaque)] pub struct MyMediaElement (pub (crate) Mutex < web_audio_api :: MediaElement >) ;"
    },
    {
      "meta": {
        "namespace": "crate::api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MyMediaElement { # [inline (always)] pub fn current_time (& self) -> f64 { self . 0 . lock () . unwrap () . current_time () } # [inline (always)] pub fn set_current_time (& self , value : f64) { self . 0 . lock () . unwrap () . set_current_time (value) ; } # [inline (always)] pub fn loop_ (& self) -> bool { self . 0 . lock () . unwrap () . loop_ () } # [inline (always)] pub fn set_loop (& self , value : bool) { self . 0 . lock () . unwrap () . set_loop (value) ; } # [inline (always)] pub fn play (& self) { self . 0 . lock () . unwrap () . play () ; } # [inline (always)] pub fn pause (& self) { self . 0 . lock () . unwrap () . pause () ; } # [inline (always)] pub fn paused (& self) -> bool { self . 0 . lock () . unwrap () . paused () } # [inline (always)] pub fn playback_rate (& self) -> f64 { self . 0 . lock () . unwrap () . playback_rate () } # [inline (always)] pub fn set_playback_rate (& self , value : f64) { self . 0 . lock () . unwrap () . set_playback_rate (value) ; } }"
    },
    {
      "meta": {
        "namespace": "crate::api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MyMediaElement { # [frb (sync)] pub fn new (file : String) -> anyhow :: Result < MyMediaElement > { Ok (MyMediaElement (Mutex :: new (web_audio_api :: MediaElement :: new (file) . map_err (| err | :: anyhow :: Error :: msg ({ let res = :: alloc :: fmt :: format (format_args ! (\"{0:?}\" , err)) ; res })) ?))) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use crate :: { handle_audio_node_trait_impls_marker , handle_getter_audio_param , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: { AudioBuffer , AudioListener , AudioParam , AudioRenderCapacity , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioRenderCapacity { # [frb (ignore)] pub fn set_onupdate () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioBuffer { # [frb (ignore)] pub fn copy_from_channel () { } # [frb (ignore)] pub fn copy_from_channel_with_offset () { } # [frb (ignore)] pub fn copy_to_channel () { } # [frb (ignore)] pub fn copy_to_channel_with_offset () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioParam { # [frb (sync , getter)] pub fn value () { } # [frb (sync , setter)] pub fn set_value () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (ignore)] pub struct ErrorEvent ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (ignore)] pub struct MediaElement ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioParam { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioListener { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn position_x () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn position_y () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn position_z () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn forward_x () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn forward_y () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn forward_z () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn up_x () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn up_y () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn up_z () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: context :: { AudioContext , AudioContextRenderSizeCategory , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioContext { # [frb (sync)] pub fn new () { } # [frb (ignore)] pub fn create_media_element_source () { } # [frb (ignore)] pub fn set_sink_id_sync () { } # [frb (ignore)] pub fn resume () { } # [frb (ignore)] pub fn base () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] pub trait BaseAudioContext { # [frb (ignore)] fn base () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl Default for AudioContextRenderSizeCategory { # [frb (ignore)] fn default () -> Self { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (non_opaque)] pub struct AudioContextOptions ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (non_opaque)] pub enum AudioContextLatencyCategory { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (ignore)] pub struct MediaDeviceInfo ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (ignore)] pub fn enumerate_devices_sync () { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (ignore)] pub struct MediaTrackConstraints ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: node :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AnalyserNode { # [frb (ignore)] pub fn get_float_time_domain_data () { } # [frb (ignore)] pub fn get_byte_time_domain_data () { } # [frb (ignore)] pub fn get_float_frequency_data () { } # [frb (ignore)] pub fn get_byte_frequency_data () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioBufferSourceNode { # [frb (ignore)] pub fn buffer () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl BiquadFilterNode { # [frb (ignore)] pub fn get_frequency_response () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ConvolverNode { # [frb (ignore)] pub fn buffer () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl IIRFilterNode { # [frb (ignore)] pub fn get_frequency_response () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl WaveShaperNode { # [frb (ignore)] pub fn curve () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl MediaStreamAudioDestinationNode { # [frb (proxy)] pub fn stream () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] # [frb (generate_implementor_enum)] pub trait AudioNode { # [frb (ignore)] fn context () ; # [frb (ignore)] fn set_onprocessorerror () ; # [frb (ignore)] fn connect_from_output_to_input () ; # [frb (ignore)] fn disconnect_dest () ; # [frb (ignore)] fn disconnect_dest_from_output () ; # [frb (ignore)] fn disconnect_dest_from_output_to_input () ; # [frb (ignore)] fn set_channel_count () ; # [frb (ignore)] fn set_channel_count_mode () ; # [frb (ignore)] fn set_channel_interpretation () ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [macro_export] macro_rules ! handle_audio_node_trait_impls_marker { ($ name : ident) => { # [frb (external)] impl $ name { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AnalyserNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioBufferSourceNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioDestinationNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl BiquadFilterNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ChannelMergerNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ChannelSplitterNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ConstantSourceNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ConvolverNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl DelayNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl DynamicsCompressorNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl GainNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl IIRFilterNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl MediaElementAudioSourceNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl MediaStreamAudioDestinationNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl MediaStreamAudioSourceNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl MediaStreamTrackAudioSourceNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl OscillatorNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl PannerNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ScriptProcessorNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl StereoPannerNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl WaveShaperNode { # [frb (ignore)] pub fn context () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn connect_from_output_to_input () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [macro_export] macro_rules ! handle_getter_audio_param { ($ struct_name : ident ; $ ($ func_name : ident) ,+) => { # [frb (external)] impl $ struct_name { $ (# [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn $ func_name () { }) + } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioBufferSourceNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn playback_rate () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn detune () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl BiquadFilterNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn gain () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn frequency () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn detune () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn q () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl ConstantSourceNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn offset () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl DelayNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn delay_time () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl DynamicsCompressorNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn attack () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn knee () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn ratio () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn release () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn threshold () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl GainNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn gain () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl OscillatorNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn frequency () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn detune () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl PannerNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn position_x () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn position_y () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn position_z () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn orientation_x () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn orientation_y () { } # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn orientation_z () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl StereoPannerNode { # [frb (proxy , sync , getter)] # [doc = \"[LARPOUX]$func_name\"] pub fn pan () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use flutter_rust_bridge :: frb ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "use web_audio_api :: worklet :: AudioWorkletNode ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] impl AudioWorkletNode { # [frb (ignore)] pub fn port () { } # [frb (ignore)] pub fn set_onprocessorerror () { } # [frb (ignore)] pub fn disconnect_dest () { } # [frb (ignore)] pub fn disconnect_dest_from_output () { } # [frb (ignore)] pub fn disconnect_dest_from_output_to_input () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "# [frb (external)] # [frb (external)] pub trait AudioWorkletProcessor { # [frb (ignore)] fn constructor () ; # [frb (ignore)] fn onmessage () ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal",
          "MoveFromCrateThirdPartyFolder"
        ],
        "is_module_public": true
      },
      "item": "const _ : () = () ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [prelude_import] use std :: prelude :: rust_2021 :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [macro_use] extern crate std ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: atomic :: { AtomicU32 , AtomicU64 , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Render quantum size, the audio graph is rendered in blocks of RENDER_QUANTUM_SIZE samples\"] # [doc = \" see. <https://webaudio.github.io/web-audio-api/#render-quantum>\"] pub (crate) const RENDER_QUANTUM_SIZE : usize = 128 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Maximum number of channels for audio processing\"] pub const MAX_CHANNELS : usize = 32 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use buffer :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use capacity :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use events :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use message_port :: MessagePort ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use param :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use periodic_wave :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use spatial :: AudioListener ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use media_element :: MediaElement ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [repr (transparent)] pub (crate) struct AtomicF32 { bits : AtomicU32 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl std :: fmt :: Debug for AtomicF32 { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . write_fmt (format_args ! (\"{0}\" , self . load (Ordering :: Relaxed))) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AtomicF32 { # [must_use] pub fn new (value : f32) -> Self { Self { bits : AtomicU32 :: new (value . to_bits ()) } } # [must_use] pub fn load (& self , ordering : Ordering) -> f32 { f32 :: from_bits (self . bits . load (ordering)) } pub fn store (& self , value : f32 , ordering : Ordering) { self . bits . store (value . to_bits () , ordering) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Atomic float 64, only `load` and `store` are supported, no arithmetic\"] # [repr (transparent)] pub (crate) struct AtomicF64 { bits : AtomicU64 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl std :: fmt :: Debug for AtomicF64 { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . write_fmt (format_args ! (\"{0}\" , self . load (Ordering :: Relaxed))) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AtomicF64 { # [must_use] pub fn new (value : f64) -> Self { Self { bits : AtomicU64 :: new (value . to_bits ()) } } # [must_use] pub fn load (& self , ordering : Ordering) -> f64 { f64 :: from_bits (self . bits . load (ordering)) } pub fn store (& self , value : f64 , ordering : Ordering) { self . bits . store (value . to_bits () , ordering) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Assert that the given sample rate is valid.\"] # [doc = \"\"] # [doc = \" Note that in practice sample rates should stand between 8000Hz (lower bound for\"] # [doc = \" voice based applications, e.g. see phone bandwidth) and 96000Hz (for very high\"] # [doc = \" quality audio applications and spectrum manipulation).\"] # [doc = \" Most common sample rates for musical applications are 44100 and 48000.\"] # [doc = \"\"] # [doc = \" - see <https://webaudio.github.io/web-audio-api/#dom-baseaudiocontext-samplerate>\"] # [doc = \" > An implementation MUST support sample rates in at least the range 8000 to 96000.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given sample rate is lower than 4000 or greater than 192000\"] # [doc = \"\"] # [track_caller] # [inline (always)] pub (crate) fn assert_valid_sample_rate (sample_rate : f32) { let min_sample_rate = 2_000. ; let max_sample_rate = 384_000. ; if ! (sample_rate >= min_sample_rate && sample_rate <= max_sample_rate) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - Invalid sample rate: {0:?}, should be in the range [{1:?}, {2:?}]\" , sample_rate , min_sample_rate , max_sample_rate)) ; } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Assert that the given number of channels is valid.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given number of channels is outside the [1, 32] range,\"] # [doc = \" 32 being defined by the MAX_CHANNELS constant.\"] # [doc = \"\"] # [track_caller] # [inline (always)] pub (crate) fn assert_valid_number_of_channels (number_of_channels : usize) { if ! (number_of_channels > 0 && number_of_channels <= MAX_CHANNELS) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - Invalid number of channels: {0:?} is outside range [1, {1:?}]\" , number_of_channels , MAX_CHANNELS)) ; } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Assert that the given channel number is valid according to the number of channels\"] # [doc = \" of an Audio asset (e.g. [`AudioBuffer`]).\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given channel number is greater than or equal to the given number of channels.\"] # [doc = \"\"] # [track_caller] # [inline (always)] pub (crate) fn assert_valid_channel_number (channel_number : usize , number_of_channels : usize) { if ! (channel_number < number_of_channels) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - Invalid channel number {0:?} (number of channels: {1:?})\" , channel_number , number_of_channels)) ; } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Assert that the given value number is a valid buffer length, i.e. greater than zero\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given value is not lower than or equal to zero\"] # [doc = \"\"] # [track_caller] # [inline (always)] pub (crate) fn assert_valid_buffer_length (length : usize) { if ! (length > 0) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - Invalid length: {0:?} is less than or equal to minimum bound (0)\" , length)) ; } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Assert that the given value number is a valid time information, i.e. greater\"] # [doc = \" than or equal to zero and finite.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given value is not finite and lower than zero\"] # [doc = \"\"] # [track_caller] # [inline (always)] pub (crate) fn assert_valid_time_value (value : f64) { if ! value . is_finite () { { :: core :: panicking :: panic_fmt (format_args ! (\"TypeError - The provided time value is non-finite.\")) ; } } ; if ! (value >= 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - The provided time value ({0:?}) cannot be negative\" , value)) ; } } ; }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub (crate) trait AudioBufferIter : Iterator < Item = FallibleBuffer > + Send + 'static { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < M : Iterator < Item = FallibleBuffer > + Send + 'static > AudioBufferIter for M { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "type FallibleBuffer = Result < AudioBuffer , Box < dyn Error + Send + Sync > > ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`AudioBuffer`]\"] pub struct AudioBufferOptions { # [doc = \" The number of channels for the buffer\"] pub number_of_channels : usize , # [doc = \" The length in sample frames of the buffer\"] pub length : usize , # [doc = \" The sample rate in Hz for the buffer\"] pub sample_rate : f32 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Memory-resident audio asset, basically a matrix of channels * samples\"] # [doc = \"\"] # [doc = \" An AudioBuffer has copy-on-write semantics, so it is cheap to clone.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#AudioBuffer>\"] # [doc = \" - see also: [`BaseAudioContext::create_buffer`](crate::context::BaseAudioContext::create_buffer)\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::f32::consts::PI;\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let length = context.sample_rate() as usize;\"] # [doc = \" let sample_rate = context.sample_rate();\"] # [doc = \" let mut buffer = context.create_buffer(1, length, sample_rate);\"] # [doc = \"\"] # [doc = \" // fill buffer with a sine wave\"] # [doc = \" let mut sine = vec![];\"] # [doc = \"\"] # [doc = \" for i in 0..length {\"] # [doc = \"     let phase = i as f32 / length as f32 * 2. * PI * 200.;\"] # [doc = \"     sine.push(phase.sin());\"] # [doc = \" }\"] # [doc = \"\"] # [doc = \" buffer.copy_to_channel(&sine, 0);\"] # [doc = \"\"] # [doc = \" // play the buffer in a loop\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.set_buffer(buffer.clone());\"] # [doc = \" src.set_loop(true);\"] # [doc = \" src.connect(&context.destination());\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Example\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example audio_buffer`\"] # [doc = \"\"] pub struct AudioBuffer { pub (crate) channels : Vec < ChannelData > , pub (crate) sample_rate : f32 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an `AudioRenderCapacity`\"] pub struct AudioRenderCapacityOptions { # [doc = \" An update interval (in seconds) for dispatching [`AudioRenderCapacityEvent`]s\"] pub update_interval : f64 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Performance metrics of the rendering thread\"] pub struct AudioRenderCapacityEvent { # [doc = \" The start time of the data collection period in terms of the associated AudioContext's currentTime\"] pub timestamp : f64 , # [doc = \" An average of collected load values over the given update interval\"] pub average_load : f64 , # [doc = \" A maximum value from collected load values over the given update interval.\"] pub peak_load : f64 , # [doc = \" A ratio between the number of buffer underruns and the total number of system-level audio callbacks over the given update interval.\"] pub underrun_ratio : f64 , # [doc = \" Inherits from this base Event\"] pub event : Event , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Provider for rendering performance metrics\"] # [doc = \"\"] # [doc = \" A load value is computed for each system-level audio callback, by dividing its execution\"] # [doc = \" duration by the system-level audio callback buffer size divided by the sample rate.\"] # [doc = \"\"] # [doc = \" Ideally the load value is below 1.0, meaning that it took less time to render the audio than it\"] # [doc = \" took to play it out. An audio buffer underrun happens when this load value is greater than 1.0: the\"] # [doc = \" system could not render audio fast enough for real-time.\"] pub struct AudioRenderCapacity { context : ConcreteBaseAudioContext , receiver : Receiver < AudioRenderCapacityLoad > , stop_send : Arc < Mutex < Option < Sender < () > > > > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The Event interface\"] # [non_exhaustive] pub struct Event { pub type_ : & 'static str , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The Error Event interface\"] # [non_exhaustive] pub struct ErrorEvent { # [doc = \" The error message\"] pub message : String , # [doc = \" The object with which panic was originally invoked.\"] pub error : Box < dyn Any + Send > , # [doc = \" Inherits from this base Event\"] pub event : Event , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The AudioProcessingEvent interface\"] # [non_exhaustive] pub struct AudioProcessingEvent { # [doc = \" The input buffer\"] pub input_buffer : AudioBuffer , # [doc = \" The output buffer\"] pub output_buffer : AudioBuffer , # [doc = \" The time when the audio will be played in the same time coordinate system as the\"] # [doc = \" AudioContext's currentTime.\"] pub playback_time : f64 , pub (crate) registration : Option < (ConcreteBaseAudioContext , AudioNodeId) > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The OfflineAudioCompletionEvent Event interface\"] # [non_exhaustive] pub struct OfflineAudioCompletionEvent { # [doc = \" The rendered AudioBuffer\"] pub rendered_buffer : AudioBuffer , # [doc = \" Inherits from this base Event\"] pub event : Event , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" One of the two ports of a message channel\"] # [doc = \"\"] # [doc = \" Allowing messages to be sent from one port and listening out for them arriving at the other.\"] pub struct MessagePort < 'a > (& 'a AudioContextRegistration) ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Precision of AudioParam value calculation per render quantum\"] pub enum AutomationRate { # [doc = \" Audio Rate - sampled for each sample-frame of the block\"] A , # [doc = \" Control Rate - sampled at the time of the very first sample-frame,\"] # [doc = \" then used for the entire block\"] K , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`AudioParam`]\"] pub struct AudioParamDescriptor { pub name : String , pub automation_rate : AutomationRate , pub default_value : f32 , pub min_value : f32 , pub max_value : f32 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" AudioParam controls an individual aspect of an AudioNode's functionality, such as volume.\"] pub struct AudioParam { registration : Arc < AudioContextRegistration > , raw_parts : AudioParamInner , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`PeriodicWave`]\"] pub struct PeriodicWaveOptions { # [doc = \" The real parameter represents an array of cosine terms of Fourier series.\"] # [doc = \"\"] # [doc = \" The first element (index 0) represents the DC-offset.\"] # [doc = \" This offset has to be given but will not be taken into account\"] # [doc = \" to build the custom periodic waveform.\"] # [doc = \"\"] # [doc = \" The following elements (index 1 and more) represent the fundamental and\"] # [doc = \" harmonics of the periodic waveform.\"] pub real : Option < Vec < f32 > > , # [doc = \" The imag parameter represents an array of sine terms of Fourier series.\"] # [doc = \"\"] # [doc = \" The first element (index 0) will not be taken into account\"] # [doc = \" to build the custom periodic waveform.\"] # [doc = \"\"] # [doc = \" The following elements (index 1 and more) represent the fundamental and\"] # [doc = \" harmonics of the periodic waveform.\"] pub imag : Option < Vec < f32 > > , # [doc = \" By default PeriodicWave is build with normalization enabled (disable_normalization = false).\"] # [doc = \" In this case, a peak normalization is applied to the given custom periodic waveform.\"] # [doc = \"\"] # [doc = \" If disable_normalization is enabled (disable_normalization = true), the normalization is\"] # [doc = \" defined by the periodic waveform characteristics (img, and real fields).\"] pub disable_normalization : bool , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `PeriodicWave` represents an arbitrary periodic waveform to be used with an `OscillatorNode`.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/PeriodicWave>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#PeriodicWave>\"] # [doc = \" - see also: [`BaseAudioContext::create_periodic_wave`]\"] # [doc = \" - see also: [`OscillatorNode`](crate::node::OscillatorNode)\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::{PeriodicWave, PeriodicWaveOptions};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" // generate a simple waveform with 2 harmonics\"] # [doc = \" let options = PeriodicWaveOptions {\"] # [doc = \"   real: Some(vec![0., 0., 0.]),\"] # [doc = \"   imag: Some(vec![0., 0.5, 0.5]),\"] # [doc = \"   disable_normalization: false,\"] # [doc = \" };\"] # [doc = \"\"] # [doc = \" let periodic_wave = PeriodicWave::new(&context, options);\"] # [doc = \"\"] # [doc = \" let mut osc = context.create_oscillator();\"] # [doc = \" osc.set_periodic_wave(periodic_wave);\"] # [doc = \" osc.connect(&context.destination());\"] # [doc = \" osc.start();\"] # [doc = \" ```\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example oscillators`\"] # [doc = \"\"] pub struct PeriodicWave { wavetable : Arc < Vec < f32 > > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Represents the position and orientation of the person listening to the audio scene\"] # [doc = \"\"] # [doc = \" All [`PannerNode`](crate::node::PannerNode) objects spatialize in relation to the [BaseAudioContext's](crate::context::BaseAudioContext) listener.\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" For example usage, check the [`PannerNode`](crate::node::PannerNode) docs.\"] pub struct AudioListener { pub (crate) position_x : AudioParam , pub (crate) position_y : AudioParam , pub (crate) position_z : AudioParam , pub (crate) forward_x : AudioParam , pub (crate) forward_y : AudioParam , pub (crate) forward_z : AudioParam , pub (crate) up_x : AudioParam , pub (crate) up_y : AudioParam , pub (crate) up_z : AudioParam , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Shim of the `<audio>` element which allows you to efficiently play and seek audio from disk\"] # [doc = \"\"] # [doc = \" The documentation for [`MediaElementAudioSourceNode`](crate::node::MediaElementAudioSourceNode)\"] # [doc = \" contains usage instructions.\"] pub struct MediaElement { stream : Option < RTSStream > , current_time : Arc < AtomicF64 > , sender : Sender < MediaElementAction > , loop_ : Arc < AtomicBool > , paused : Arc < AtomicBool > , playback_rate : Arc < AtomicF64 > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { assert_valid_buffer_length , assert_valid_channel_number , assert_valid_number_of_channels , assert_valid_sample_rate , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioBufferOptions { # [inline] fn clone (& self) -> AudioBufferOptions { AudioBufferOptions { number_of_channels : :: core :: clone :: Clone :: clone (& self . number_of_channels) , length : :: core :: clone :: Clone :: clone (& self . length) , sample_rate : :: core :: clone :: Clone :: clone (& self . sample_rate) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioBufferOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"AudioBufferOptions\" , \"number_of_channels\" , & self . number_of_channels , \"length\" , & self . length , \"sample_rate\" , & & self . sample_rate) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioBuffer { # [inline] fn clone (& self) -> AudioBuffer { AudioBuffer { channels : :: core :: clone :: Clone :: clone (& self . channels) , sample_rate : :: core :: clone :: Clone :: clone (& self . sample_rate) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioBuffer { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AudioBuffer\" , \"channels\" , & self . channels , \"sample_rate\" , & & self . sample_rate) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioBuffer { # [doc = \" Allocate a silent audiobuffer with [`AudioBufferOptions`]\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given sample rate is zero\"] # [doc = \" - the given number of channels is outside the [1, 32] range,\"] # [doc = \" 32 being defined by the MAX_CHANNELS constant.\"] pub fn new (options : AudioBufferOptions) -> Self { assert_valid_sample_rate (options . sample_rate) ; assert_valid_buffer_length (options . length) ; assert_valid_number_of_channels (options . number_of_channels) ; let silence = ChannelData :: new (options . length) ; Self { channels : :: alloc :: vec :: from_elem (silence , options . number_of_channels) , sample_rate : options . sample_rate , } } # [doc = \" Convert raw samples to an AudioBuffer\"] # [doc = \"\"] # [doc = \" The outer Vec determine the channels. The inner Vecs should have the same length.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given sample rate is zero\"] # [doc = \" - the given number of channels defined by `samples.len()`is outside the\"] # [doc = \"   [1, 32] range, 32 being defined by the MAX_CHANNELS constant.\"] # [doc = \" - any of its items have different lengths\"] pub fn from (samples : Vec < Vec < f32 > > , sample_rate : f32) -> Self { assert_valid_sample_rate (sample_rate) ; assert_valid_number_of_channels (samples . len ()) ; let channels : Vec < _ > = samples . into_iter () . map (ChannelData :: from) . collect () ; if ! channels . iter () . all (| c | c . len () == channels [0] . len ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"Trying to create AudioBuffer from channel data with unequal length\")) ; } ; } Self { channels , sample_rate } } # [doc = \" Number of channels in this `AudioBuffer`\"] pub fn number_of_channels (& self) -> usize { self . channels . len () } # [doc = \" Number of samples per channel in this `AudioBuffer`\"] pub fn length (& self) -> usize { self . channels . first () . map (ChannelData :: len) . unwrap_or (0) } # [doc = \" Sample rate of this `AudioBuffer` in Hertz\"] pub fn sample_rate (& self) -> f32 { self . sample_rate } # [doc = \" Duration in seconds of the `AudioBuffer`\"] pub fn duration (& self) -> f64 { self . length () as f64 / self . sample_rate as f64 } # [doc = \" Copy data from a given channel to the given `Vec`\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if `channel_number` is greater or equal than\"] # [doc = \" `AudioBuffer::number_of_channels()`\"] pub fn copy_from_channel (& self , destination : & mut [f32] , channel_number : usize) { assert_valid_channel_number (channel_number , self . number_of_channels ()) ; self . copy_from_channel_with_offset (destination , channel_number , 0) ; } # [doc = \" Copy data from a given channel to the given `Vec` starting at `offset`\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given channel number is greater than or equal to the given number of channels.\"] pub fn copy_from_channel_with_offset (& self , destination : & mut [f32] , channel_number : usize , offset : usize) { assert_valid_channel_number (channel_number , self . number_of_channels ()) ; let offset = offset . min (self . length ()) ; let dest_length = destination . len () ; let max_frame = (self . length () - offset) . clamp (0 , dest_length) ; let channel = self . channel_data (channel_number) . as_slice () ; destination [.. max_frame] . copy_from_slice (& channel [offset .. (max_frame + offset)]) ; } # [doc = \" Copy data from a given source to the given channel.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given channel number is greater than or equal to the given number of channels.\"] pub fn copy_to_channel (& mut self , source : & [f32] , channel_number : usize) { assert_valid_channel_number (channel_number , self . number_of_channels ()) ; self . copy_to_channel_with_offset (source , channel_number , 0) ; } # [doc = \" Copy data from a given source to the given channel starting at `offset`.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given channel number is greater than or equal to the given number of channels.\"] pub fn copy_to_channel_with_offset (& mut self , source : & [f32] , channel_number : usize , offset : usize) { assert_valid_channel_number (channel_number , self . number_of_channels ()) ; let offset = offset . min (self . length ()) ; let src_len = source . len () ; let max_frame = (self . length () - offset) . clamp (0 , src_len) ; let channel = self . channel_data_mut (channel_number) . as_mut_slice () ; channel [offset .. (max_frame + offset)] . copy_from_slice (& source [.. max_frame]) ; } # [doc = \" Return a read-only copy of the underlying data of the channel\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given channel number is greater than or equal to the given number of channels.\"] pub fn get_channel_data (& self , channel_number : usize) -> & [f32] { assert_valid_channel_number (channel_number , self . number_of_channels ()) ; self . channel_data (channel_number) . as_slice () } # [doc = \" Return a mutable slice of the underlying data of the channel\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given channel number is greater than or equal to the given number of channels.\"] pub fn get_channel_data_mut (& mut self , channel_number : usize) -> & mut [f32] { assert_valid_channel_number (channel_number , self . number_of_channels ()) ; self . channel_data_mut (channel_number) . as_mut_slice () } # [doc = \" Create a multi-channel audiobuffer directly from `ChannelData`s.\"] pub (crate) fn from_channels (channels : Vec < ChannelData > , sample_rate : f32) -> Self { Self { channels , sample_rate } } # [doc = \" Channel data as slice\"] pub (crate) fn channels (& self) -> & [ChannelData] { & self . channels } # [doc = \" Channel data as slice (mutable)\"] pub (crate) fn channels_mut (& mut self) -> & mut [ChannelData] { & mut self . channels } # [doc = \" Get the samples from this specific channel.\"] # [doc = \"\"] # [doc = \" Panics if the index is greater than the available number of channels\"] pub (crate) fn channel_data (& self , index : usize) -> & ChannelData { & self . channels [index] } # [doc = \" Get the samples (mutable) from this specific channel.\"] # [doc = \"\"] # [doc = \" Panics if the index is greater than the available number of channels\"] pub (crate) fn channel_data_mut (& mut self , index : usize) -> & mut ChannelData { & mut self . channels [index] } # [doc = \" Extends an AudioBuffer with the contents of another.\"] # [doc = \"\"] # [doc = \" This function will panic if the sample_rate and channel_count are not equal\"] pub (crate) fn extend (& mut self , other : & Self) { match (& self . sample_rate , & other . sample_rate) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; match (& self . number_of_channels () , & other . number_of_channels ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; let data = self . channels_mut () ; data . iter_mut () . zip (other . channels . iter ()) . for_each (| (channel , other_channel) | { let cur_channel_data = Arc :: make_mut (& mut channel . data) ; cur_channel_data . extend (other_channel . as_slice ()) ; }) } # [doc = \" Split an AudioBuffer in two at the given index.\"] pub (crate) fn split_off (& mut self , index : usize) -> Self { let channels : Vec < _ > = self . channels_mut () . iter_mut () . map (| channel_data | Arc :: make_mut (& mut channel_data . data) . split_off (index)) . map (ChannelData :: from) . collect () ; AudioBuffer :: from_channels (channels , self . sample_rate) } # [doc = \" Resample to the desired sample rate. The method performs a simple linear\"] # [doc = \" interpolation an keep the first and last sample intact. The new number\"] # [doc = \" of samples is always ceiled according the ratio defined by old and new\"] # [doc = \" sample rates.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if:\"] # [doc = \" - the given sample rate is zero\"] pub (crate) fn resample (& mut self , sample_rate : f32) { assert_valid_sample_rate (sample_rate) ; if { match (& self . sample_rate , & sample_rate) { (a_val , b_val) => { false || :: float_eq :: FloatEqCmp :: abs (a_val , b_val , & 0.1) } } } { self . sample_rate = sample_rate ; return ; } if self . length () == 0 { self . sample_rate = sample_rate ; return ; } let source_sr = self . sample_rate as f64 ; let target_sr = sample_rate as f64 ; let ratio = target_sr / source_sr ; let source_length = self . length () ; let target_length = (self . length () as f64 * ratio) . ceil () as usize ; let num_channels = self . number_of_channels () ; let mut resampled = Vec :: < Vec < f32 > > :: with_capacity (num_channels) ; resampled . resize_with (num_channels , | | Vec :: < f32 > :: with_capacity (target_length)) ; for i in 0 .. target_length { let position = i as f64 / (target_length - 1) as f64 ; let playhead = position * (source_length - 1) as f64 ; let playhead_floored = playhead . floor () ; let prev_index = playhead_floored as usize ; let next_index = (prev_index + 1) . min (source_length - 1) ; let k = (playhead - playhead_floored) as f32 ; let k_inv = 1. - k ; for (channel , resampled_data) in resampled . iter_mut () . enumerate () { let prev_sample = self . channels [channel] . data [prev_index] ; let next_sample = self . channels [channel] . data [next_index] ; let value = k_inv * prev_sample + k * next_sample ; resampled_data . push (value) ; } } self . channels . iter_mut () . zip (resampled) . for_each (| (channel_data , resampled_data) | { channel_data . data = Arc :: new (resampled_data) ; }) ; self . sample_rate = sample_rate ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelData { # [inline] fn clone (& self) -> ChannelData { ChannelData { data : :: core :: clone :: Clone :: clone (& self . data) } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for ChannelData { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for ChannelData { # [inline] fn eq (& self , other : & ChannelData) -> bool { self . data == other . data } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for ChannelData { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"ChannelData\") . field (\"len\" , & self . len ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::buffer",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ChannelData { pub fn new (length : usize) -> Self { let buffer = :: alloc :: vec :: from_elem (0. , length) ; let data = Arc :: new (buffer) ; Self { data } } pub fn from (data : Vec < f32 >) -> Self { Self { data : Arc :: new (data) } } pub fn len (& self) -> usize { self . data . len () } # [allow (dead_code)] pub fn is_empty (& self) -> bool { self . data . is_empty () } pub fn as_slice (& self) -> & [f32] { & self . data [..] } pub fn as_mut_slice (& mut self) -> & mut [f32] { & mut Arc :: make_mut (& mut self . data) [..] } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { Receiver , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { BaseAudioContext , ConcreteBaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { EventDispatch , EventHandler , EventPayload , EventType } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: Event ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AudioRenderCapacityLoad { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioRenderCapacityLoad { # [inline] fn clone (& self) -> AudioRenderCapacityLoad { let _ : :: core :: clone :: AssertParamIsClone < f64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioRenderCapacityLoad { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AudioRenderCapacityLoad\" , \"render_timestamp\" , & self . render_timestamp , \"load_value\" , & & self . load_value) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioRenderCapacityOptions { # [inline] fn clone (& self) -> AudioRenderCapacityOptions { AudioRenderCapacityOptions { update_interval : :: core :: clone :: Clone :: clone (& self . update_interval) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioRenderCapacityOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"AudioRenderCapacityOptions\" , \"update_interval\" , & & self . update_interval) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioRenderCapacityOptions { fn default () -> Self { Self { update_interval : 1. } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioRenderCapacityEvent { # [inline] fn clone (& self) -> AudioRenderCapacityEvent { AudioRenderCapacityEvent { timestamp : :: core :: clone :: Clone :: clone (& self . timestamp) , average_load : :: core :: clone :: Clone :: clone (& self . average_load) , peak_load : :: core :: clone :: Clone :: clone (& self . peak_load) , underrun_ratio : :: core :: clone :: Clone :: clone (& self . underrun_ratio) , event : :: core :: clone :: Clone :: clone (& self . event) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioRenderCapacityEvent { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"AudioRenderCapacityEvent\" , \"timestamp\" , & self . timestamp , \"average_load\" , & self . average_load , \"peak_load\" , & self . peak_load , \"underrun_ratio\" , & self . underrun_ratio , \"event\" , & & self . event) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioRenderCapacityEvent { fn new (timestamp : f64 , average_load : f64 , peak_load : f64 , underrun_ratio : f64) -> Self { Self { timestamp , average_load : (average_load * 100.) . round () / 100. , peak_load : (peak_load * 100.) . round () / 100. , underrun_ratio : (underrun_ratio * 100.) . ceil () / 100. , event : Event { type_ : \"AudioRenderCapacityEvent\" } , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for AudioRenderCapacity { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"AudioRenderCapacity\") . field (\"context\" , & { let res = :: alloc :: fmt :: format (format_args ! (\"BaseAudioContext@{0}\" , self . context . address ())) ; res }) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::capacity",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioRenderCapacity { pub (crate) fn new (context : ConcreteBaseAudioContext , receiver : Receiver < AudioRenderCapacityLoad >) -> Self { let stop_send = Arc :: new (Mutex :: new (None)) ; Self { context , receiver , stop_send } } # [doc = \" Start metric collection and analysis\"] # [allow (clippy :: missing_panics_doc)] pub fn start (& self , options : AudioRenderCapacityOptions) { self . stop () ; let receiver = self . receiver . clone () ; let (stop_send , stop_recv) = crossbeam_channel :: bounded (0) ; * self . stop_send . lock () . unwrap () = Some (stop_send) ; let mut timestamp : f64 = self . context . current_time () ; let mut load_sum : f64 = 0. ; let mut counter = 0 ; let mut peak_load : f64 = 0. ; let mut underrun_sum = 0 ; let mut next_checkpoint = timestamp + options . update_interval ; let base_context = self . context . clone () ; std :: thread :: spawn (move | | loop { let try_item = { const _IS_BIASED : bool = false ; { const _LEN : usize = 1 + (1 + 0) ; let _handle : & dyn :: crossbeam_channel :: internal :: SelectHandle = & :: crossbeam_channel :: never :: < () > () ; # [allow (unused_mut)] let mut _sel = [(_handle , 0 , :: std :: ptr :: null ()) ; _LEN] ; { match receiver { ref _r => { let _oper0 : & :: crossbeam_channel :: Receiver < _ > = unsafe { let _r : & :: crossbeam_channel :: Receiver < _ > = _r ; unsafe fn unbind < 'a , T > (x : & T) -> & 'a T { :: std :: mem :: transmute (x) } unbind (_r) } ; _sel [0usize] = (_oper0 , 0usize , _oper0 as * const :: crossbeam_channel :: Receiver < _ > as * const u8) ; { match stop_recv { ref _r => { let _oper1 : & :: crossbeam_channel :: Receiver < _ > = unsafe { let _r : & :: crossbeam_channel :: Receiver < _ > = _r ; unsafe fn unbind < 'a , T > (x : & T) -> & 'a T { :: std :: mem :: transmute (x) } unbind (_r) } ; _sel [1usize] = (_oper1 , 1usize , _oper1 as * const :: crossbeam_channel :: Receiver < _ > as * const u8) ; { let _oper : :: crossbeam_channel :: SelectedOperation < '_ > = { let _oper = :: crossbeam_channel :: internal :: select (& mut _sel , _IS_BIASED) ; unsafe { :: std :: mem :: transmute (_oper) } } ; { if _oper . index () == 0usize { let _res = _oper . recv (_oper0) ; { _sel } ; let item = _res ; { item } } else { { if _oper . index () == 1usize { let _res = _oper . recv (_oper1) ; { _sel } ; let _ = _res ; { return } } else { { { :: core :: panicking :: panic_fmt (format_args ! (\"internal error: entered unreachable code: {0}\" , format_args ! (\"internal error in crossbeam-channel: invalid case\"))) ; } } } } } } } } } } } } } } } ; let item = match try_item { Err (_) => return , Ok (item) => item , } ; let AudioRenderCapacityLoad { render_timestamp , load_value } = item ; counter += 1 ; load_sum += load_value ; peak_load = peak_load . max (load_value) ; if load_value > 1. { underrun_sum += 1 ; } if render_timestamp >= next_checkpoint { let event = AudioRenderCapacityEvent :: new (timestamp , load_sum / counter as f64 , peak_load , underrun_sum as f64 / counter as f64) ; let send_result = base_context . send_event (EventDispatch :: render_capacity (event)) ; if send_result . is_err () { break ; } next_checkpoint += options . update_interval ; timestamp = render_timestamp ; load_sum = 0. ; counter = 0 ; peak_load = 0. ; underrun_sum = 0 ; } }) ; } # [doc = \" Stop metric collection and analysis\"] # [allow (clippy :: missing_panics_doc)] pub fn stop (& self) { if let Some (stop_send) = self . stop_send . lock () . unwrap () . take () { let _ = stop_send . send (()) ; } } # [doc = \" The EventHandler for [`AudioRenderCapacityEvent`].\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] pub fn set_onupdate < F : FnMut (AudioRenderCapacityEvent) + Send + 'static > (& self , mut callback : F) { let callback = move | v | match v { EventPayload :: RenderCapacity (v) => callback (v) , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } ; self . context . set_event_handler (EventType :: RenderCapacity , EventHandler :: Multiple (Box :: new (callback))) ; } # [doc = \" Unset the EventHandler for [`AudioRenderCapacityEvent`].\"] pub fn clear_onupdate (& self) { self . context . clear_event_handler (EventType :: RenderCapacity) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: { any :: Any , ops :: Range } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use base :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use concrete_base :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use offline :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use online :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Destination node id is always at index 0\"] pub (crate) const DESTINATION_NODE_ID : AudioNodeId = AudioNodeId (0) ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" listener node id is always at index 1\"] const LISTENER_NODE_ID : AudioNodeId = AudioNodeId (1) ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" listener audio parameters ids are always at index 2 through 10\"] const LISTENER_PARAM_IDS : Range < u64 > = 2 .. 11 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" listener audio parameters ids are always at index 2 through 10\"] pub (crate) const LISTENER_AUDIO_PARAM_IDS : [AudioParamId ; 9] = [AudioParamId (2) , AudioParamId (3) , AudioParamId (4) , AudioParamId (5) , AudioParamId (6) , AudioParamId (7) , AudioParamId (8) , AudioParamId (9) , AudioParamId (10)] ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Unique identifier for audio nodes.\"] # [doc = \"\"] # [doc = \" Used for internal bookkeeping.\"] pub (crate) struct AudioNodeId (pub u64) ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: hash :: Hash for AudioNodeId { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . 0 , state) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for AudioNodeId { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for AudioNodeId { # [inline] fn eq (& self , other : & AudioNodeId) -> bool { self . 0 == other . 0 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for AudioNodeId { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < u64 > ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioNodeId { # [inline] fn clone (& self) -> AudioNodeId { let _ : :: core :: clone :: AssertParamIsClone < u64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AudioNodeId { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl std :: fmt :: Debug for AudioNodeId { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . write_fmt (format_args ! (\"AudioNodeId({0})\" , self . 0)) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Unique identifier for audio params.\"] # [doc = \"\"] # [doc = \" Store these in your `AudioProcessor` to get access to `AudioParam` values.\"] pub struct AudioParamId (u64) ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamId { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"AudioParamId\" , & & self . 0) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl From < & AudioParamId > for AudioNodeId { fn from (i : & AudioParamId) -> Self { Self (i . 0) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Describes the current state of the `AudioContext`\"] pub enum AudioContextState { # [doc = \" This context is currently suspended (context time is not proceeding,\"] # [doc = \" audio hardware may be powered down/released).\"] Suspended , # [doc = \" Audio is being processed.\"] Running , # [doc = \" This context has been released, and can no longer be used to process audio.\"] # [doc = \" All system audio resources have been released.\"] Closed , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioContextState { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { AudioContextState :: Suspended => \"Suspended\" , AudioContextState :: Running => \"Running\" , AudioContextState :: Closed => \"Closed\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AudioContextState { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioContextState { # [inline] fn clone (& self) -> AudioContextState { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for AudioContextState { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for AudioContextState { # [inline] fn eq (& self , other : & AudioContextState) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for AudioContextState { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl From < u8 > for AudioContextState { fn from (value : u8) -> Self { match value { 0 => Self :: Suspended , 1 => Self :: Running , 2 => Self :: Closed , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Handle of the [`AudioNode`](crate::node::AudioNode) to its associated [`BaseAudioContext`].\"] # [doc = \"\"] # [doc = \" Only when implementing the AudioNode trait manually, this struct is of any concern.\"] # [doc = \"\"] # [doc = \" This object allows for communication with the render thread and dynamic lifetime management.\"] pub struct AudioContextRegistration { # [doc = \" the audio context in which nodes and connections lives\"] context : ConcreteBaseAudioContext , # [doc = \" identify a specific `AudioNode`\"] id : AudioNodeId , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl std :: fmt :: Debug for AudioContextRegistration { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"AudioContextRegistration\") . field (\"id\" , & self . id) . field (\"context\" , & { let res = :: alloc :: fmt :: format (format_args ! (\"BaseAudioContext@{0}\" , self . context . address ())) ; res }) . finish () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioContextRegistration { # [doc = \" Get the audio node id of the registration\"] # [must_use] pub (crate) fn id (& self) -> AudioNodeId { self . id } # [doc = \" Get the [`BaseAudioContext`] concrete type associated with this `AudioContext`\"] # [must_use] pub (crate) fn context (& self) -> & ConcreteBaseAudioContext { & self . context } # [doc = \" Send a message to the corresponding audio processor of this node\"] # [doc = \"\"] # [doc = \" The message will be handled by\"] # [doc = \" [`AudioProcessor::onmessage`](crate::render::AudioProcessor::onmessage).\"] pub (crate) fn post_message < M : Any + Send + 'static > (& self , msg : M) { let wrapped = crate :: message :: ControlMessage :: NodeMessage { id : self . id , msg : llq :: Node :: new (Box :: new (msg)) , } ; self . context . send_control_msg (wrapped) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl Drop for AudioContextRegistration { fn drop (& mut self) { self . context . mark_node_dropped (self . id) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The interface representing an audio-processing graph built from audio modules linked together,\"] # [doc = \" each represented by an `AudioNode`.\"] # [doc = \"\"] # [doc = \" An audio context controls both the creation of the nodes it contains and the execution of the\"] # [doc = \" audio processing, or decoding.\"] # [allow (clippy :: module_name_repetitions)] pub trait BaseAudioContext { # [doc = \" Returns the [`BaseAudioContext`] concrete type associated with this `AudioContext`\"] # [doc (hidden)] fn base (& self) -> & ConcreteBaseAudioContext ; # [doc = \" Decode an [`AudioBuffer`] from a given input stream.\"] # [doc = \"\"] # [doc = \" The current implementation can decode FLAC, Opus, PCM, Vorbis, and Wav.\"] # [doc = \"\"] # [doc = \" In addition to the official spec, the input parameter can be any byte stream (not just an\"] # [doc = \" array). This means you can decode audio data from a file, network stream, or in memory\"] # [doc = \" buffer, and any other [`std::io::Read`] implementer. The data if buffered internally so you\"] # [doc = \" should not wrap the source in a `BufReader`.\"] # [doc = \"\"] # [doc = \" This function operates synchronously, which may be undesirable on the control thread. The\"] # [doc = \" example shows how to avoid this. An async version is currently not implemented.\"] # [doc = \"\"] # [doc = \" # Errors\"] # [doc = \"\"] # [doc = \" This method returns an Error in various cases (IO, mime sniffing, decoding).\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::io::Cursor;\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, OfflineAudioContext};\"] # [doc = \"\"] # [doc = \" let input = Cursor::new(vec![0; 32]); // or a File, TcpStream, ...\"] # [doc = \"\"] # [doc = \" let context = OfflineAudioContext::new(2, 44_100, 44_100.);\"] # [doc = \" let handle = std::thread::spawn(move || context.decode_audio_data_sync(input));\"] # [doc = \"\"] # [doc = \" // do other things\"] # [doc = \"\"] # [doc = \" // await result from the decoder thread\"] # [doc = \" let decode_buffer_result = handle.join();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" The following example shows how to use a thread pool for audio buffer decoding:\"] # [doc = \"\"] # [doc = \" `cargo run --release --example decode_multithreaded`\"] fn decode_audio_data_sync < R : std :: io :: Read + Send + Sync + 'static > (& self , input : R) -> Result < AudioBuffer , Box < dyn std :: error :: Error + Send + Sync > > { let mut buffer = MediaDecoder :: try_new (input) ? . collect :: < Result < Vec < _ > , _ > > () ? . into_iter () . reduce (| mut accum , item | { accum . extend (& item) ; accum }) . unwrap_or_else (| | AudioBuffer :: from (< [_] > :: into_vec (# [rustc_box] :: alloc :: boxed :: Box :: new ([:: alloc :: vec :: Vec :: new ()])) , self . sample_rate ())) ; buffer . resample (self . sample_rate ()) ; Ok (buffer) } # [doc = \" Create an new \\\"in-memory\\\" `AudioBuffer` with the given number of channels,\"] # [doc = \" length (i.e. number of samples per channel) and sample rate.\"] # [doc = \"\"] # [doc = \" Note: In most cases you will want the sample rate to match the current\"] # [doc = \" audio context sample rate.\"] # [must_use] fn create_buffer (& self , number_of_channels : usize , length : usize , sample_rate : f32) -> AudioBuffer { let options = AudioBufferOptions { number_of_channels , length , sample_rate , } ; AudioBuffer :: new (options) } # [doc = \" Creates a `AnalyserNode`\"] # [must_use] fn create_analyser (& self) -> node :: AnalyserNode { node :: AnalyserNode :: new (self . base () , node :: AnalyserOptions :: default ()) } # [doc = \" Creates an `BiquadFilterNode` which implements a second order filter\"] # [must_use] fn create_biquad_filter (& self) -> node :: BiquadFilterNode { node :: BiquadFilterNode :: new (self . base () , node :: BiquadFilterOptions :: default ()) } # [doc = \" Creates an `AudioBufferSourceNode`\"] # [must_use] fn create_buffer_source (& self) -> node :: AudioBufferSourceNode { node :: AudioBufferSourceNode :: new (self . base () , node :: AudioBufferSourceOptions :: default ()) } # [doc = \" Creates an `ConstantSourceNode`, a source representing a constant value\"] # [must_use] fn create_constant_source (& self) -> node :: ConstantSourceNode { node :: ConstantSourceNode :: new (self . base () , node :: ConstantSourceOptions :: default ()) } # [doc = \" Creates an `ConvolverNode`, a processing node which applies linear convolution\"] # [must_use] fn create_convolver (& self) -> node :: ConvolverNode { node :: ConvolverNode :: new (self . base () , node :: ConvolverOptions :: default ()) } # [doc = \" Creates a `ChannelMergerNode`\"] # [must_use] fn create_channel_merger (& self , number_of_inputs : usize) -> node :: ChannelMergerNode { let opts = node :: ChannelMergerOptions { number_of_inputs , .. node :: ChannelMergerOptions :: default () } ; node :: ChannelMergerNode :: new (self . base () , opts) } # [doc = \" Creates a `ChannelSplitterNode`\"] # [must_use] fn create_channel_splitter (& self , number_of_outputs : usize) -> node :: ChannelSplitterNode { let opts = node :: ChannelSplitterOptions { number_of_outputs , .. node :: ChannelSplitterOptions :: default () } ; node :: ChannelSplitterNode :: new (self . base () , opts) } # [doc = \" Creates a `DelayNode`, delaying the audio signal\"] # [must_use] fn create_delay (& self , max_delay_time : f64) -> node :: DelayNode { let opts = node :: DelayOptions { max_delay_time , .. node :: DelayOptions :: default () } ; node :: DelayNode :: new (self . base () , opts) } # [doc = \" Creates a `DynamicsCompressorNode`, compressing the audio signal\"] # [must_use] fn create_dynamics_compressor (& self) -> node :: DynamicsCompressorNode { node :: DynamicsCompressorNode :: new (self . base () , node :: DynamicsCompressorOptions :: default ()) } # [doc = \" Creates an `GainNode`, to control audio volume\"] # [must_use] fn create_gain (& self) -> node :: GainNode { node :: GainNode :: new (self . base () , node :: GainOptions :: default ()) } # [doc = \" Creates an `IirFilterNode`\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\"] # [doc = \" The maximum length of this array is 20\"] # [doc = \" * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\"] # [doc = \" The maximum length of this array is 20\"] # [must_use] fn create_iir_filter (& self , feedforward : Vec < f64 > , feedback : Vec < f64 >) -> node :: IIRFilterNode { let options = node :: IIRFilterOptions { audio_node_options : AudioNodeOptions :: default () , feedforward , feedback , } ; node :: IIRFilterNode :: new (self . base () , options) } # [doc = \" Creates an `OscillatorNode`, a source representing a periodic waveform.\"] # [must_use] fn create_oscillator (& self) -> node :: OscillatorNode { node :: OscillatorNode :: new (self . base () , node :: OscillatorOptions :: default ()) } # [doc = \" Creates a `PannerNode`\"] # [must_use] fn create_panner (& self) -> node :: PannerNode { node :: PannerNode :: new (self . base () , node :: PannerOptions :: default ()) } # [doc = \" Creates a periodic wave\"] # [doc = \"\"] # [doc = \" Please note that this constructor deviates slightly from the spec by requiring a single\"] # [doc = \" argument with the periodic wave options.\"] # [must_use] fn create_periodic_wave (& self , options : PeriodicWaveOptions) -> PeriodicWave { PeriodicWave :: new (self . base () , options) } # [doc = \" Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if:\"] # [doc = \" - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\"] # [doc = \" - the number of input and output channels are both zero\"] # [doc = \" - either of the channel counts exceed [`crate::MAX_CHANNELS`]\"] # [must_use] fn create_script_processor (& self , buffer_size : usize , number_of_input_channels : usize , number_of_output_channels : usize) -> node :: ScriptProcessorNode { let options = node :: ScriptProcessorOptions { buffer_size , number_of_input_channels , number_of_output_channels , } ; node :: ScriptProcessorNode :: new (self . base () , options) } # [doc = \" Creates an `StereoPannerNode` to pan a stereo output\"] # [must_use] fn create_stereo_panner (& self) -> node :: StereoPannerNode { node :: StereoPannerNode :: new (self . base () , node :: StereoPannerOptions :: default ()) } # [doc = \" Creates a `WaveShaperNode`\"] # [must_use] fn create_wave_shaper (& self) -> node :: WaveShaperNode { node :: WaveShaperNode :: new (self . base () , node :: WaveShaperOptions :: default ()) } # [doc = \" Returns an `AudioDestinationNode` representing the final destination of all audio in the\"] # [doc = \" context. It can be thought of as the audio-rendering device.\"] # [must_use] fn destination (& self) -> node :: AudioDestinationNode { let registration = AudioContextRegistration { id : DESTINATION_NODE_ID , context : self . base () . clone () , } ; let channel_config = self . base () . destination_channel_config () ; node :: AudioDestinationNode :: from_raw_parts (registration , channel_config) } # [doc = \" Returns the `AudioListener` which is used for 3D spatialization\"] # [must_use] fn listener (& self) -> AudioListener { self . base () . listener () } # [doc = \" The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\"] # [must_use] fn sample_rate (& self) -> f32 { self . base () . sample_rate () } # [doc = \" Returns state of current context\"] # [must_use] fn state (& self) -> AudioContextState { self . base () . state () } # [doc = \" This is the time in seconds of the sample frame immediately following the last sample-frame\"] # [doc = \" in the block of audio most recently processed by the context’s rendering graph.\"] # [must_use] fn current_time (& self) -> f64 { self . base () . current_time () } # [doc = \" Create an `AudioParam`.\"] # [doc = \"\"] # [doc = \" Call this inside the `register` closure when setting up your `AudioNode`\"] # [must_use] fn create_audio_param (& self , opts : AudioParamDescriptor , dest : & AudioContextRegistration) -> (crate :: param :: AudioParam , AudioParamId) { let param = self . base () . register (move | registration | { let (node , proc) = crate :: param :: audio_param_pair (opts , registration) ; (node , Box :: new (proc)) }) ; self . base () . queue_audio_param_connect (& param , dest . id ()) ; let proc_id = AudioParamId (param . registration () . id () . 0) ; (param , proc_id) } # [doc = \" Register callback to run when the state of the AudioContext has changed\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] fn set_onstatechange < F : FnMut (Event) + Send + 'static > (& self , mut callback : F) { let callback = move | _ | { callback (Event { type_ : \"statechange\" }) } ; self . base () . set_event_handler (EventType :: StateChange , EventHandler :: Multiple (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when the state of the AudioContext has changed\"] fn clear_onstatechange (& self) { self . base () . clear_event_handler (EventType :: StateChange) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The struct that corresponds to the Javascript `BaseAudioContext` object.\"] # [doc = \"\"] # [doc = \" This object is returned from the `base()` method on\"] # [doc = \" [`AudioContext`](crate::context::AudioContext) and\"] # [doc = \" [`OfflineAudioContext`](crate::context::OfflineAudioContext), and the `context()` method on\"] # [doc = \" `AudioNode`s.\"] # [doc = \"\"] # [doc = \" The `ConcreteBaseAudioContext` allows for shallow cloning (using an `Arc` internally).\"] # [allow (clippy :: module_name_repetitions)] # [doc (hidden)] pub struct ConcreteBaseAudioContext { inner : Arc < ConcreteBaseAudioContextInner > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The `OfflineAudioContext` doesn't render the audio to the device hardware; instead, it generates\"] # [doc = \" it, as fast as it can, and outputs the result to an `AudioBuffer`.\"] # [allow (clippy :: module_name_repetitions)] pub struct OfflineAudioContext { # [doc = \" represents the underlying `BaseAudioContext`\"] base : ConcreteBaseAudioContext , # [doc = \" the size of the buffer in sample-frames\"] length : usize , # [doc = \" actual renderer of the audio graph, can only be called once\"] renderer : Mutex < Option < OfflineAudioContextRenderer > > , # [doc = \" channel to notify resume actions on the rendering\"] resume_sender : mpsc :: Sender < () > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Identify the type of playback, which affects tradeoffs\"] # [doc = \" between audio output latency and power consumption\"] pub enum AudioContextLatencyCategory { # [doc = \" Balance audio output latency and power consumption.\"] Balanced , # [doc = \" Provide the lowest audio output latency possible without glitching. This is the default.\"] Interactive , # [doc = \" Prioritize sustained playback without interruption over audio output latency.\"] # [doc = \"\"] # [doc = \" Lowest power consumption.\"] Playback , # [doc = \" Specify the number of seconds of latency\"] # [doc = \"\"] # [doc = \" This latency is not guaranteed to be applied, it depends on the audio hardware capabilities\"] Custom (f64) , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [non_exhaustive] # [doc = \" This allows users to ask for a particular render quantum size.\"] # [doc = \"\"] # [doc = \" Currently, only the default value is available\"] pub enum AudioContextRenderSizeCategory { # [doc = \" The default value of 128 frames\"] Default , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Specify the playback configuration for the [`AudioContext`] constructor.\"] # [doc = \"\"] # [doc = \" All fields are optional and will default to the value best suited for interactive playback on\"] # [doc = \" your hardware configuration.\"] # [doc = \"\"] # [doc = \" For future compatibility, it is best to construct a default implementation of this struct and\"] # [doc = \" set the fields you would like to override:\"] # [doc = \" ```\"] # [doc = \" use web_audio_api::context::AudioContextOptions;\"] # [doc = \"\"] # [doc = \" // Request a sample rate of 44.1 kHz, leave other fields to their default values\"] # [doc = \" let opts = AudioContextOptions {\"] # [doc = \"     sample_rate: Some(44100.),\"] # [doc = \"     ..AudioContextOptions::default()\"] # [doc = \" };\"] pub struct AudioContextOptions { # [doc = \" Identify the type of playback, which affects tradeoffs between audio output latency and\"] # [doc = \" power consumption.\"] pub latency_hint : AudioContextLatencyCategory , # [doc = \" Sample rate of the audio context and audio output hardware. Use `None` for a default value.\"] pub sample_rate : Option < f32 > , # [doc = \" The audio output device\"] # [doc = \" - use `\\\"\\\"` for the default audio output device\"] # [doc = \" - use `\\\"none\\\"` to process the audio graph without playing through an audio output device.\"] # [doc = \" - use `\\\"sinkId\\\"` to use the specified audio sink id, obtained with [`enumerate_devices_sync`]\"] pub sink_id : String , # [doc = \" Option to request a default, optimized or specific render quantum size. It is a hint that might not be honored.\"] pub render_size_hint : AudioContextRenderSizeCategory , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" This interface represents an audio graph whose `AudioDestinationNode` is routed to a real-time\"] # [doc = \" output device that produces a signal directed at the user.\"] # [allow (clippy :: module_name_repetitions)] pub struct AudioContext { # [doc = \" represents the underlying `BaseAudioContext`\"] base : ConcreteBaseAudioContext , # [doc = \" audio backend (play/pause functionality)\"] backend_manager : Mutex < Box < dyn AudioBackendManager > > , # [doc = \" Provider for rendering performance metrics\"] render_capacity : AudioRenderCapacity , # [doc = \" Initializer for the render thread (when restart is required)\"] render_thread_init : RenderThreadInit , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: { AudioBuffer , AudioBufferOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioContextState , AudioParamId , ConcreteBaseAudioContext , DESTINATION_NODE_ID , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: decoding :: MediaDecoder ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { Event , EventHandler , EventType } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { AudioNode , AudioNodeOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: AudioParamDescriptor ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: periodic_wave :: { PeriodicWave , PeriodicWaveOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { node , AudioListener } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioContextState , AudioNodeId , BaseAudioContext , DESTINATION_NODE_ID , LISTENER_NODE_ID , LISTENER_PARAM_IDS , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { EventDispatch , EventHandler , EventLoop , EventType , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: message :: ControlMessage ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { AudioDestinationNode , AudioNode , AudioNodeOptions , ChannelConfig , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: AudioParam ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: AudioProcessor ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: spatial :: AudioListenerParams ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: AudioListener ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { SendError , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: collections :: HashSet ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: { AtomicU64 , AtomicU8 , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex , RwLock , RwLockWriteGuard } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNodeIdProvider { fn new (id_consumer : llq :: Consumer < AudioNodeId >) -> Self { Self { id_inc : AtomicU64 :: new (0) , id_consumer : Mutex :: new (id_consumer) , } } fn get (& self) -> AudioNodeId { if let Some (available_id) = self . id_consumer . lock () . unwrap () . pop () { llq :: Node :: into_inner (available_id) } else { AudioNodeId (self . id_inc . fetch_add (1 , Ordering :: Relaxed)) } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] # [allow (clippy :: module_name_repetitions)] impl :: core :: clone :: Clone for ConcreteBaseAudioContext { # [inline] fn clone (& self) -> ConcreteBaseAudioContext { ConcreteBaseAudioContext { inner : :: core :: clone :: Clone :: clone (& self . inner) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl PartialEq for ConcreteBaseAudioContext { fn eq (& self , other : & Self) -> bool { Arc :: ptr_eq (& self . inner , & other . inner) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for ConcreteBaseAudioContext { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"BaseAudioContext\") . field (\"id\" , & self . address ()) . field (\"state\" , & self . state ()) . field (\"sample_rate\" , & self . sample_rate ()) . field (\"current_time\" , & self . current_time ()) . field (\"max_channel_count\" , & self . max_channel_count ()) . field (\"offline\" , & self . offline ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl BaseAudioContext for ConcreteBaseAudioContext { fn base (& self) -> & ConcreteBaseAudioContext { self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::concrete_base",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ConcreteBaseAudioContext { # [doc = \" Creates a `BaseAudioContext` instance\"] # [allow (clippy :: too_many_arguments)] pub (super) fn new (sample_rate : f32 , max_channel_count : usize , state : Arc < AtomicU8 > , frames_played : Arc < AtomicU64 > , render_channel : Sender < ControlMessage > , event_send : Sender < EventDispatch > , event_loop : EventLoop , offline : bool , node_id_consumer : llq :: Consumer < AudioNodeId >) -> Self { let audio_node_id_provider = AudioNodeIdProvider :: new (node_id_consumer) ; let base_inner = ConcreteBaseAudioContextInner { sample_rate , max_channel_count , render_channel : RwLock :: new (render_channel) , queued_messages : Mutex :: new (Vec :: new ()) , audio_node_id_provider , destination_channel_config : AudioNodeOptions :: default () . into () , frames_played , queued_audio_listener_msgs : Mutex :: new (Vec :: new ()) , listener_params : None , offline , state , event_loop , event_send , connections : Mutex :: new (HashSet :: new ()) , } ; let base = Self { inner : Arc :: new (base_inner) } ; let initial_channel_count = if offline { max_channel_count } else { 2 . min (max_channel_count) } ; let (listener_params , destination_channel_config) = { let dest = AudioDestinationNode :: new (& base , initial_channel_count) ; let destination_channel_config = dest . into_channel_config () ; let listener = crate :: spatial :: AudioListenerNode :: new (& base) ; let listener_params = listener . into_fields () ; let AudioListener { position_x , position_y , position_z , forward_x , forward_y , forward_z , up_x , up_y , up_z } = listener_params ; let listener_params = AudioListenerParams { position_x : position_x . into_raw_parts () , position_y : position_y . into_raw_parts () , position_z : position_z . into_raw_parts () , forward_x : forward_x . into_raw_parts () , forward_y : forward_y . into_raw_parts () , forward_z : forward_z . into_raw_parts () , up_x : up_x . into_raw_parts () , up_y : up_y . into_raw_parts () , up_z : up_z . into_raw_parts () , } ; (listener_params , destination_channel_config) } ; let mut base = base ; let inner_mut = Arc :: get_mut (& mut base . inner) . unwrap () ; inner_mut . listener_params = Some (listener_params) ; inner_mut . destination_channel_config = destination_channel_config ; if true { match (& base . inner . audio_node_id_provider . id_inc . load (Ordering :: Relaxed) , & LISTENER_PARAM_IDS . end) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; } ; if ! offline { crate :: node :: load_hrtf_processor (sample_rate as u32) ; } base } pub (crate) fn address (& self) -> usize { Arc :: as_ptr (& self . inner) as usize } # [doc = \" Construct a new pair of [`AudioNode`] and [`AudioProcessor`]\"] pub (crate) fn register < T : AudioNode , F : FnOnce (AudioContextRegistration) -> (T , Box < dyn AudioProcessor >) > (& self , f : F) -> T { let id = self . inner . audio_node_id_provider . get () ; let registration = AudioContextRegistration { id , context : self . clone () } ; let (node , render) = (f) (registration) ; let message = ControlMessage :: RegisterNode { id , reclaim_id : llq :: Node :: new (id) , node : render , inputs : node . number_of_inputs () , outputs : node . number_of_outputs () , channel_config : node . channel_config () . inner () , } ; if id == LISTENER_NODE_ID || LISTENER_PARAM_IDS . contains (& id . 0) { let mut queued_audio_listener_msgs = self . inner . queued_audio_listener_msgs . lock () . unwrap () ; queued_audio_listener_msgs . push (message) ; } else { self . send_control_msg (message) ; self . resolve_queued_control_msgs (id) ; } node } # [doc = \" Send a control message to the render thread\"] # [doc = \"\"] # [doc = \" When the render thread is closed or crashed, the message is discarded and a log warning is\"] # [doc = \" emitted.\"] pub (crate) fn send_control_msg (& self , msg : ControlMessage) { if self . state () != AudioContextState :: Closed { let result = self . inner . render_channel . read () . unwrap () . send (msg) ; if result . is_err () { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Discarding control message - render thread is closed\") , lvl , & (\"web_audio_api::context::concrete_base\" , \"web_audio_api::context::concrete_base\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/concrete_base.rs\") , 277u32 , ()) ; } } ; } } } pub (crate) fn send_event (& self , msg : EventDispatch) -> Result < () , SendError < EventDispatch > > { self . inner . event_send . send (msg) } pub (crate) fn lock_control_msg_sender (& self) -> RwLockWriteGuard < '_ , Sender < ControlMessage > > { self . inner . render_channel . write () . unwrap () } pub (super) fn mark_node_dropped (& self , id : AudioNodeId) { if id == DESTINATION_NODE_ID || id == LISTENER_NODE_ID || LISTENER_PARAM_IDS . contains (& id . 0) { return ; } let message = ControlMessage :: ControlHandleDropped { id } ; self . send_control_msg (message) ; self . inner . connections . lock () . unwrap () . retain (| & (from , _output , to , _input) | from != id && to != id) ; } # [doc = \" Inform render thread that this node can act as a cycle breaker\"] # [doc (hidden)] pub fn mark_cycle_breaker (& self , reg : & AudioContextRegistration) { let id = reg . id () ; let message = ControlMessage :: MarkCycleBreaker { id } ; self . send_control_msg (message) ; } # [doc = \" `ChannelConfig` of the `AudioDestinationNode`\"] pub (super) fn destination_channel_config (& self) -> ChannelConfig { self . inner . destination_channel_config . clone () } # [doc = \" Returns the `AudioListener` which is used for 3D spatialization\"] pub (super) fn listener (& self) -> AudioListener { self . base () . ensure_audio_listener_present () ; let mut ids = LISTENER_PARAM_IDS . map (| i | AudioContextRegistration { id : AudioNodeId (i) , context : self . clone () , }) ; let params = self . inner . listener_params . as_ref () . unwrap () ; AudioListener { position_x : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . position_x . clone ()) , position_y : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . position_y . clone ()) , position_z : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . position_z . clone ()) , forward_x : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . forward_x . clone ()) , forward_y : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . forward_y . clone ()) , forward_z : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . forward_z . clone ()) , up_x : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . up_x . clone ()) , up_y : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . up_y . clone ()) , up_z : AudioParam :: from_raw_parts (ids . next () . unwrap () , params . up_z . clone ()) , } } # [doc = \" Returns state of current context\"] # [must_use] pub (super) fn state (& self) -> AudioContextState { self . inner . state . load (Ordering :: Acquire) . into () } # [doc = \" Updates state of current context\"] pub (super) fn set_state (& self , state : AudioContextState) { let current_state = self . state () ; if current_state != state { self . inner . state . store (state as u8 , Ordering :: Release) ; let _ = self . send_event (EventDispatch :: state_change (state)) ; } } # [doc = \" The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\"] # [must_use] pub (super) fn sample_rate (& self) -> f32 { self . inner . sample_rate } # [doc = \" This is the time in seconds of the sample frame immediately following the last sample-frame\"] # [doc = \" in the block of audio most recently processed by the context’s rendering graph.\"] # [must_use] # [allow (clippy :: cast_precision_loss)] pub (super) fn current_time (& self) -> f64 { self . inner . frames_played . load (Ordering :: SeqCst) as f64 / self . inner . sample_rate as f64 } # [doc = \" Maximum available channels for the audio destination\"] # [must_use] pub (crate) fn max_channel_count (& self) -> usize { self . inner . max_channel_count } # [doc = \" Release queued control messages to the render thread that were blocking on the availability\"] # [doc = \" of the Node with the given `id`\"] fn resolve_queued_control_msgs (& self , id : AudioNodeId) { let mut queued = self . inner . queued_messages . lock () . unwrap () ; let mut i = 0 ; while i < queued . len () { if match & queued [i] { ControlMessage :: ConnectNode { to , .. } if * to == id => true , _ => false , } { let m = queued . remove (i) ; self . send_control_msg (m) ; } else { i += 1 ; } } } # [doc = \" Connects the output of the `from` audio node to the input of the `to` audio node\"] pub (crate) fn connect (& self , from : AudioNodeId , to : AudioNodeId , output : usize , input : usize) { self . inner . connections . lock () . unwrap () . insert ((from , output , to , input)) ; let message = ControlMessage :: ConnectNode { from , to , output , input } ; self . send_control_msg (message) ; } # [doc = \" Schedule a connection of an `AudioParam` to the `AudioNode` it belongs to\"] # [doc = \"\"] # [doc = \" It is not performed immediately as the `AudioNode` is not registered at this point.\"] pub (super) fn queue_audio_param_connect (& self , param : & AudioParam , audio_node : AudioNodeId) { let message = ControlMessage :: ConnectNode { from : param . registration () . id () , to : audio_node , output : 0 , input : usize :: MAX , } ; self . inner . queued_messages . lock () . unwrap () . push (message) ; } # [doc = \" Disconnects outputs of the audio node, possibly filtered by output node, input, output.\"] pub (crate) fn disconnect (& self , from : AudioNodeId , output : Option < usize > , to : Option < AudioNodeId > , input : Option < usize >) { let mut has_disconnected = false ; let mut connections = self . inner . connections . lock () . unwrap () ; connections . retain (| & (c_from , c_output , c_to , c_input) | { let retain = c_from != from || c_output != output . unwrap_or (c_output) || c_to != to . unwrap_or (c_to) || c_input != input . unwrap_or (c_input) ; if ! retain { has_disconnected = true ; let message = ControlMessage :: DisconnectNode { from , to : c_to , input : c_input , output : c_output , } ; self . send_control_msg (message) ; } retain }) ; drop (connections) ; if ! has_disconnected && to . is_some () { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - attempting to disconnect unconnected nodes\")) ; } ; } } # [doc = \" Connect the `AudioListener` to a `PannerNode`\"] pub (crate) fn connect_listener_to_panner (& self , panner : AudioNodeId) { self . connect (LISTENER_NODE_ID , panner , 0 , usize :: MAX) ; } # [doc = \" Add the [`AudioListener`] to the audio graph (if not already)\"] pub (crate) fn ensure_audio_listener_present (& self) { let mut queued_audio_listener_msgs = self . inner . queued_audio_listener_msgs . lock () . unwrap () ; let mut released = false ; while let Some (message) = queued_audio_listener_msgs . pop () { self . send_control_msg (message) ; released = true ; } if released { self . resolve_queued_control_msgs (LISTENER_NODE_ID) ; self . connect (LISTENER_NODE_ID , DESTINATION_NODE_ID , 0 , usize :: MAX) ; } } # [doc = \" Returns true if this is `OfflineAudioContext` (false when it is an `AudioContext`)\"] pub (crate) fn offline (& self) -> bool { self . inner . offline } pub (crate) fn set_event_handler (& self , event : EventType , callback : EventHandler) { self . inner . event_loop . set_handler (event , callback) ; } pub (crate) fn clear_event_handler (& self , event : EventType) { self . inner . event_loop . clear_handler (event) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: { AtomicU64 , AtomicU8 } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextState , BaseAudioContext , ConcreteBaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { Event , EventDispatch , EventHandler , EventPayload , EventType , OfflineAudioCompletionEvent , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: RenderThread ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { assert_valid_buffer_length , assert_valid_number_of_channels , assert_valid_sample_rate , RENDER_QUANTUM_SIZE , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: EventLoop ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use futures_channel :: { mpsc , oneshot } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use futures_util :: SinkExt as _ ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for OfflineAudioContext { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"OfflineAudioContext\") . field (\"length\" , & self . length ()) . field (\"base\" , & self . base ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl BaseAudioContext for OfflineAudioContext { fn base (& self) -> & ConcreteBaseAudioContext { & self . base } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::offline",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl OfflineAudioContext { # [doc = \" Creates an `OfflineAudioContext` instance\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `channels` - number of output channels to render\"] # [doc = \" * `length` - length of the rendering audio buffer\"] # [doc = \" * `sample_rate` - output sample rate\"] # [must_use] # [allow (clippy :: missing_panics_doc)] pub fn new (number_of_channels : usize , length : usize , sample_rate : f32) -> Self { assert_valid_number_of_channels (number_of_channels) ; assert_valid_buffer_length (length) ; assert_valid_sample_rate (sample_rate) ; let (sender , receiver) = crossbeam_channel :: unbounded () ; let (node_id_producer , node_id_consumer) = llq :: Queue :: new () . split () ; let graph = crate :: render :: graph :: Graph :: new (node_id_producer) ; let message = crate :: message :: ControlMessage :: Startup { graph } ; sender . send (message) . unwrap () ; let frames_played = Arc :: new (AtomicU64 :: new (0)) ; let frames_played_clone = Arc :: clone (& frames_played) ; let state = Arc :: new (AtomicU8 :: new (AudioContextState :: Suspended as u8)) ; let state_clone = Arc :: clone (& state) ; let (event_send , event_recv) = crossbeam_channel :: unbounded () ; let event_loop = EventLoop :: new (event_recv) ; let renderer = RenderThread :: new (sample_rate , number_of_channels , receiver , state_clone , frames_played_clone , event_send . clone ()) ; let base = ConcreteBaseAudioContext :: new (sample_rate , number_of_channels , state , frames_played , sender , event_send , event_loop . clone () , true , node_id_consumer) ; let (resume_sender , resume_receiver) = mpsc :: channel (0) ; let renderer = OfflineAudioContextRenderer { renderer , suspend_promises : Vec :: new () , suspend_callbacks : Vec :: new () , resume_receiver , event_loop , } ; Self { base , length , renderer : Mutex :: new (Some (renderer)) , resume_sender , } } # [doc = \" Given the current connections and scheduled changes, starts rendering audio.\"] # [doc = \"\"] # [doc = \" This function will block the current thread and returns the rendered `AudioBuffer`\"] # [doc = \" synchronously.\"] # [doc = \"\"] # [doc = \" This method will only adhere to scheduled suspensions via [`Self::suspend_sync`] and\"] # [doc = \" will ignore those provided via [`Self::suspend`].\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if this method is called multiple times\"] # [must_use] pub fn start_rendering_sync (& mut self) -> AudioBuffer { let renderer = self . renderer . lock () . unwrap () . take () . expect (\"InvalidStateError - Cannot call `startRendering` twice\") ; let OfflineAudioContextRenderer { renderer , suspend_callbacks , event_loop , .. } = renderer ; self . base . set_state (AudioContextState :: Running) ; let result = renderer . render_audiobuffer_sync (self , suspend_callbacks , & event_loop) ; self . base . set_state (AudioContextState :: Closed) ; let _ = self . base . send_event (EventDispatch :: complete (result . clone ())) ; event_loop . handle_pending_events () ; result } # [doc = \" Given the current connections and scheduled changes, starts rendering audio.\"] # [doc = \"\"] # [doc = \" Rendering is purely CPU bound and contains no `await` points, so calling this method will\"] # [doc = \" block the executor until completion or until the context is suspended.\"] # [doc = \"\"] # [doc = \" This method will only adhere to scheduled suspensions via [`Self::suspend`] and will\"] # [doc = \" ignore those provided via [`Self::suspend_sync`].\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if this method is called multiple times.\"] pub async fn start_rendering (& self) -> AudioBuffer { let renderer = self . renderer . lock () . unwrap () . take () . expect (\"InvalidStateError - Cannot call `startRendering` twice\") ; let OfflineAudioContextRenderer { renderer , suspend_promises , resume_receiver , event_loop , .. } = renderer ; self . base . set_state (AudioContextState :: Running) ; let result = renderer . render_audiobuffer (self . length , suspend_promises , resume_receiver , & event_loop) . await ; self . base . set_state (AudioContextState :: Closed) ; let _ = self . base . send_event (EventDispatch :: complete (result . clone ())) ; event_loop . handle_pending_events () ; result } # [doc = \" get the length of rendering audio buffer\"] # [allow (clippy :: missing_const_for_fn , clippy :: unused_self)] # [must_use] pub fn length (& self) -> usize { self . length } # [track_caller] fn calculate_suspend_frame (& self , suspend_time : f64) -> usize { if ! (suspend_time >= 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError: suspendTime cannot be negative\")) ; } } ; if ! (suspend_time < self . length as f64 / self . sample_rate () as f64) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError: suspendTime cannot be greater than or equal to the total render duration\")) ; } } ; (suspend_time * self . base . sample_rate () as f64 / RENDER_QUANTUM_SIZE as f64) . ceil () as usize } # [doc = \" Schedules a suspension of the time progression in the audio context at the specified time\"] # [doc = \" and returns a promise\"] # [doc = \"\"] # [doc = \" The specified time is quantized and rounded up to the render quantum size.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the quantized frame number\"] # [doc = \"\"] # [doc = \" - is negative or\"] # [doc = \" - is less than or equal to the current time or\"] # [doc = \" - is greater than or equal to the total render duration or\"] # [doc = \" - is scheduled by another suspend for the same time\"] # [doc = \"\"] # [doc = \" # Example usage\"] # [doc = \"\"] # [doc = \" ```rust\"] # [doc = \" use futures::{executor, join};\"] # [doc = \" use futures::FutureExt as _;\"] # [doc = \" use std::sync::Arc;\"] # [doc = \"\"] # [doc = \" use web_audio_api::context::BaseAudioContext;\"] # [doc = \" use web_audio_api::context::OfflineAudioContext;\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = Arc::new(OfflineAudioContext::new(1, 512, 44_100.));\"] # [doc = \" let context_clone = Arc::clone(&context);\"] # [doc = \"\"] # [doc = \" let suspend_promise = context.suspend(128. / 44_100.).then(|_| async move {\"] # [doc = \"     let mut src = context_clone.create_constant_source();\"] # [doc = \"     src.connect(&context_clone.destination());\"] # [doc = \"     src.start();\"] # [doc = \"     context_clone.resume().await;\"] # [doc = \" });\"] # [doc = \"\"] # [doc = \" let render_promise = context.start_rendering();\"] # [doc = \"\"] # [doc = \" let buffer = executor::block_on(async move { join!(suspend_promise, render_promise).1 });\"] # [doc = \" assert_eq!(buffer.number_of_channels(), 1);\"] # [doc = \" assert_eq!(buffer.length(), 512);\"] # [doc = \" ```\"] pub async fn suspend (& self , suspend_time : f64) { let quantum = self . calculate_suspend_frame (suspend_time) ; let (sender , receiver) = oneshot :: channel () ; { let mut lock = self . renderer . lock () . unwrap () ; let renderer = lock . as_mut () . expect (\"InvalidStateError - cannot suspend when rendering has already started\") ; let insert_pos = renderer . suspend_promises . binary_search_by_key (& quantum , | & (q , _) | q) . expect_err (\"InvalidStateError - cannot suspend multiple times at the same render quantum\") ; renderer . suspend_promises . insert (insert_pos , (quantum , sender)) ; } receiver . await . unwrap () ; self . base () . set_state (AudioContextState :: Suspended) ; } # [doc = \" Schedules a suspension of the time progression in the audio context at the specified time\"] # [doc = \" and runs a callback.\"] # [doc = \"\"] # [doc = \" This is a synchronous version of [`Self::suspend`] that runs the provided callback at\"] # [doc = \" the `suspendTime`. The rendering resumes automatically after the callback has run, so there\"] # [doc = \" is no `resume_sync` method.\"] # [doc = \"\"] # [doc = \" The specified time is quantized and rounded up to the render quantum size.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the quantized frame number\"] # [doc = \"\"] # [doc = \" - is negative or\"] # [doc = \" - is less than or equal to the current time or\"] # [doc = \" - is greater than or equal to the total render duration or\"] # [doc = \" - is scheduled by another suspend for the same time\"] # [doc = \"\"] # [doc = \" # Example usage\"] # [doc = \"\"] # [doc = \" ```rust\"] # [doc = \" use web_audio_api::context::BaseAudioContext;\"] # [doc = \" use web_audio_api::context::OfflineAudioContext;\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let mut context = OfflineAudioContext::new(1, 512, 44_100.);\"] # [doc = \"\"] # [doc = \" context.suspend_sync(128. / 44_100., |context| {\"] # [doc = \"     let mut src = context.create_constant_source();\"] # [doc = \"     src.connect(&context.destination());\"] # [doc = \"     src.start();\"] # [doc = \" });\"] # [doc = \"\"] # [doc = \" let buffer = context.start_rendering_sync();\"] # [doc = \" assert_eq!(buffer.number_of_channels(), 1);\"] # [doc = \" assert_eq!(buffer.length(), 512);\"] # [doc = \" ```\"] pub fn suspend_sync < F : FnOnce (& mut Self) + Send + Sync + 'static > (& mut self , suspend_time : f64 , callback : F) { let quantum = self . calculate_suspend_frame (suspend_time) ; let mut lock = self . renderer . lock () . unwrap () ; let renderer = lock . as_mut () . expect (\"InvalidStateError - cannot suspend when rendering has already started\") ; let insert_pos = renderer . suspend_callbacks . binary_search_by_key (& quantum , | (q , _c) | * q) . expect_err (\"InvalidStateError - cannot suspend multiple times at the same render quantum\") ; let boxed_callback = Box :: new (| ctx : & mut OfflineAudioContext | { ctx . base () . set_state (AudioContextState :: Suspended) ; (callback) (ctx) ; ctx . base () . set_state (AudioContextState :: Running) ; }) ; renderer . suspend_callbacks . insert (insert_pos , (quantum , boxed_callback)) ; } # [doc = \" Resumes the progression of the OfflineAudioContext's currentTime when it has been suspended\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics when the context is closed or rendering has not started\"] pub async fn resume (& self) { self . base () . set_state (AudioContextState :: Running) ; self . resume_sender . clone () . send (()) . await . unwrap () } # [doc = \" Register callback to run when the rendering has completed\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] # [allow (clippy :: missing_panics_doc)] pub fn set_oncomplete < F : FnOnce (OfflineAudioCompletionEvent) + Send + 'static > (& self , callback : F) { let callback = move | v | match v { EventPayload :: Complete (v) => { let event = OfflineAudioCompletionEvent { rendered_buffer : v , event : Event { type_ : \"complete\" } , } ; callback (event) } _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } ; self . base () . set_event_handler (EventType :: Complete , EventHandler :: Once (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when the rendering has completed\"] pub fn clear_oncomplete (& self) { self . base () . clear_event_handler (EventType :: Complete) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Mutex ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextState , BaseAudioContext , ConcreteBaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { EventDispatch , EventHandler , EventLoop , EventPayload , EventType , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: io :: { self , AudioBackendManager , ControlThreadInit , NoneBackend , RenderThreadInit , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_devices :: { enumerate_devices_sync , MediaDeviceInfoKind , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_streams :: { MediaStream , MediaStreamTrack } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: message :: { ControlMessage , OneshotNotify } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { self , AudioNodeOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: graph :: Graph ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: MediaElement ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AudioRenderCapacity , Event } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use futures_channel :: oneshot ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AudioContextLatencyCategory { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioContextLatencyCategory { # [inline] fn clone (& self) -> AudioContextLatencyCategory { let _ : :: core :: clone :: AssertParamIsClone < f64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioContextLatencyCategory { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { AudioContextLatencyCategory :: Balanced => :: core :: fmt :: Formatter :: write_str (f , \"Balanced\") , AudioContextLatencyCategory :: Interactive => :: core :: fmt :: Formatter :: write_str (f , \"Interactive\") , AudioContextLatencyCategory :: Playback => :: core :: fmt :: Formatter :: write_str (f , \"Playback\") , AudioContextLatencyCategory :: Custom (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Custom\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioContextLatencyCategory { fn default () -> Self { Self :: Interactive } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AudioContextRenderSizeCategory { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioContextRenderSizeCategory { # [inline] fn clone (& self) -> AudioContextRenderSizeCategory { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioContextRenderSizeCategory { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , \"Default\") } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioContextRenderSizeCategory { fn default () -> Self { Self :: Default } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioContextOptions { # [inline] fn clone (& self) -> AudioContextOptions { AudioContextOptions { latency_hint : :: core :: clone :: Clone :: clone (& self . latency_hint) , sample_rate : :: core :: clone :: Clone :: clone (& self . sample_rate) , sink_id : :: core :: clone :: Clone :: clone (& self . sink_id) , render_size_hint : :: core :: clone :: Clone :: clone (& self . render_size_hint) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioContextOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"AudioContextOptions\" , \"latency_hint\" , & self . latency_hint , \"sample_rate\" , & self . sample_rate , \"sink_id\" , & self . sink_id , \"render_size_hint\" , & & self . render_size_hint) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for AudioContextOptions { # [inline] fn default () -> AudioContextOptions { AudioContextOptions { latency_hint : :: core :: default :: Default :: default () , sample_rate : :: core :: default :: Default :: default () , sink_id : :: core :: default :: Default :: default () , render_size_hint : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for AudioContext { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"AudioContext\") . field (\"sink_id\" , & self . sink_id ()) . field (\"base_latency\" , & self . base_latency ()) . field (\"output_latency\" , & self . output_latency ()) . field (\"base\" , & self . base ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Drop for AudioContext { fn drop (& mut self) { if self . state () == AudioContextState :: Running { let tombstone = Box :: new (NoneBackend :: void ()) ; let original = std :: mem :: replace (self . backend_manager . get_mut () . unwrap () , tombstone) ; Box :: leak (original) ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl BaseAudioContext for AudioContext { fn base (& self) -> & ConcreteBaseAudioContext { & self . base } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioContext { fn default () -> Self { Self :: new (AudioContextOptions :: default ()) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::context::online",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioContext { # [doc = \" Creates and returns a new `AudioContext` object.\"] # [doc = \"\"] # [doc = \" This will play live audio on the default output device.\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{AudioContext, AudioContextOptions};\"] # [doc = \"\"] # [doc = \" // Request a sample rate of 44.1 kHz and default latency (buffer size 128, if available)\"] # [doc = \" let opts = AudioContextOptions {\"] # [doc = \"     sample_rate: Some(44100.),\"] # [doc = \"     ..AudioContextOptions::default()\"] # [doc = \" };\"] # [doc = \"\"] # [doc = \" // Setup the audio context that will emit to your speakers\"] # [doc = \" let context = AudioContext::new(opts);\"] # [doc = \"\"] # [doc = \" // Alternatively, use the default constructor to get the best settings for your hardware\"] # [doc = \" // let context = AudioContext::default();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" The `AudioContext` constructor will panic when an invalid `sinkId` is provided in the\"] # [doc = \" `AudioContextOptions`. In a future version, a `try_new` constructor will be introduced that\"] # [doc = \" never panics.\"] # [allow (clippy :: needless_pass_by_value)] # [must_use] pub fn new (mut options : AudioContextOptions) -> Self { if ! is_valid_sink_id (& options . sink_id) { { let lvl = :: log :: Level :: Error ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"NotFoundError: invalid sinkId {0:?}\" , options . sink_id) , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 186u32 , ()) ; } } ; options . sink_id = String :: from (\"\") ; } let (control_thread_init , render_thread_init) = io :: thread_init () ; let backend = io :: build_output (options , render_thread_init . clone ()) ; let ControlThreadInit { state , frames_played , ctrl_msg_send , load_value_recv , event_send , event_recv } = control_thread_init ; let (node_id_producer , node_id_consumer) = llq :: Queue :: new () . split () ; let graph = Graph :: new (node_id_producer) ; let message = ControlMessage :: Startup { graph } ; ctrl_msg_send . send (message) . unwrap () ; let event_loop = EventLoop :: new (event_recv) ; let base = ConcreteBaseAudioContext :: new (backend . sample_rate () , backend . number_of_channels () , state , frames_played , ctrl_msg_send , event_send , event_loop . clone () , false , node_id_consumer) ; let base_clone = base . clone () ; let render_capacity = AudioRenderCapacity :: new (base_clone , load_value_recv) ; event_loop . run_in_thread () ; Self { base , backend_manager : Mutex :: new (backend) , render_capacity , render_thread_init , } } # [doc = \" This represents the number of seconds of processing latency incurred by\"] # [doc = \" the `AudioContext` passing the audio from the `AudioDestinationNode`\"] # [doc = \" to the audio subsystem.\"] # [allow (clippy :: unused_self)] # [must_use] pub fn base_latency (& self) -> f64 { 0. } # [doc = \" The estimation in seconds of audio output latency, i.e., the interval\"] # [doc = \" between the time the UA requests the host system to play a buffer and\"] # [doc = \" the time at which the first sample in the buffer is actually processed\"] # [doc = \" by the audio output device.\"] # [must_use] # [allow (clippy :: missing_panics_doc)] pub fn output_latency (& self) -> f64 { self . backend_manager . lock () . unwrap () . output_latency () } # [doc = \" Identifier or the information of the current audio output device.\"] # [doc = \"\"] # [doc = \" The initial value is `\\\"\\\"`, which means the default audio output device.\"] # [allow (clippy :: missing_panics_doc)] pub fn sink_id (& self) -> String { self . backend_manager . lock () . unwrap () . sink_id () . to_owned () } # [doc = \" Update the current audio output device.\"] # [doc = \"\"] # [doc = \" The provided `sink_id` string must match a device name `enumerate_devices_sync`.\"] # [doc = \"\"] # [doc = \" Supplying `\\\"none\\\"` for the `sink_id` will process the audio graph without playing through an\"] # [doc = \" audio output device.\"] # [doc = \"\"] # [doc = \" This function operates synchronously and might block the current thread. An async version\"] # [doc = \" is currently not implemented.\"] # [allow (clippy :: needless_collect , clippy :: missing_panics_doc)] pub fn set_sink_id_sync (& self , sink_id : String) -> Result < () , Box < dyn Error > > { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange requested\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 282u32 , ()) ; } } ; if self . sink_id () == sink_id { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: no-op\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 284u32 , ()) ; } } ; return Ok (()) ; } if ! is_valid_sink_id (& sink_id) { Err ({ let res = :: alloc :: fmt :: format (format_args ! (\"NotFoundError: invalid sinkId {0}\" , sink_id)) ; res }) ? ; } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: locking backend manager\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 292u32 , ()) ; } } ; let mut backend_manager_guard = self . backend_manager . lock () . unwrap () ; let original_state = self . state () ; if original_state == AudioContextState :: Closed { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: context is closed\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 296u32 , ()) ; } } ; return Ok (()) ; } { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: locking message channel\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 301u32 , ()) ; } } ; let ctrl_msg_send = self . base . lock_control_msg_sender () ; let mut pending_msgs : Vec < _ > = self . render_thread_init . ctrl_msg_recv . try_iter () . collect () ; let graph = if match pending_msgs . first () { Some (ControlMessage :: Startup { .. }) => true , _ => false , } { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: recover unstarted graph\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 311u32 , ()) ; } } ; let msg = pending_msgs . remove (0) ; match msg { ControlMessage :: Startup { graph } => graph , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } else { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: recover graph from render thread\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 320u32 , ()) ; } } ; let (graph_send , graph_recv) = crossbeam_channel :: bounded (1) ; let message = ControlMessage :: CloseAndRecycle { sender : graph_send } ; ctrl_msg_send . send (message) . unwrap () ; if original_state == AudioContextState :: Suspended { backend_manager_guard . resume () ; } graph_recv . recv () . unwrap () } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: closing audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 333u32 , ()) ; } } ; backend_manager_guard . close () ; let options = AudioContextOptions { sample_rate : Some (self . sample_rate ()) , latency_hint : AudioContextLatencyCategory :: default () , sink_id , render_size_hint : AudioContextRenderSizeCategory :: default () , } ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: starting audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 343u32 , ()) ; } } ; * backend_manager_guard = io :: build_output (options , self . render_thread_init . clone ()) ; if original_state == AudioContextState :: Suspended { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: suspending audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 348u32 , ()) ; } } ; backend_manager_guard . suspend () ; } let message = ControlMessage :: Startup { graph } ; ctrl_msg_send . send (message) . unwrap () ; pending_msgs . into_iter () . for_each (| m | self . base () . send_control_msg (m)) ; drop (backend_manager_guard) ; let _ = self . base . send_event (EventDispatch :: sink_change ()) ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"SinkChange: done\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 367u32 , ()) ; } } ; Ok (()) } # [doc = \" Register callback to run when the audio sink has changed\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] pub fn set_onsinkchange < F : FnMut (Event) + Send + 'static > (& self , mut callback : F) { let callback = move | _ | { callback (Event { type_ : \"sinkchange\" }) } ; self . base () . set_event_handler (EventType :: SinkChange , EventHandler :: Multiple (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when the audio sink has changed\"] pub fn clear_onsinkchange (& self) { self . base () . clear_event_handler (EventType :: SinkChange) ; } # [allow (clippy :: missing_panics_doc)] # [doc (hidden)] pub fn run_diagnostics < F : Fn (String) + Send + 'static > (& self , callback : F) { let mut buffer = Vec :: with_capacity (32 * 1024) ; { let backend = self . backend_manager . lock () . unwrap () ; use std :: io :: Write ; (& mut buffer) . write_fmt (format_args ! (\"backend: {0}\\n\" , backend . name ())) . ok () ; (& mut buffer) . write_fmt (format_args ! (\"sink id: {0}\\n\" , backend . sink_id ())) . ok () ; (& mut buffer) . write_fmt (format_args ! (\"output latency: {0:.6}\\n\" , backend . output_latency ())) . ok () ; } let callback = move | v | match v { EventPayload :: Diagnostics (v) => { let s = String :: from_utf8 (v) . unwrap () ; callback (s) ; } _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } ; self . base () . set_event_handler (EventType :: Diagnostics , EventHandler :: Once (Box :: new (callback))) ; self . base () . send_control_msg (ControlMessage :: RunDiagnostics { buffer , }) ; } # [doc = \" Suspends the progression of time in the audio context.\"] # [doc = \"\"] # [doc = \" This will temporarily halt audio hardware access and reducing CPU/battery usage in the\"] # [doc = \" process.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * The audio device is not available\"] # [doc = \" * For a `BackendSpecificError`\"] pub async fn suspend (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspend called\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 439u32 , ()) ; } } ; if self . state () != AudioContextState :: Running { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspend no-op - context is not running\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 442u32 , ()) ; } } ; return ; } let (sender , receiver) = oneshot :: channel () ; let notify = OneshotNotify :: Async (sender) ; self . base . send_control_msg (ControlMessage :: Suspend { notify , }) ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspending audio graph, waiting for signal..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 454u32 , ()) ; } } ; receiver . await . unwrap () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspended audio graph. Suspending audio stream..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 458u32 , ()) ; } } ; self . backend_manager . lock () . unwrap () . suspend () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspended audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 461u32 , ()) ; } } ; } # [doc = \" Resumes the progression of time in an audio context that has previously been\"] # [doc = \" suspended/paused.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * The audio device is not available\"] # [doc = \" * For a `BackendSpecificError`\"] # [allow (clippy :: await_holding_lock)] pub async fn resume (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resume called, locking backend manager\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 476u32 , ()) ; } } ; let backend_manager_guard = self . backend_manager . lock () . unwrap () ; if self . state () != AudioContextState :: Suspended { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resume no-op - context is not suspended\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 480u32 , ()) ; } } ; return ; } backend_manager_guard . resume () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resumed audio stream, waking audio graph\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 488u32 , ()) ; } } ; let (sender , receiver) = oneshot :: channel () ; let notify = OneshotNotify :: Async (sender) ; self . base . send_control_msg (ControlMessage :: Resume { notify }) ; drop (backend_manager_guard) ; receiver . await . unwrap () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resumed audio graph\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 500u32 , ()) ; } } ; } # [doc = \" Closes the `AudioContext`, releasing the system resources being used.\"] # [doc = \"\"] # [doc = \" This will not automatically release all `AudioContext`-created objects, but will suspend\"] # [doc = \" the progression of the currentTime, and stop processing audio data.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic when this function is called multiple times\"] pub async fn close (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Close called\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 513u32 , ()) ; } } ; if self . state () == AudioContextState :: Closed { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Close no-op - context is already closed\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 516u32 , ()) ; } } ; return ; } if self . state () == AudioContextState :: Running { let (sender , receiver) = oneshot :: channel () ; let notify = OneshotNotify :: Async (sender) ; self . base . send_control_msg (ControlMessage :: Close { notify , }) ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspending audio graph, waiting for signal..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 528u32 , ()) ; } } ; receiver . await . unwrap () ; } else { self . base . set_state (AudioContextState :: Closed) ; } { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspended audio graph. Closing audio stream..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 536u32 , ()) ; } } ; self . backend_manager . lock () . unwrap () . close () ; self . render_capacity . stop () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Closed audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 542u32 , ()) ; } } ; } # [doc = \" Suspends the progression of time in the audio context.\"] # [doc = \"\"] # [doc = \" This will temporarily halt audio hardware access and reducing CPU/battery usage in the\"] # [doc = \" process.\"] # [doc = \"\"] # [doc = \" This function operates synchronously and blocks the current thread until the audio thread\"] # [doc = \" has stopped processing.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * The audio device is not available\"] # [doc = \" * For a `BackendSpecificError`\"] pub fn suspend_sync (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspend_sync called, locking backend manager\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 561u32 , ()) ; } } ; let backend_manager_guard = self . backend_manager . lock () . unwrap () ; if self . state () != AudioContextState :: Running { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspend_sync no-op - context is not running\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 565u32 , ()) ; } } ; return ; } let (sender , receiver) = crossbeam_channel :: bounded (0) ; let notify = OneshotNotify :: Sync (sender) ; self . base . send_control_msg (ControlMessage :: Suspend { notify , }) ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspending audio graph, waiting for signal..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 577u32 , ()) ; } } ; receiver . recv () . ok () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspended audio graph. Suspending audio stream..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 581u32 , ()) ; } } ; backend_manager_guard . suspend () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspended audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 584u32 , ()) ; } } ; } # [doc = \" Resumes the progression of time in an audio context that has previously been\"] # [doc = \" suspended/paused.\"] # [doc = \"\"] # [doc = \" This function operates synchronously and blocks the current thread until the audio thread\"] # [doc = \" has started processing again.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * The audio device is not available\"] # [doc = \" * For a `BackendSpecificError`\"] pub fn resume_sync (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resume_sync called, locking backend manager\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 601u32 , ()) ; } } ; let backend_manager_guard = self . backend_manager . lock () . unwrap () ; if self . state () != AudioContextState :: Suspended { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resume no-op - context is not suspended\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 605u32 , ()) ; } } ; return ; } backend_manager_guard . resume () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resumed audio stream, waking audio graph\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 613u32 , ()) ; } } ; let (sender , receiver) = crossbeam_channel :: bounded (0) ; let notify = OneshotNotify :: Sync (sender) ; self . base . send_control_msg (ControlMessage :: Resume { notify }) ; receiver . recv () . ok () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Resumed audio graph\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 622u32 , ()) ; } } ; } # [doc = \" Closes the `AudioContext`, releasing the system resources being used.\"] # [doc = \"\"] # [doc = \" This will not automatically release all `AudioContext`-created objects, but will suspend\"] # [doc = \" the progression of the currentTime, and stop processing audio data.\"] # [doc = \"\"] # [doc = \" This function operates synchronously and blocks the current thread until the audio thread\"] # [doc = \" has stopped processing.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic when this function is called multiple times\"] pub fn close_sync (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Close_sync called, locking backend manager\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 638u32 , ()) ; } } ; let backend_manager_guard = self . backend_manager . lock () . unwrap () ; if self . state () == AudioContextState :: Closed { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Close no-op - context is already closed\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 642u32 , ()) ; } } ; return ; } if self . state () == AudioContextState :: Running { let (sender , receiver) = crossbeam_channel :: bounded (0) ; let notify = OneshotNotify :: Sync (sender) ; self . base . send_control_msg (ControlMessage :: Close { notify , }) ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspending audio graph, waiting for signal..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 654u32 , ()) ; } } ; receiver . recv () . ok () ; } else { self . base . set_state (AudioContextState :: Closed) ; } { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Suspended audio graph. Closing audio stream..\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 662u32 , ()) ; } } ; backend_manager_guard . close () ; self . render_capacity . stop () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Closed audio stream\") , lvl , & (\"web_audio_api::context::online\" , \"web_audio_api::context::online\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/context/online.rs\") , 668u32 , ()) ; } } ; } # [doc = \" Creates a [`MediaStreamAudioSourceNode`](node::MediaStreamAudioSourceNode) from a\"] # [doc = \" [`MediaStream`]\"] # [must_use] pub fn create_media_stream_source (& self , media : & MediaStream) -> node :: MediaStreamAudioSourceNode { let opts = node :: MediaStreamAudioSourceOptions { media_stream : media } ; node :: MediaStreamAudioSourceNode :: new (self , opts) } # [doc = \" Creates a [`MediaStreamAudioDestinationNode`](node::MediaStreamAudioDestinationNode)\"] # [must_use] pub fn create_media_stream_destination (& self) -> node :: MediaStreamAudioDestinationNode { let opts = AudioNodeOptions :: default () ; node :: MediaStreamAudioDestinationNode :: new (self , opts) } # [doc = \" Creates a [`MediaStreamTrackAudioSourceNode`](node::MediaStreamTrackAudioSourceNode) from a\"] # [doc = \" [`MediaStreamTrack`]\"] # [must_use] pub fn create_media_stream_track_source (& self , media : & MediaStreamTrack) -> node :: MediaStreamTrackAudioSourceNode { let opts = node :: MediaStreamTrackAudioSourceOptions { media_stream_track : media , } ; node :: MediaStreamTrackAudioSourceNode :: new (self , opts) } # [doc = \" Creates a [`MediaElementAudioSourceNode`](node::MediaElementAudioSourceNode) from a\"] # [doc = \" [`MediaElement`]\"] # [must_use] pub fn create_media_element_source (& self , media_element : & mut MediaElement) -> node :: MediaElementAudioSourceNode { let opts = node :: MediaElementAudioSourceOptions { media_element } ; node :: MediaElementAudioSourceNode :: new (self , opts) } # [doc = \" Returns an [`AudioRenderCapacity`] instance associated with an AudioContext.\"] # [must_use] pub fn render_capacity (& self) -> & AudioRenderCapacity { & self . render_capacity } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: collections :: hash_map :: DefaultHasher ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: hash :: { Hash , Hasher } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: context :: { AudioContextLatencyCategory , AudioContextOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: media_streams :: MediaStream ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" List the available media output devices, such as speakers, headsets, loopbacks, etc\"] # [doc = \"\"] # [doc = \" The media device_id can be used to specify the [`sink_id` of the `AudioContext`](crate::context::AudioContextOptions::sink_id)\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::media_devices::{enumerate_devices_sync, MediaDeviceInfoKind};\"] # [doc = \"\"] # [doc = \" let devices = enumerate_devices_sync();\"] # [doc = \" assert_eq!(devices[0].device_id(), \\\"1\\\");\"] # [doc = \" assert_eq!(devices[0].group_id(), None);\"] # [doc = \" assert_eq!(devices[0].kind(), MediaDeviceInfoKind::AudioOutput);\"] # [doc = \" assert_eq!(devices[0].label(), \\\"Macbook Pro Builtin Speakers\\\");\"] # [doc = \" ```\"] pub fn enumerate_devices_sync () -> Vec < MediaDeviceInfo > { crate :: io :: enumerate_devices_sync () }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub (crate) struct DeviceId { kind : MediaDeviceInfoKind , host : String , device_name : String , num_channels : u16 , index : u8 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: hash :: Hash for DeviceId { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { :: core :: hash :: Hash :: hash (& self . kind , state) ; :: core :: hash :: Hash :: hash (& self . host , state) ; :: core :: hash :: Hash :: hash (& self . device_name , state) ; :: core :: hash :: Hash :: hash (& self . num_channels , state) ; :: core :: hash :: Hash :: hash (& self . index , state) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl DeviceId { pub (crate) fn as_string (kind : MediaDeviceInfoKind , host : String , device_name : String , num_channels : u16 , index : u8) -> String { let device_info = Self { kind , host , device_name , num_channels , index } ; let mut hasher = DefaultHasher :: new () ; device_info . hash (& mut hasher) ; { let res = :: alloc :: fmt :: format (format_args ! (\"{0}\" , hasher . finish ())) ; res } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Describes input/output type of a media device\"] pub enum MediaDeviceInfoKind { VideoInput , AudioInput , AudioOutput , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for MediaDeviceInfoKind { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for MediaDeviceInfoKind { # [inline] fn clone (& self) -> MediaDeviceInfoKind { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaDeviceInfoKind { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { MediaDeviceInfoKind :: VideoInput => \"VideoInput\" , MediaDeviceInfoKind :: AudioInput => \"AudioInput\" , MediaDeviceInfoKind :: AudioOutput => \"AudioOutput\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for MediaDeviceInfoKind { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for MediaDeviceInfoKind { # [inline] fn eq (& self , other : & MediaDeviceInfoKind) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for MediaDeviceInfoKind { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: hash :: Hash for MediaDeviceInfoKind { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; :: core :: hash :: Hash :: hash (& __self_tag , state) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Describes a single media input or output device\"] # [doc = \"\"] # [doc = \" Call [`enumerate_devices_sync`] to obtain a list of devices for your hardware.\"] pub struct MediaDeviceInfo { device_id : String , group_id : Option < String > , kind : MediaDeviceInfoKind , label : String , device : Box < dyn std :: any :: Any > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaDeviceInfo { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"MediaDeviceInfo\" , \"device_id\" , & self . device_id , \"group_id\" , & self . group_id , \"kind\" , & self . kind , \"label\" , & self . label , \"device\" , & & self . device) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaDeviceInfo { pub (crate) fn new (device_id : String , group_id : Option < String > , kind : MediaDeviceInfoKind , label : String , device : Box < dyn std :: any :: Any >) -> Self { Self { device_id , group_id , kind , label , device } } # [doc = \" Identifier for the represented device\"] # [doc = \"\"] # [doc = \" The current implementation is not stable across sessions so you should not persist this\"] # [doc = \" value\"] pub fn device_id (& self) -> & str { & self . device_id } # [doc = \" Two devices have the same group identifier if they belong to the same physical device\"] pub fn group_id (& self) -> Option < & str > { self . group_id . as_deref () } # [doc = \" Enumerated value that is either \\\"videoinput\\\", \\\"audioinput\\\" or \\\"audiooutput\\\".\"] pub fn kind (& self) -> MediaDeviceInfoKind { self . kind } # [doc = \" Friendly label describing this device\"] pub fn label (& self) -> & str { & self . label } pub (crate) fn device (self) -> Box < dyn std :: any :: Any > { self . device } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Dictionary used to instruct what sort of tracks to include in the [`MediaStream`] returned by\"] # [doc = \" [`get_user_media_sync`]\"] pub enum MediaStreamConstraints { Audio , AudioWithConstraints (MediaTrackConstraints) , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for MediaStreamConstraints { # [inline] fn clone (& self) -> MediaStreamConstraints { match self { MediaStreamConstraints :: Audio => MediaStreamConstraints :: Audio , MediaStreamConstraints :: AudioWithConstraints (__self_0) => MediaStreamConstraints :: AudioWithConstraints (:: core :: clone :: Clone :: clone (__self_0)) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaStreamConstraints { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { MediaStreamConstraints :: Audio => :: core :: fmt :: Formatter :: write_str (f , \"Audio\") , MediaStreamConstraints :: AudioWithConstraints (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"AudioWithConstraints\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Desired media stream track settings for [`MediaTrackConstraints`]\"] # [non_exhaustive] pub struct MediaTrackConstraints { pub sample_rate : Option < f32 > , pub latency : Option < f64 > , pub channel_count : Option < u32 > , pub device_id : Option < String > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for MediaTrackConstraints { # [inline] fn default () -> MediaTrackConstraints { MediaTrackConstraints { sample_rate : :: core :: default :: Default :: default () , latency : :: core :: default :: Default :: default () , channel_count : :: core :: default :: Default :: default () , device_id : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaTrackConstraints { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"MediaTrackConstraints\" , \"sample_rate\" , & self . sample_rate , \"latency\" , & self . latency , \"channel_count\" , & self . channel_count , \"device_id\" , & & self . device_id) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for MediaTrackConstraints { # [inline] fn clone (& self) -> MediaTrackConstraints { MediaTrackConstraints { sample_rate : :: core :: clone :: Clone :: clone (& self . sample_rate) , latency : :: core :: clone :: Clone :: clone (& self . latency) , channel_count : :: core :: clone :: Clone :: clone (& self . channel_count) , device_id : :: core :: clone :: Clone :: clone (& self . device_id) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl From < MediaTrackConstraints > for AudioContextOptions { fn from (value : MediaTrackConstraints) -> Self { let latency_hint = match value . latency { Some (v) => AudioContextLatencyCategory :: Custom (v) , None => AudioContextLatencyCategory :: Interactive , } ; let sink_id = value . device_id . unwrap_or (String :: from (\"\")) ; AudioContextOptions { latency_hint , sample_rate : value . sample_rate , sink_id , render_size_hint : Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Check if the provided device_id is available for playback\"] # [doc = \"\"] # [doc = \" It should be \\\"\\\" or a valid input `deviceId` returned from [`enumerate_devices_sync`]\"] fn is_valid_device_id (device_id : & str) -> bool { if device_id . is_empty () { true } else { enumerate_devices_sync () . into_iter () . filter (| d | d . kind == MediaDeviceInfoKind :: AudioInput) . any (| d | d . device_id () == device_id) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_devices",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Prompt for permission to use a media input (audio only)\"] # [doc = \"\"] # [doc = \" This produces a [`MediaStream`] with tracks containing the requested types of media, which can\"] # [doc = \" be used inside a [`MediaStreamAudioSourceNode`](crate::node::MediaStreamAudioSourceNode).\"] # [doc = \"\"] # [doc = \" It is okay for the `MediaStream` struct to go out of scope, any corresponding stream will still be\"] # [doc = \" kept alive and emit audio buffers. Call the `close()` method if you want to stop the media\"] # [doc = \" input and release all system resources.\"] # [doc = \"\"] # [doc = \" This function operates synchronously, which may be undesirable on the control thread. An async\"] # [doc = \" version is currently not implemented.\"] # [doc = \"\"] # [doc = \" # Example\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::context::{AudioContextLatencyCategory, AudioContextOptions};\"] # [doc = \" use web_audio_api::media_devices;\"] # [doc = \" use web_audio_api::media_devices::MediaStreamConstraints;\"] # [doc = \" use web_audio_api::node::AudioNode;\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let mic = media_devices::get_user_media_sync(MediaStreamConstraints::Audio);\"] # [doc = \"\"] # [doc = \" // register as media element in the audio context\"] # [doc = \" let background = context.create_media_stream_source(&mic);\"] # [doc = \"\"] # [doc = \" // connect the node directly to the destination node (speakers)\"] # [doc = \" background.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" // enjoy listening\"] # [doc = \" std::thread::sleep(std::time::Duration::from_secs(4));\"] # [doc = \" ```\"] pub fn get_user_media_sync (constraints : MediaStreamConstraints) -> MediaStream { let (channel_count , mut options) = match constraints { MediaStreamConstraints :: Audio => (None , AudioContextOptions :: default ()) , MediaStreamConstraints :: AudioWithConstraints (cs) => (cs . channel_count , cs . into ()) , } ; if ! is_valid_device_id (& options . sink_id) { { let lvl = :: log :: Level :: Error ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"NotFoundError: invalid deviceId {0:?}\" , options . sink_id) , lvl , & (\"web_audio_api::media_devices\" , \"web_audio_api::media_devices\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/media_devices/mod.rs\") , 228u32 , ()) ; } } ; options . sink_id = String :: from (\"\") ; } crate :: io :: build_input (options , channel_count) }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: media_streams :: MediaStream ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: { AudioBuffer , ErrorEvent , Event } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: io :: Write ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: atomic :: { AtomicBool , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: time :: Instant ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "type EventCallback = Box < dyn FnOnce (Event) + Send + 'static > ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "type BlobEventCallback = Box < dyn FnMut (BlobEvent) + Send + 'static > ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "type ErrorEventCallback = Box < dyn FnOnce (ErrorEvent) + Send + 'static > ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "struct RecordedData { blob : Vec < u8 > , start_timecode : Instant , current_timecode : Instant , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl RecordedData { fn new (blob : Vec < u8 >) -> Self { let now = Instant :: now () ; Self { blob , start_timecode : now , current_timecode : now } } # [doc = \" Start encoding audio into the blob buffer\"] fn encode_first (& mut self , buf : AudioBuffer) { let spec = hound :: WavSpec { channels : buf . number_of_channels () as u16 , sample_rate : buf . sample_rate () as u32 , bits_per_sample : 32 , sample_format : hound :: SampleFormat :: Float , } ; let v = spec . into_header_for_infinite_file () ; self . blob . write_all (& v) . unwrap () ; self . encode_next (buf) ; } # [doc = \" Encode subsequent buffers into the blob buffer\"] fn encode_next (& mut self , buf : AudioBuffer) { for i in 0 .. buf . length () { for c in 0 .. buf . number_of_channels () { let v = buf . get_channel_data (c) [i] ; hound :: Sample :: write (v , & mut self . blob , 32) . unwrap () ; } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "struct MediaRecorderInner { stream : MediaStream , active : AtomicBool , recorded_data : Mutex < RecordedData > , data_available_callback : Mutex < Option < BlobEventCallback > > , stop_callback : Mutex < Option < EventCallback > > , error_callback : Mutex < Option < ErrorEventCallback > > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaRecorderInner { fn record (& self , buf : AudioBuffer) { let mut recorded_data = self . recorded_data . lock () . unwrap () ; recorded_data . encode_next (buf) ; if recorded_data . blob . len () > 128 * 1024 { drop (recorded_data) ; self . flush () ; } } fn handle_error (& self , error : Box < dyn Error + Send + Sync >) { self . flush () ; if let Some (f) = self . error_callback . lock () . unwrap () . take () { (f) (ErrorEvent { message : error . to_string () , error : Box :: new (error) , event : Event { type_ : \"ErrorEvent\" } , }) } self . stop () ; } fn flush (& self) { let mut recorded_data = self . recorded_data . lock () . unwrap () ; let timecode = recorded_data . current_timecode . duration_since (recorded_data . start_timecode) . as_secs_f64 () ; let send = std :: mem :: replace (& mut recorded_data . blob , Vec :: with_capacity (128 * 1024)) ; if let Some (f) = self . data_available_callback . lock () . unwrap () . as_mut () { let event = BlobEvent { blob : send , timecode , event : Event { type_ : \"BlobEvent\" } , } ; (f) (event) } recorded_data . current_timecode = Instant :: now () ; } fn stop (& self) { self . active . store (false , Ordering :: SeqCst) ; if let Some (f) = self . stop_callback . lock () . unwrap () . take () { (f) (Event { type_ : \"StopEvent\" }) } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Record and encode media\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::AudioContext;\"] # [doc = \" use web_audio_api::media_recorder::MediaRecorder;\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let output = context.create_media_stream_destination();\"] # [doc = \"\"] # [doc = \" let recorder = MediaRecorder::new(output.stream());\"] # [doc = \" recorder.set_ondataavailable(|event| {\"] # [doc = \"     println!(\\\"Received {} bytes of data\\\", event.blob.len());\"] # [doc = \" });\"] # [doc = \" recorder.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example recorder`\"] pub struct MediaRecorder { inner : Arc < MediaRecorderInner > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl std :: fmt :: Debug for MediaRecorder { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"MediaRecorder\") . field (\"stream\" , & self . inner . stream) . field (\"active\" , & self . inner . active) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaRecorder { # [doc = \" Creates a new `MediaRecorder` object, given a [`MediaStream`] to record.\"] # [doc = \"\"] # [doc = \" Only supports WAV file format currently.\"] pub fn new (stream : & MediaStream) -> Self { let inner = MediaRecorderInner { stream : stream . clone () , active : AtomicBool :: new (false) , recorded_data : Mutex :: new (RecordedData :: new (:: alloc :: vec :: Vec :: new ())) , data_available_callback : Mutex :: new (None) , stop_callback : Mutex :: new (None) , error_callback : Mutex :: new (None) , } ; Self { inner : Arc :: new (inner) } } # [allow (clippy :: missing_panics_doc)] pub fn set_ondataavailable < F : FnMut (BlobEvent) + Send + 'static > (& self , callback : F) { * self . inner . data_available_callback . lock () . unwrap () = Some (Box :: new (callback)) ; } # [allow (clippy :: missing_panics_doc)] pub fn clear_ondataavailable (& self) { * self . inner . data_available_callback . lock () . unwrap () = None ; } # [allow (clippy :: missing_panics_doc)] pub fn set_onstop < F : FnOnce (Event) + Send + 'static > (& self , callback : F) { * self . inner . stop_callback . lock () . unwrap () = Some (Box :: new (callback)) ; } # [allow (clippy :: missing_panics_doc)] pub fn clear_onstop (& self) { * self . inner . stop_callback . lock () . unwrap () = None ; } # [allow (clippy :: missing_panics_doc)] pub fn set_onerror < F : FnOnce (ErrorEvent) + Send + 'static > (& self , callback : F) { * self . inner . error_callback . lock () . unwrap () = Some (Box :: new (callback)) ; } # [allow (clippy :: missing_panics_doc)] pub fn clear_onerror (& self) { * self . inner . error_callback . lock () . unwrap () = None ; } # [doc = \" Begin recording media\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic when the recorder has already started\"] pub fn start (& self) { let prev_active = self . inner . active . swap (true , Ordering :: Relaxed) ; if ! ! prev_active { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError - recorder has already started\")) ; } } ; let inner = Arc :: clone (& self . inner) ; let blob = Vec :: with_capacity (128 * 1024) ; std :: thread :: spawn (move | | { let mut stream_iter = inner . stream . get_tracks () [0] . iter () ; let buf = match stream_iter . next () { None => return , Some (Err (error)) => { inner . handle_error (error) ; return ; } Some (Ok (first)) => first , } ; let mut recorded_data = RecordedData :: new (blob) ; recorded_data . encode_first (buf) ; * inner . recorded_data . lock () . unwrap () = recorded_data ; for item in stream_iter { if ! inner . active . load (Ordering :: Relaxed) { return ; } let buf = match item { Ok (buf) => buf , Err (error) => { inner . handle_error (error) ; return ; } } ; inner . record (buf) ; } inner . flush () ; inner . stop () ; }) ; } pub fn stop (& self) { self . inner . flush () ; self . inner . stop () ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Interface for the `dataavailable` event, containing the recorded data\"] # [non_exhaustive] pub struct BlobEvent { # [doc = \" The encoded data\"] pub blob : Vec < u8 > , # [doc = \" The difference between the timestamp of the first chunk in data and the timestamp of the\"] # [doc = \" first chunk in the first BlobEvent produced by this recorder\"] pub timecode : f64 , # [doc = \" Inherits from this base Event\"] pub event : Event , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_recorder",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for BlobEvent { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"BlobEvent\" , \"blob\" , & self . blob , \"timecode\" , & self . timecode , \"event\" , & & self . event) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: { AudioBuffer , FallibleBuffer } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use arc_swap :: ArcSwap ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: atomic :: { AtomicBool , AtomicU64 , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Ready-state of a [`MediaStreamTrack`]\"] pub enum MediaStreamTrackState { # [doc = \" The track is active (the track's underlying media source is making a best-effort attempt to\"] # [doc = \" provide data in real time).\"] Live , # [doc = \" The track has ended (the track's underlying media source is no longer providing data, and\"] # [doc = \" will never provide more data for this track). Once a track enters this state, it never\"] # [doc = \" exits it.\"] Ended , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for MediaStreamTrackState { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for MediaStreamTrackState { # [inline] fn clone (& self) -> MediaStreamTrackState { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for MediaStreamTrackState { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for MediaStreamTrackState { # [inline] fn eq (& self , other : & MediaStreamTrackState) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for MediaStreamTrackState { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaStreamTrackState { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { MediaStreamTrackState :: Live => \"Live\" , MediaStreamTrackState :: Ended => \"Ended\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Single media track within a [`MediaStream`]\"] pub struct MediaStreamTrack { inner : Arc < MediaStreamTrackInner > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for MediaStreamTrack { # [inline] fn clone (& self) -> MediaStreamTrack { MediaStreamTrack { inner : :: core :: clone :: Clone :: clone (& self . inner) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl std :: fmt :: Debug for MediaStreamTrack { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"MediaStreamTrack\") . field (\"ended\" , & self . inner . ended) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "struct MediaStreamTrackInner { data : ArcSwap < FallibleBuffer > , position : AtomicU64 , ended : AtomicBool , provider : Mutex < Box < dyn Iterator < Item = FallibleBuffer > + Send + Sync + 'static > > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaStreamTrack { # [allow (clippy :: should_implement_trait)] pub fn from_iter < T : IntoIterator < Item = FallibleBuffer > > (iter : T) -> Self where < T as IntoIterator > :: IntoIter : Send + Sync + 'static { let initial = Ok (AudioBuffer :: from (< [_] > :: into_vec (# [rustc_box] :: alloc :: boxed :: Box :: new ([< [_] > :: into_vec (# [rustc_box] :: alloc :: boxed :: Box :: new ([0.]))])) , 48000.)) ; let inner = MediaStreamTrackInner { data : ArcSwap :: from_pointee (initial) , position : AtomicU64 :: new (0) , ended : AtomicBool :: new (false) , provider : Mutex :: new (Box :: new (iter . into_iter ())) , } ; MediaStreamTrack { inner : Arc :: new (inner) } } pub fn ready_state (& self) -> MediaStreamTrackState { if self . inner . ended . load (Ordering :: Relaxed) { MediaStreamTrackState :: Ended } else { MediaStreamTrackState :: Live } } pub fn iter (& self) -> impl Iterator < Item = FallibleBuffer > { MediaStreamTrackIter { track : Arc :: clone (& self . inner) , position : 0 , } } # [allow (clippy :: missing_panics_doc)] pub fn close (& self) { * self . inner . provider . lock () . unwrap () = Box :: new (std :: iter :: empty ()) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "struct MediaStreamTrackIter { track : Arc < MediaStreamTrackInner > , position : u64 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl Iterator for MediaStreamTrackIter { type Item = FallibleBuffer ; fn next (& mut self) -> Option < Self :: Item > { if self . track . ended . load (Ordering :: Relaxed) { return None ; } let mut stream_position = self . track . position . load (Ordering :: Relaxed) ; if stream_position == self . position { match self . track . provider . lock () . unwrap () . next () { Some (buf) => { let _ = self . track . data . swap (Arc :: new (buf)) ; } None => { self . track . ended . store (true , Ordering :: Relaxed) ; return None ; } } stream_position += 1 ; self . track . position . fetch_add (1 , Ordering :: Relaxed) ; } self . position = stream_position ; Some (match & self . track . data . load () . as_ref () { Ok (buf) => Ok (buf . clone ()) , Err (e) => Err (e . to_string () . into ()) , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Stream of media content.\"] # [doc = \"\"] # [doc = \" A stream consists of several tracks, such as video or audio tracks. Each track is specified as\"] # [doc = \" an instance of [`MediaStreamTrack`].\"] pub struct MediaStream { tracks : Vec < MediaStreamTrack > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for MediaStream { # [inline] fn clone (& self) -> MediaStream { MediaStream { tracks : :: core :: clone :: Clone :: clone (& self . tracks) } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaStream { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"MediaStream\" , \"tracks\" , & & self . tracks) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_streams",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl MediaStream { pub fn from_tracks (tracks : Vec < MediaStreamTrack >) -> Self { Self { tracks } } pub fn get_tracks (& self) -> & [MediaStreamTrack] { & self . tracks } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: f32 :: consts :: PI ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: sync :: OnceLock ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: AudioBufferIter ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use audio_node :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use scheduled_source :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use analyser :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use audio_buffer_source :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use biquad_filter :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use channel_merger :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use channel_splitter :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use constant_source :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use convolver :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use delay :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use destination :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use dynamics_compressor :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use gain :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use iir_filter :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use media_element_source :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use media_stream_destination :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use media_stream_source :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use media_stream_track_source :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use oscillator :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use panner :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use script_processor :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use stereo_panner :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use waveshaper :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub (crate) const TABLE_LENGTH_USIZE : usize = 8192 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub (crate) const TABLE_LENGTH_BY_4_USIZE : usize = TABLE_LENGTH_USIZE / 4 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub (crate) const TABLE_LENGTH_F32 : f32 = TABLE_LENGTH_USIZE as f32 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub (crate) const TABLE_LENGTH_BY_4_F32 : f32 = TABLE_LENGTH_BY_4_USIZE as f32 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Precomputed sine table\"] pub (crate) fn precomputed_sine_table () -> & 'static [f32] { static INSTANCE : OnceLock < Vec < f32 > > = OnceLock :: new () ; INSTANCE . get_or_init (| | { (0 .. TABLE_LENGTH_USIZE) . map (| x | ((x as f32) * 2.0 * PI * (1. / (TABLE_LENGTH_F32))) . sin ()) . collect () }) }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "struct MediaStreamRenderer < R > { stream : R , finished : bool , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < R > MediaStreamRenderer < R > { fn new (stream : R) -> Self { Self { stream , finished : false } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < R : AudioBufferIter > AudioProcessor for MediaStreamRenderer < R > { fn process (& mut self , _inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let output = & mut outputs [0] ; match self . stream . next () { Some (Ok (buffer)) => { let channels = buffer . number_of_channels () ; output . set_number_of_channels (channels) ; output . channels_mut () . iter_mut () . zip (buffer . channels ()) . for_each (| (o , i) | o . copy_from_slice (i . as_slice ())) ; } Some (Err (e)) => { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Error playing audio stream: {0}\" , e) , lvl , & (\"web_audio_api::node\" , \"web_audio_api::node\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/mod.rs\") , 118u32 , ()) ; } } ; self . finished = true ; output . make_silent () } None => { if ! self . finished { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Stream finished\") , lvl , & (\"web_audio_api::node\" , \"web_audio_api::node\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/mod.rs\") , 124u32 , ()) ; } } ; self . finished = true ; } output . make_silent () } } ! self . finished } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" How channels must be matched between the node's inputs and outputs.\"] pub enum ChannelCountMode { # [doc = \" `computedNumberOfChannels` is the maximum of the number of channels of all connections to an\"] # [doc = \" input. In this mode channelCount is ignored.\"] Max , # [doc = \" `computedNumberOfChannels` is determined as for \\\"max\\\" and then clamped to a maximum value of\"] # [doc = \" the given channelCount.\"] ClampedMax , # [doc = \" `computedNumberOfChannels` is the exact value as specified by the channelCount.\"] Explicit , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The meaning of the channels, defining how audio up-mixing and down-mixing will happen.\"] pub enum ChannelInterpretation { Speakers , Discrete , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options that can be used in constructing all AudioNodes.\"] pub struct AudioNodeOptions { # [doc = \" Desired number of channels for the [`AudioNode::channel_count`] attribute.\"] pub channel_count : usize , # [doc = \" Desired mode for the [`AudioNode::channel_count_mode`] attribute.\"] pub channel_count_mode : ChannelCountMode , # [doc = \" Desired mode for the [`AudioNode::channel_interpretation`] attribute.\"] pub channel_interpretation : ChannelInterpretation , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Config for up/down-mixing of input channels for audio nodes\"] # [doc = \"\"] # [doc = \" Only when implementing the [`AudioNode`] trait manually, this struct is of any concern. The\"] # [doc = \" methods `set_channel_count`, `set_channel_count_mode` and `set_channel_interpretation` from the\"] # [doc = \" audio node interface will use this struct to sync the required info to the render thread.\"] # [doc = \"\"] # [doc = \" The only way to construct an instance is with [`AudioNodeOptions`]\"] # [doc = \"\"] # [doc = \" ```\"] # [doc = \" use web_audio_api::node::{AudioNodeOptions, ChannelConfig, ChannelInterpretation, ChannelCountMode};\"] # [doc = \"\"] # [doc = \" let opts = AudioNodeOptions {\"] # [doc = \"     channel_count: 1,\"] # [doc = \"     channel_count_mode: ChannelCountMode::Explicit,\"] # [doc = \"     channel_interpretation: ChannelInterpretation::Discrete,\"] # [doc = \" };\"] # [doc = \" let _: ChannelConfig = opts.into();\"] pub struct ChannelConfig { inner : Arc < Mutex < ChannelConfigInner > > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" This interface represents audio sources, the audio destination, and intermediate processing\"] # [doc = \" modules.\"] # [doc = \"\"] # [doc = \" These modules can be connected together to form processing graphs for rendering audio\"] # [doc = \" to the audio hardware. Each node can have inputs and/or outputs.\"] # [doc = \"\"] # [doc = \" Note that the AudioNode is typically constructed together with an `AudioWorkletProcessor`\"] # [doc = \" (the object that lives the render thread). See the [`crate::worklet`] mod.\"] pub trait AudioNode { # [doc = \" Handle of the associated [`BaseAudioContext`](crate::context::BaseAudioContext).\"] # [doc = \"\"] # [doc = \" Only when implementing the AudioNode trait manually, this struct is of any concern.\"] fn registration (& self) -> & AudioContextRegistration ; # [doc = \" Config for up/down-mixing of input channels for this node.\"] # [doc = \"\"] # [doc = \" Only when implementing the [`AudioNode`] trait manually, this struct is of any concern.\"] fn channel_config (& self) -> & ChannelConfig ; # [doc = \" The [`BaseAudioContext`](crate::context::BaseAudioContext) concrete type which owns this\"] # [doc = \" AudioNode.\"] fn context (& self) -> & ConcreteBaseAudioContext { self . registration () . context () } # [doc = \" Connect the output of this AudioNode to the input of another node.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] fn connect < 'a > (& self , dest : & 'a dyn AudioNode) -> & 'a dyn AudioNode { self . connect_from_output_to_input (dest , 0 , 0) } # [doc = \" Connect a specific output of this AudioNode to a specific input of another node.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - if the input port is out of bounds for the destination node\"] # [doc = \" - if the output port is out of bounds for the source node\"] fn connect_from_output_to_input < 'a > (& self , dest : & 'a dyn AudioNode , output : usize , input : usize) -> & 'a dyn AudioNode { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to connect nodes from different contexts\")) ; } } ; if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; if ! (dest . number_of_inputs () > input) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - input port {0} is out of bounds\" , input)) ; } } ; self . context () . connect (self . registration () . id () , dest . registration () . id () , output , input) ; dest } # [doc = \" Disconnects all outgoing connections from the AudioNode.\"] fn disconnect (& self) { self . context () . disconnect (self . registration () . id () , None , None , None) ; } # [doc = \" Disconnects all outputs of the AudioNode that go to a specific destination AudioNode.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - the source node was not connected to the destination node\"] fn disconnect_dest (& self , dest : & dyn AudioNode) { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to disconnect nodes from different contexts\")) ; } } ; self . context () . disconnect (self . registration () . id () , None , Some (dest . registration () . id ()) , None) ; } # [doc = \" Disconnects all outgoing connections at the given output port from the AudioNode.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - if the output port is out of bounds for this node\"] fn disconnect_output (& self , output : usize) { if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; self . context () . disconnect (self . registration () . id () , Some (output) , None , None) ; } # [doc = \" Disconnects a specific output of the AudioNode to a specific destination AudioNode\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - if the output port is out of bounds for the source node\"] # [doc = \" - the source node was not connected to the destination node\"] fn disconnect_dest_from_output (& self , dest : & dyn AudioNode , output : usize) { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to disconnect nodes from different contexts\")) ; } } ; if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; self . context () . disconnect (self . registration () . id () , Some (output) , Some (dest . registration () . id ()) , None) ; } # [doc = \" Disconnects a specific output of the AudioNode to a specific input of some destination\"] # [doc = \" AudioNode\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - if the input port is out of bounds for the destination node\"] # [doc = \" - if the output port is out of bounds for the source node\"] # [doc = \" - the source node was not connected to the destination node\"] fn disconnect_dest_from_output_to_input (& self , dest : & dyn AudioNode , output : usize , input : usize) { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to disconnect nodes from different contexts\")) ; } } ; if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; if ! (dest . number_of_inputs () > input) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - input port {0} is out of bounds\" , input)) ; } } ; self . context () . disconnect (self . registration () . id () , Some (output) , Some (dest . registration () . id ()) , Some (input)) ; } # [doc = \" The number of inputs feeding into the AudioNode. For source nodes, this will be 0.\"] fn number_of_inputs (& self) -> usize ; # [doc = \" The number of outputs coming out of the AudioNode.\"] fn number_of_outputs (& self) -> usize ; # [doc = \" Represents an enumerated value describing the way channels must be matched between the\"] # [doc = \" node's inputs and outputs.\"] fn channel_count_mode (& self) -> ChannelCountMode { self . channel_config () . count_mode () } # [doc = \" Update the `channel_count_mode` attribute\"] fn set_channel_count_mode (& self , v : ChannelCountMode) { self . channel_config () . set_count_mode (v , self . registration ()) } # [doc = \" Represents an enumerated value describing the meaning of the channels. This interpretation\"] # [doc = \" will define how audio up-mixing and down-mixing will happen.\"] fn channel_interpretation (& self) -> ChannelInterpretation { self . channel_config () . interpretation () } # [doc = \" Update the `channel_interpretation` attribute\"] fn set_channel_interpretation (& self , v : ChannelInterpretation) { self . channel_config () . set_interpretation (v , self . registration ()) } # [doc = \" Represents an integer used to determine how many channels are used when up-mixing and\"] # [doc = \" down-mixing connections to any inputs to the node.\"] fn channel_count (& self) -> usize { self . channel_config () . count () } # [doc = \" Update the `channel_count` attribute\"] fn set_channel_count (& self , v : usize) { self . channel_config () . set_count (v , self . registration ()) } # [doc = \" Register callback to run when an unhandled exception occurs in the audio processor.\"] # [doc = \"\"] # [doc = \" Note that once a unhandled exception is thrown, the processor will output silence throughout its lifetime.\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] fn set_onprocessorerror (& self , callback : Box < dyn FnOnce (ErrorEvent) + Send + 'static >) { let callback = move | v | match v { EventPayload :: ProcessorError (v) => callback (v) , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } ; self . context () . set_event_handler (EventType :: ProcessorError (self . registration () . id ()) , EventHandler :: Once (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when an unhandled exception occurs in the audio processor.\"] fn clear_onprocessorerror (& self) { self . context () . clear_event_handler (EventType :: ProcessorError (self . registration () . id ())) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Interface of source nodes, controlling start and stop times.\"] # [doc = \" The node will emit silence before it is started, and after it has ended.\"] pub trait AudioScheduledSourceNode : AudioNode { # [doc = \" Play immediately\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the source was already started\"] fn start (& mut self) ; # [doc = \" Schedule playback start at given timestamp\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the source was already started\"] fn start_at (& mut self , when : f64) ; # [doc = \" Stop immediately\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the source was already stopped\"] fn stop (& mut self) ; # [doc = \" Schedule playback stop at given timestamp\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the source was already stopped\"] fn stop_at (& mut self , when : f64) ; # [doc = \" Register callback to run when the source node has stopped playing\"] # [doc = \"\"] # [doc = \" For all [`AudioScheduledSourceNode`]s, the ended event is dispatched when the stop time\"] # [doc = \" determined by stop() is reached. For an\"] # [doc = \" [`AudioBufferSourceNode`](crate::node::AudioBufferSourceNode), the event is also dispatched\"] # [doc = \" because the duration has been reached or if the entire buffer has been played.\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] fn set_onended < F : FnOnce (Event) + Send + 'static > (& self , callback : F) { let callback = move | _ | callback (Event { type_ : \"ended\" }) ; self . context () . set_event_handler (EventType :: Ended (self . registration () . id ()) , EventHandler :: Once (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when the source node has stopped playing\"] fn clear_onended (& self) { self . context () . clear_event_handler (EventType :: Ended (self . registration () . id ())) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`AnalyserNode`]\"] pub struct AnalyserOptions { pub fft_size : usize , pub max_decibels : f64 , pub min_decibels : f64 , pub smoothing_time_constant : f64 , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `AnalyserNode` represents a node able to provide real-time frequency and\"] # [doc = \" time-domain analysis information.\"] # [doc = \"\"] # [doc = \" It is an AudioNode that passes the audio stream unchanged from the input to\"] # [doc = \" the output, but allows you to take the generated data, process it, and create\"] # [doc = \" audio visualizations..\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#AnalyserNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_analyser`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let mut analyser = context.create_analyser();\"] # [doc = \" analyser.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" let mut osc = context.create_oscillator();\"] # [doc = \" osc.frequency().set_value(200.);\"] # [doc = \" osc.connect(&analyser);\"] # [doc = \" osc.start();\"] # [doc = \"\"] # [doc = \" let mut bins = vec![0.; analyser.frequency_bin_count()];\"] # [doc = \"\"] # [doc = \"\"] # [doc = \" loop {\"] # [doc = \"     analyser.get_float_frequency_data(&mut bins);\"] # [doc = \"     println!(\\\"{:?}\\\", &bins[0..20]); // print 20 first bins\"] # [doc = \"     std::thread::sleep(std::time::Duration::from_millis(1000));\"] # [doc = \" }\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example analyser`\"] # [doc = \" - `cd showcase/mic_playback && cargo run --release`\"] # [doc = \"\"] pub struct AnalyserNode { registration : AudioContextRegistration , channel_config : ChannelConfig , analyser : Analyser , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`AudioBufferSourceNode`]\"] pub struct AudioBufferSourceOptions { pub buffer : Option < AudioBuffer > , pub detune : f32 , pub loop_ : bool , pub loop_start : f64 , pub loop_end : f64 , pub playback_rate : f32 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `AudioBufferSourceNode` represents an audio source that consists of an\"] # [doc = \" in-memory audio source (i.e. an audio file completely loaded in memory),\"] # [doc = \" stored in an [`AudioBuffer`].\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#AudioBufferSourceNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_buffer_source`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" // create an `AudioContext`\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" // load and decode a soundfile\"] # [doc = \" let file = File::open(\\\"samples/sample.wav\\\").unwrap();\"] # [doc = \" let audio_buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \" // play the sound file\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.set_buffer(audio_buffer);\"] # [doc = \" src.connect(&context.destination());\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example trigger_soundfile`\"] # [doc = \" - `cargo run --release --example granular`\"] # [doc = \"\"] pub struct AudioBufferSourceNode { registration : AudioContextRegistration , channel_config : ChannelConfig , detune : AudioParam , playback_rate : AudioParam , buffer_time : Arc < AtomicF64 > , buffer : Option < AudioBuffer > , loop_state : LoopState , start_stop_count : u8 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Biquad filter types\"] pub enum BiquadFilterType { # [doc = \" Allows frequencies below the cutoff frequency to pass through and\"] # [doc = \" attenuates frequencies above the cutoff. (12dB/oct rolloff)\"] Lowpass , # [doc = \" Frequencies above the cutoff frequency are passed through, but\"] # [doc = \" frequencies below the cutoff are attenuated. (12dB/oct rolloff)\"] Highpass , # [doc = \" Allows a range of frequencies to pass through and attenuates the\"] # [doc = \" frequencies below and above this frequency range.\"] Bandpass , # [doc = \" Allows all frequencies through, except for a set of frequencies.\"] Notch , # [doc = \" Allows all frequencies through, but changes the phase relationship\"] # [doc = \" between the various frequencies.\"] Allpass , # [doc = \" Allows all frequencies through, but adds a boost (or attenuation) to\"] # [doc = \" a range of frequencies.\"] Peaking , # [doc = \" Allows all frequencies through, but adds a boost (or attenuation) to\"] # [doc = \" the lower frequencies.\"] Lowshelf , # [doc = \" Allows all frequencies through, but adds a boost (or attenuation) to\"] # [doc = \" the higher frequencies.\"] Highshelf , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`BiquadFilterNode`]\"] pub struct BiquadFilterOptions { pub q : f32 , pub detune : f32 , pub frequency : f32 , pub gain : f32 , pub type_ : BiquadFilterType , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" BiquadFilterNode is an AudioNode processor implementing very common low-order\"] # [doc = \" IIR filters.\"] # [doc = \"\"] # [doc = \" Low-order filters are the building blocks of basic tone controls\"] # [doc = \" (bass, mid, treble), graphic equalizers, and more advanced filters. Multiple\"] # [doc = \" BiquadFilterNode filters can be combined to form more complex filters.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/BiquadFilterNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#BiquadFilterNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_biquad_filter`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let file = File::open(\\\"samples/think-stereo-48000.wav\\\").unwrap();\"] # [doc = \" let buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \"\"] # [doc = \" // create a lowpass filter (default) and open frequency parameter over time\"] # [doc = \" let biquad = context.create_biquad_filter();\"] # [doc = \" biquad.connect(&context.destination());\"] # [doc = \" biquad.frequency().set_value(10.);\"] # [doc = \" biquad\"] # [doc = \"     .frequency()\"] # [doc = \"     .exponential_ramp_to_value_at_time(10000., context.current_time() + 10.);\"] # [doc = \"\"] # [doc = \" // pipe the audio buffer source into the lowpass filter\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.connect(&biquad);\"] # [doc = \" src.set_buffer(buffer);\"] # [doc = \" src.set_loop(true);\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example biquad`\"] # [doc = \"\"] pub struct BiquadFilterNode { # [doc = \" Represents the node instance and its associated audio context\"] registration : AudioContextRegistration , # [doc = \" Infos about audio node channel configuration\"] channel_config : ChannelConfig , # [doc = \" quality factor - its impact on the frequency response of the filter\"] # [doc = \" depends on the `BiquadFilterType`\"] q : AudioParam , # [doc = \" A detune value, in cents, for the frequency.\"] # [doc = \" It forms a compound parameter with frequency to form the computedFrequency.\"] detune : AudioParam , # [doc = \" frequency where the filter is applied - its impact on the frequency\"] # [doc = \" response of the filter, depends on the `BiquadFilterType`\"] frequency : AudioParam , # [doc = \" boost/attenuation (dB) - its impact on the frequency response of the\"] # [doc = \" filter, depends on the `BiquadFilterType`\"] gain : AudioParam , # [doc = \" Current biquad filter type\"] type_ : BiquadFilterType , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`ChannelMergerNode`]\"] pub struct ChannelMergerOptions { pub number_of_inputs : usize , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" AudioNode for combining channels from multiple audio streams into a single audio stream.\"] pub struct ChannelMergerNode { registration : AudioContextRegistration , channel_config : ChannelConfig , number_of_inputs : usize , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`ChannelSplitterNode`]\"] pub struct ChannelSplitterOptions { pub number_of_outputs : usize , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" AudioNode for accessing the individual channels of an audio stream in the routing graph\"] pub struct ChannelSplitterNode { registration : AudioContextRegistration , channel_config : ChannelConfig , number_of_outputs : usize , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`ConstantSourceNode`]\"] pub struct ConstantSourceOptions { # [doc = \" Initial parameter value of the constant signal\"] pub offset : f32 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Audio source whose output is nominally a constant value. A `ConstantSourceNode`\"] # [doc = \" can be used as a constructible `AudioParam` by automating the value of its offset.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/ConstantSourceNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#ConstantSourceNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_constant_source`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::AudioNode;\"] # [doc = \"\"] # [doc = \" let audio_context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let gain1 = audio_context.create_gain();\"] # [doc = \" gain1.gain().set_value(0.);\"] # [doc = \"\"] # [doc = \" let gain2 = audio_context.create_gain();\"] # [doc = \" gain2.gain().set_value(0.);\"] # [doc = \"\"] # [doc = \" let automation = audio_context.create_constant_source();\"] # [doc = \" automation.offset().set_value(0.);\"] # [doc = \" automation.connect(gain1.gain());\"] # [doc = \" automation.connect(gain2.gain());\"] # [doc = \"\"] # [doc = \" // control both `GainNode`s with 1 automation\"] # [doc = \" automation.offset().set_target_at_time(1., audio_context.current_time(), 0.1);\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Example\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example constant_source`\"] # [doc = \"\"] pub struct ConstantSourceNode { registration : AudioContextRegistration , channel_config : ChannelConfig , offset : AudioParam , start_stop_count : u8 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `ConvolverNode` options\"] pub struct ConvolverOptions { # [doc = \" The desired buffer for the ConvolverNode\"] pub buffer : Option < AudioBuffer > , # [doc = \" The opposite of the desired initial value for the normalize attribute\"] pub disable_normalization : bool , # [doc = \" AudioNode options\"] pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Processing node which applies a linear convolution effect given an impulse response.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/ConvolverNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#ConvolverNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_convolver`]\"] # [doc = \"\"] # [doc = \" The current implementation only handles mono-to-mono convolutions. The provided impulse\"] # [doc = \" response buffer and the input signal will be downmixed appropriately.\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \"\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode, ConvolverNode, ConvolverOptions};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let file = File::open(\\\"samples/vocals-dry.wav\\\").unwrap();\"] # [doc = \" let audio_buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \"\"] # [doc = \" let impulse_file = File::open(\\\"samples/small-room-response.wav\\\").unwrap();\"] # [doc = \" let impulse_buffer = context.decode_audio_data_sync(impulse_file).unwrap();\"] # [doc = \"\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.set_buffer(audio_buffer);\"] # [doc = \"\"] # [doc = \" let mut convolve = ConvolverNode::new(&context, ConvolverOptions::default());\"] # [doc = \" convolve.set_buffer(impulse_buffer);\"] # [doc = \"\"] # [doc = \" src.connect(&convolve);\"] # [doc = \" convolve.connect(&context.destination());\"] # [doc = \" src.start();\"] # [doc = \" std::thread::sleep(std::time::Duration::from_millis(4_000));\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example convolution`\"] # [doc = \"\"] pub struct ConvolverNode { # [doc = \" Represents the node instance and its associated audio context\"] registration : AudioContextRegistration , # [doc = \" Info about audio node channel configuration\"] channel_config : ChannelConfig , # [doc = \" Perform equal power normalization on response buffer\"] normalize : bool , # [doc = \" The response buffer, nullable\"] buffer : Option < AudioBuffer > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`DelayNode`]\"] pub struct DelayOptions { pub max_delay_time : f64 , pub delay_time : f64 , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Node that delays the incoming audio signal by a certain amount\"] # [doc = \"\"] # [doc = \" The current implementation does not allow for zero delay. The minimum delay is one render\"] # [doc = \" quantum (e.g. ~2.9ms at 44.1kHz).\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/DelayNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#DelayNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_delay`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" // create an `AudioContext` and load a sound file\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let file = File::open(\\\"samples/sample.wav\\\").unwrap();\"] # [doc = \" let audio_buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \"\"] # [doc = \" // create a delay of 0.5s\"] # [doc = \" let delay = context.create_delay(1.);\"] # [doc = \" delay.delay_time().set_value(0.5);\"] # [doc = \" delay.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.set_buffer(audio_buffer);\"] # [doc = \" // connect to both delay and destination\"] # [doc = \" src.connect(&delay);\"] # [doc = \" src.connect(&context.destination());\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example simple_delay`\"] # [doc = \" - `cargo run --release --example feedback_delay`\"] # [doc = \"\"] pub struct DelayNode { reader_registration : AudioContextRegistration , writer_registration : AudioContextRegistration , delay_time : AudioParam , channel_config : ChannelConfig , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" The AudioDestinationNode interface represents the terminal node of an audio\"] # [doc = \" graph in a given context. usually the speakers of your device, or the node that\"] # [doc = \" will \\\"record\\\" the audio data with an OfflineAudioContext.\"] # [doc = \"\"] # [doc = \" The output of a AudioDestinationNode is produced by summing its input, allowing to capture\"] # [doc = \" the output of an AudioContext into, for example, a MediaStreamAudioDestinationNode, or a\"] # [doc = \" MediaRecorder.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/AudioDestinationNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#AudioDestinationNode>\"] # [doc = \" - see also: [`BaseAudioContext::destination`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let mut osc = context.create_oscillator();\"] # [doc = \" osc.connect(&context.destination());\"] # [doc = \" osc.start();\"] # [doc = \" ```\"] # [doc = \"\"] pub struct AudioDestinationNode { registration : AudioContextRegistration , channel_config : ChannelConfig , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`DynamicsCompressorNode`]\"] pub struct DynamicsCompressorOptions { pub attack : f32 , pub knee : f32 , pub ratio : f32 , pub release : f32 , pub threshold : f32 , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `DynamicsCompressorNode` provides a compression effect.\"] # [doc = \"\"] # [doc = \" It lowers the volume of the loudest parts of the signal and raises the volume\"] # [doc = \" of the softest parts. Overall, a louder, richer, and fuller sound can be achieved.\"] # [doc = \" It is especially important in games and musical applications where large numbers\"] # [doc = \" of individual sounds are played simultaneous to control the overall signal level\"] # [doc = \" and help avoid clipping (distorting) the audio output to the speakers.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/DynamicsCompressorNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#DynamicsCompressorNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_dynamics_compressor`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" // create an `AudioContext`\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" // load and decode a soundfile into an audio buffer\"] # [doc = \" let file = File::open(\\\"samples/sample.wav\\\").unwrap();\"] # [doc = \" let buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \"\"] # [doc = \" // create compressor and connect to destination\"] # [doc = \" let compressor = context.create_dynamics_compressor();\"] # [doc = \" compressor.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" // pipe the audio source in the compressor\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.connect(&compressor);\"] # [doc = \" src.set_buffer(buffer.clone());\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example compressor`\"] # [doc = \"\"] pub struct DynamicsCompressorNode { registration : AudioContextRegistration , channel_config : ChannelConfig , attack : AudioParam , knee : AudioParam , ratio : AudioParam , release : AudioParam , threshold : AudioParam , reduction : Arc < AtomicF32 > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`GainNode`]\"] pub struct GainOptions { pub gain : f32 , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" AudioNode for volume control\"] pub struct GainNode { registration : AudioContextRegistration , channel_config : ChannelConfig , gain : AudioParam , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`IIRFilterNode`]\"] pub struct IIRFilterOptions { # [doc = \" audio node options\"] pub audio_node_options : AudioNodeOptions , # [doc = \" feedforward coefficients\"] pub feedforward : Vec < f64 > , # [doc = \" feedback coefficients\"] pub feedback : Vec < f64 > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" IIRFilterNode is an AudioNode processor implementing a general IIR\"] # [doc = \" (infinite impulse response)Filter.\"] # [doc = \"\"] # [doc = \" In general, you should prefer using a BiquadFilterNode for the following reasons:\"] # [doc = \" - Generally less sensitive to numeric issues\"] # [doc = \" - Filter parameters can be automated\"] # [doc = \" - Can be used to create all even-ordered IIR filters\"] # [doc = \"\"] # [doc = \" However, odd-ordered filters cannot be created with BiquadFilterNode, so if\"] # [doc = \" your application require such filters and/or automation is not needed, then IIR\"] # [doc = \" filters may be appropriate. In short, use this if you know what you are doing!\"] # [doc = \"\"] # [doc = \" Note that once created, the coefficients of the IIR filter cannot be changed.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/IIRFilterNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#IIRFilterNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_iir_filter`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" // create context and grab some audio buffer\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let file = File::open(\\\"samples/think-stereo-48000.wav\\\").unwrap();\"] # [doc = \" let buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \"\"] # [doc = \" // these coefficients correspond to a lowpass filter at 200Hz (calculated from biquad)\"] # [doc = \" let feedforward = vec![\"] # [doc = \"     0.0002029799640409502,\"] # [doc = \"     0.0004059599280819004,\"] # [doc = \"     0.0002029799640409502,\"] # [doc = \" ];\"] # [doc = \"\"] # [doc = \" let feedback = vec![\"] # [doc = \"     1.0126964557853775,\"] # [doc = \"     -1.9991880801438362,\"] # [doc = \"     0.9873035442146225,\"] # [doc = \" ];\"] # [doc = \"\"] # [doc = \" // create the IIR filter node\"] # [doc = \" let iir = context.create_iir_filter(feedforward, feedback);\"] # [doc = \" iir.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" // play the buffer and pipe it into the filter\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.connect(&iir);\"] # [doc = \" src.set_buffer(buffer);\"] # [doc = \" src.set_loop(true);\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example iir`\"] # [doc = \"\"] pub struct IIRFilterNode { # [doc = \" Represents the node instance and its associated audio context\"] registration : AudioContextRegistration , # [doc = \" Infos about audio node channel configuration\"] channel_config : ChannelConfig , # [doc = \" numerator filter's coefficients\"] feedforward : Vec < f64 > , # [doc = \" denomintor filter's coefficients\"] feedback : Vec < f64 > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`MediaElementAudioSourceNode`]\"] pub struct MediaElementAudioSourceOptions < 'a > { pub media_element : & 'a mut MediaElement , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" An audio source from an `<audio>` element\"] # [doc = \"\"] # [doc = \" - MDN documentation:\"] # [doc = \" <https://developer.mozilla.org/en-US/docs/Web/API/MediaElementAudioSourceNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#MediaElementAudioSourceNode>\"] # [doc = \" - see also:\"] # [doc = \" [`AudioContext::create_media_element_source`](crate::context::AudioContext::create_media_element_source)\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::MediaElement;\"] # [doc = \" use web_audio_api::node::AudioNode;\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let mut media = MediaElement::new(\\\"samples/major-scale.ogg\\\").unwrap();\"] # [doc = \"\"] # [doc = \" let mut src = context.create_media_element_source(&mut media);\"] # [doc = \" src.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" media.set_loop(true); // continuously loop\"] # [doc = \" media.set_current_time(1.0); // seek to offset\"] # [doc = \" media.play(); // start playing\"] # [doc = \"\"] # [doc = \" loop {}\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example media_element`\"] pub struct MediaElementAudioSourceNode { registration : AudioContextRegistration , channel_config : ChannelConfig , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" An audio stream destination (e.g. WebRTC sink)\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioDestinationNode>\"] # [doc = \" - specification: <https://www.w3.org/TR/webaudio/#mediastreamaudiodestinationnode>\"] # [doc = \" - see also: [`AudioContext::create_media_stream_destination`](crate::context::AudioContext::create_media_stream_destination)\"] # [doc = \"\"] # [doc = \" Since the w3c `MediaStream` interface is not part of this library, we cannot adhere to the\"] # [doc = \" official specification. Instead, you can pass in any callback that handles audio buffers.\"] # [doc = \"\"] # [doc = \" IMPORTANT: you must consume the buffers faster than the render thread produces them, or you\"] # [doc = \" will miss frames. Consider to spin up a dedicated thread to consume the buffers and cache them.\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" // Create an audio context where all audio nodes lives\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" // Create an oscillator node with sine (default) type\"] # [doc = \" let mut osc = context.create_oscillator();\"] # [doc = \"\"] # [doc = \" // Create a media destination node\"] # [doc = \" let dest = context.create_media_stream_destination();\"] # [doc = \" osc.connect(&dest);\"] # [doc = \" osc.start();\"] # [doc = \"\"] # [doc = \" // Handle recorded buffers\"] # [doc = \" println!(\\\"samples recorded:\\\");\"] # [doc = \" let mut samples_recorded = 0;\"] # [doc = \" for item in dest.stream().get_tracks()[0].iter() {\"] # [doc = \"     let buffer = item.unwrap();\"] # [doc = \"\"] # [doc = \"     // You could write the samples to a file here.\"] # [doc = \"     samples_recorded += buffer.length();\"] # [doc = \"     print!(\\\"{}\\\\r\\\", samples_recorded);\"] # [doc = \" }\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example recorder`\"] pub struct MediaStreamAudioDestinationNode { registration : AudioContextRegistration , channel_config : ChannelConfig , stream : MediaStream , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`MediaStreamAudioSourceNode`]\"] pub struct MediaStreamAudioSourceOptions < 'a > { pub media_stream : & 'a MediaStream , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" An audio source from a [`MediaStream`] (e.g. microphone input)\"] # [doc = \"\"] # [doc = \" IMPORTANT: the media stream is polled on the render thread so you must ensure the media stream\"] # [doc = \" iterator never blocks. Use a\"] # [doc = \" [`MediaElementAudioSourceNode`](crate::node::MediaElementAudioSourceNode) for real time safe\"] # [doc = \" media playback.\"] pub struct MediaStreamAudioSourceNode { registration : AudioContextRegistration , channel_config : ChannelConfig , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`MediaStreamTrackAudioSourceNode`]\"] pub struct MediaStreamTrackAudioSourceOptions < 'a > { pub media_stream_track : & 'a MediaStreamTrack , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" An audio source from a [`MediaStreamTrack`] (e.g. the audio track of the microphone input)\"] # [doc = \"\"] # [doc = \" Below is an example showing how to create and play a stream directly in the audio context.\"] # [doc = \" Take care:  The media stream will be polled on the render thread which will have catastrophic\"] # [doc = \" effects if the iterator blocks or for another reason takes too much time to yield a new sample\"] # [doc = \" frame.  Use a [`MediaElementAudioSourceNode`](crate::node::MediaElementAudioSourceNode) for\"] # [doc = \" real time safe media playback.\"] # [doc = \"\"] # [doc = \" # Example\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{AudioContext, BaseAudioContext};\"] # [doc = \" use web_audio_api::{AudioBuffer, AudioBufferOptions};\"] # [doc = \" use web_audio_api::node::AudioNode;\"] # [doc = \" use web_audio_api::media_streams::MediaStreamTrack;\"] # [doc = \"\"] # [doc = \" // create a new buffer: 512 samples of silence\"] # [doc = \" let options = AudioBufferOptions {\"] # [doc = \"     number_of_channels: 0,\"] # [doc = \"     length: 512,\"] # [doc = \"     sample_rate: 44_100.,\"] # [doc = \" };\"] # [doc = \" let silence = AudioBuffer::new(options);\"] # [doc = \"\"] # [doc = \" // create a sequence of this buffer\"] # [doc = \" let sequence = std::iter::repeat(silence).take(5);\"] # [doc = \"\"] # [doc = \" // the sequence should actually yield `Result<AudioBuffer, _>`s\"] # [doc = \" let sequence = sequence.map(|b| Ok(b));\"] # [doc = \"\"] # [doc = \" // convert to a media track\"] # [doc = \" let media = MediaStreamTrack::from_iter(sequence);\"] # [doc = \"\"] # [doc = \" // use in the web audio context\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" let node = context.create_media_stream_track_source(&media);\"] # [doc = \" node.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" loop {}\"] # [doc = \" ```\"] pub struct MediaStreamTrackAudioSourceNode { registration : AudioContextRegistration , channel_config : ChannelConfig , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`OscillatorNode`]\"] pub struct OscillatorOptions { # [doc = \" The shape of the periodic waveform\"] pub type_ : OscillatorType , # [doc = \" The frequency of the fundamental frequency.\"] pub frequency : f32 , # [doc = \" A detuning value (in cents) which will offset the frequency by the given amount.\"] pub detune : f32 , # [doc = \" Optional custom waveform, if specified (set `type` to \\\"custom\\\")\"] pub periodic_wave : Option < PeriodicWave > , # [doc = \" channel config options\"] pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Type of the waveform rendered by an `OscillatorNode`\"] pub enum OscillatorType { # [doc = \" Sine wave\"] Sine , # [doc = \" Square wave\"] Square , # [doc = \" Sawtooth wave\"] Sawtooth , # [doc = \" Triangle wave\"] Triangle , # [doc = \" type used when periodic_wave is specified\"] Custom , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `OscillatorNode` represents an audio source generating a periodic waveform.\"] # [doc = \" It can generate a few common waveforms (i.e. sine, square, sawtooth, triangle),\"] # [doc = \" or can be set to an arbitrary periodic waveform using a [`PeriodicWave`] object.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/OscillatorNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#OscillatorNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_oscillator`]\"] # [doc = \" - see also: [`PeriodicWave`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let mut osc = context.create_oscillator();\"] # [doc = \" osc.frequency().set_value(200.);\"] # [doc = \" osc.connect(&context.destination());\"] # [doc = \" osc.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example oscillators`\"] # [doc = \" - `cargo run --release --example many_oscillators_with_env`\"] # [doc = \" - `cargo run --release --example amplitude_modulation`\"] # [doc = \"\"] pub struct OscillatorNode { # [doc = \" Represents the node instance and its associated audio context\"] registration : AudioContextRegistration , # [doc = \" Infos about audio node channel configuration\"] channel_config : ChannelConfig , # [doc = \" The frequency of the fundamental frequency.\"] frequency : AudioParam , # [doc = \" A detuning value (in cents) which will offset the frequency by the given amount.\"] detune : AudioParam , # [doc = \" Waveform of an oscillator\"] type_ : OscillatorType , # [doc = \" Number of start/stop actions, node can only be started and stopped once\"] start_stop_count : u8 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Spatialization algorithm used to position the audio in 3D space\"] pub enum PanningModelType { # [default] EqualPower , HRTF , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Algorithm to reduce the volume of an audio source as it moves away from the listener\"] pub enum DistanceModelType { Linear , # [default] Inverse , Exponential , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`PannerNode`]\"] pub struct PannerOptions { pub panning_model : PanningModelType , pub distance_model : DistanceModelType , pub position_x : f32 , pub position_y : f32 , pub position_z : f32 , pub orientation_x : f32 , pub orientation_y : f32 , pub orientation_z : f32 , pub ref_distance : f64 , pub max_distance : f64 , pub rolloff_factor : f64 , pub cone_inner_angle : f64 , pub cone_outer_angle : f64 , pub cone_outer_gain : f64 , pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `PannerNode` positions / spatializes an incoming audio stream in three-dimensional space.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/PannerNode>\"] # [doc = \" - specification: <https://www.w3.org/TR/webaudio/#pannernode> and\"] # [doc = \" <https://www.w3.org/TR/webaudio/#Spatialization>\"] # [doc = \" - see also: [`BaseAudioContext::create_panner`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::AudioNode;\"] # [doc = \" use web_audio_api::node::AudioScheduledSourceNode;\"] # [doc = \"\"] # [doc = \" // Setup a new audio context\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" // Create a friendly tone\"] # [doc = \" let mut tone = context.create_oscillator();\"] # [doc = \" tone.frequency().set_value_at_time(300.0f32, 0.);\"] # [doc = \" tone.start();\"] # [doc = \"\"] # [doc = \" // Connect tone > panner node > destination node\"] # [doc = \" let panner = context.create_panner();\"] # [doc = \" tone.connect(&panner);\"] # [doc = \" panner.connect(&context.destination());\"] # [doc = \"\"] # [doc = \" // The panner node is 1 unit in front of listener\"] # [doc = \" panner.position_z().set_value_at_time(1., 0.);\"] # [doc = \"\"] # [doc = \" // And sweeps 10 units left to right, every second\"] # [doc = \" let mut moving = context.create_oscillator();\"] # [doc = \" moving.start();\"] # [doc = \" moving.frequency().set_value_at_time(1., 0.);\"] # [doc = \" let gain = context.create_gain();\"] # [doc = \" gain.gain().set_value_at_time(10., 0.);\"] # [doc = \" moving.connect(&gain);\"] # [doc = \" gain.connect(panner.position_x());\"] # [doc = \"\"] # [doc = \" // enjoy listening\"] # [doc = \" std::thread::sleep(std::time::Duration::from_secs(4));\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example spatial`\"] # [doc = \" - `cargo run --release --example panner_cone`\"] pub struct PannerNode { registration : AudioContextRegistration , channel_config : ChannelConfig , position_x : AudioParam , position_y : AudioParam , position_z : AudioParam , orientation_x : AudioParam , orientation_y : AudioParam , orientation_z : AudioParam , cone_inner_angle : f64 , cone_outer_angle : f64 , cone_outer_gain : f64 , distance_model : DistanceModelType , ref_distance : f64 , max_distance : f64 , rolloff_factor : f64 , panning_model : PanningModelType , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`ScriptProcessorNode`]\"] pub struct ScriptProcessorOptions { pub buffer_size : usize , pub number_of_input_channels : usize , pub number_of_output_channels : usize , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" An AudioNode which can generate, process, or analyse audio directly using a script (deprecated)\"] pub struct ScriptProcessorNode { registration : AudioContextRegistration , channel_config : ChannelConfig , buffer_size : usize , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing a [`StereoPannerOptions`]\"] pub struct StereoPannerOptions { # [doc = \" initial value for the pan parameter\"] pub pan : f32 , # [doc = \" audio node options\"] pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `StereoPannerNode` positions an incoming audio stream in a stereo image\"] # [doc = \"\"] # [doc = \" It is an audio-processing module that positions an incoming audio stream\"] # [doc = \" in a stereo image using a low-cost panning algorithm.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/StereoPannerNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#stereopannernode>\"] # [doc = \" - see also: [`BaseAudioContext::create_stereo_panner`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" // create an `AudioContext`\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \" // load and decode a soundfile\"] # [doc = \" let panner = context.create_stereo_panner();\"] # [doc = \" panner.connect(&context.destination());\"] # [doc = \" // position source on the left\"] # [doc = \" panner.pan().set_value(-1.);\"] # [doc = \"\"] # [doc = \" // pipe an oscillator into the stereo panner\"] # [doc = \" let mut osc = context.create_oscillator();\"] # [doc = \" osc.frequency().set_value(200.);\"] # [doc = \" osc.connect(&panner);\"] # [doc = \" osc.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example stereo_panner`\"] # [doc = \"\"] pub struct StereoPannerNode { # [doc = \" Represents the node instance and its associated audio context\"] registration : AudioContextRegistration , # [doc = \" Infos about audio node channel configuration\"] channel_config : ChannelConfig , # [doc = \" The position of the input in the output’s stereo image. -1 represents\"] # [doc = \" full left, +1 represents full right.\"] pan : AudioParam , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" enumerates the oversampling rate available for `WaveShaperNode`\"] pub enum OverSampleType { # [doc = \" No oversampling is applied\"] None , # [doc = \" Oversampled by a factor of 2\"] X2 , # [doc = \" Oversampled by a factor of 4\"] X4 , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `WaveShaperNode` options\"] pub struct WaveShaperOptions { # [doc = \" The distortion curve\"] pub curve : Option < Vec < f32 > > , # [doc = \" Oversampling rate - default to `None`\"] pub oversample : OverSampleType , # [doc = \" audio node options\"] pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" `WaveShaperNode` allows to apply non-linear distortion effect on a audio\"] # [doc = \" signal. Arbitrary non-linear shaping curves may be specified.\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/WaveShaperNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#WaveShaperNode>\"] # [doc = \" - see also: [`BaseAudioContext::create_wave_shaper`]\"] # [doc = \"\"] # [doc = \" # Usage\"] # [doc = \"\"] # [doc = \" ```no_run\"] # [doc = \" use std::fs::File;\"] # [doc = \" use web_audio_api::context::{BaseAudioContext, AudioContext};\"] # [doc = \" use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\"] # [doc = \"\"] # [doc = \" # use std::f32::consts::PI;\"] # [doc = \" # fn make_distortion_curve(size: usize) -> Vec<f32> {\"] # [doc = \" #     let mut curve = vec![0.; size];\"] # [doc = \" #     let mut phase = 0.;\"] # [doc = \" #     let phase_incr = PI / (size - 1) as f32;\"] # [doc = \" #     for i in 0..size {\"] # [doc = \" #         curve[i] = (PI + phase).cos();\"] # [doc = \" #         phase += phase_incr;\"] # [doc = \" #     }\"] # [doc = \" #     curve\"] # [doc = \" # }\"] # [doc = \" let context = AudioContext::default();\"] # [doc = \"\"] # [doc = \" let file = File::open(\\\"sample.wav\\\").unwrap();\"] # [doc = \" let buffer = context.decode_audio_data_sync(file).unwrap();\"] # [doc = \" let curve = make_distortion_curve(2048);\"] # [doc = \" let drive = 4.;\"] # [doc = \"\"] # [doc = \" let post_gain = context.create_gain();\"] # [doc = \" post_gain.connect(&context.destination());\"] # [doc = \" post_gain.gain().set_value(1. / drive);\"] # [doc = \"\"] # [doc = \" let mut shaper = context.create_wave_shaper();\"] # [doc = \" shaper.connect(&post_gain);\"] # [doc = \" shaper.set_curve(curve);\"] # [doc = \"\"] # [doc = \" let pre_gain = context.create_gain();\"] # [doc = \" pre_gain.connect(&shaper);\"] # [doc = \" pre_gain.gain().set_value(drive);\"] # [doc = \"\"] # [doc = \" let mut src = context.create_buffer_source();\"] # [doc = \" src.connect(&pre_gain);\"] # [doc = \" src.set_buffer(buffer);\"] # [doc = \"\"] # [doc = \" src.start();\"] # [doc = \" ```\"] # [doc = \"\"] # [doc = \" # Example\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example waveshaper`\"] pub struct WaveShaperNode { # [doc = \" Represents the node instance and its associated audio context\"] registration : AudioContextRegistration , # [doc = \" Infos about audio node channel configuration\"] channel_config : ChannelConfig , # [doc = \" distortion curve\"] curve : Option < Vec < f32 > > , # [doc = \" oversample type\"] oversample : OverSampleType , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , ConcreteBaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { ErrorEvent , EventHandler , EventPayload , EventType , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: message :: ControlMessage ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for ChannelCountMode { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelCountMode { # [inline] fn clone (& self) -> ChannelCountMode { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for ChannelCountMode { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for ChannelCountMode { # [inline] fn eq (& self , other : & ChannelCountMode) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for ChannelCountMode { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelCountMode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { ChannelCountMode :: Max => \"Max\" , ChannelCountMode :: ClampedMax => \"ClampedMax\" , ChannelCountMode :: Explicit => \"Explicit\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u32 > for ChannelCountMode { fn from (i : u32) -> Self { use ChannelCountMode :: * ; match i { 0 => Max , 1 => ClampedMax , 2 => Explicit , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for ChannelInterpretation { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelInterpretation { # [inline] fn clone (& self) -> ChannelInterpretation { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for ChannelInterpretation { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for ChannelInterpretation { # [inline] fn eq (& self , other : & ChannelInterpretation) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for ChannelInterpretation { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelInterpretation { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { ChannelInterpretation :: Speakers => \"Speakers\" , ChannelInterpretation :: Discrete => \"Discrete\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u32 > for ChannelInterpretation { fn from (i : u32) -> Self { use ChannelInterpretation :: * ; match i { 0 => Speakers , 1 => Discrete , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioNodeOptions { # [inline] fn clone (& self) -> AudioNodeOptions { AudioNodeOptions { channel_count : :: core :: clone :: Clone :: clone (& self . channel_count) , channel_count_mode : :: core :: clone :: Clone :: clone (& self . channel_count_mode) , channel_interpretation : :: core :: clone :: Clone :: clone (& self . channel_interpretation) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioNodeOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"AudioNodeOptions\" , \"channel_count\" , & self . channel_count , \"channel_count_mode\" , & self . channel_count_mode , \"channel_interpretation\" , & & self . channel_interpretation) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioNodeOptions { fn default () -> Self { Self { channel_count : 2 , channel_count_mode : ChannelCountMode :: Max , channel_interpretation : ChannelInterpretation :: Speakers , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelConfig { # [inline] fn clone (& self) -> ChannelConfig { ChannelConfig { inner : :: core :: clone :: Clone :: clone (& self . inner) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelConfigInner { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ChannelConfigInner\" , \"count\" , & self . count , \"count_mode\" , & self . count_mode , \"interpretation\" , & & self . interpretation) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelConfigInner { # [inline] fn clone (& self) -> ChannelConfigInner { ChannelConfigInner { count : :: core :: clone :: Clone :: clone (& self . count) , count_mode : :: core :: clone :: Clone :: clone (& self . count_mode) , interpretation : :: core :: clone :: Clone :: clone (& self . interpretation) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for ChannelConfig { fn default () -> Self { AudioNodeOptions :: default () . into () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for ChannelConfig { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"ChannelConfig\") . field (\"count\" , & self . count ()) . field (\"count_mode\" , & self . count_mode ()) . field (\"interpretation\" , & self . interpretation ()) . finish () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ChannelConfig { # [doc = \" Represents an enumerated value describing the way channels must be matched between the\"] # [doc = \" node's inputs and outputs.\"] pub (crate) fn count_mode (& self) -> ChannelCountMode { self . inner . lock () . unwrap () . count_mode } pub (super) fn set_count_mode (& self , v : ChannelCountMode , registration : & AudioContextRegistration) { let mut guard = self . inner . lock () . unwrap () ; guard . count_mode = v ; let message = ControlMessage :: SetChannelCountMode { id : registration . id () , mode : v , } ; registration . context () . send_control_msg (message) ; drop (guard) ; } # [doc = \" Represents an enumerated value describing the meaning of the channels. This interpretation\"] # [doc = \" will define how audio up-mixing and down-mixing will happen.\"] pub (crate) fn interpretation (& self) -> ChannelInterpretation { self . inner . lock () . unwrap () . interpretation } pub (super) fn set_interpretation (& self , v : ChannelInterpretation , registration : & AudioContextRegistration) { let mut guard = self . inner . lock () . unwrap () ; guard . interpretation = v ; let message = ControlMessage :: SetChannelInterpretation { id : registration . id () , interpretation : v , } ; registration . context () . send_control_msg (message) ; drop (guard) ; } # [doc = \" Represents an integer used to determine how many channels are used when up-mixing and\"] # [doc = \" down-mixing connections to any inputs to the node.\"] pub (crate) fn count (& self) -> usize { self . inner . lock () . unwrap () . count } pub (super) fn set_count (& self , v : usize , registration : & AudioContextRegistration) { crate :: assert_valid_number_of_channels (v) ; let mut guard = self . inner . lock () . unwrap () ; guard . count = v ; let message = ControlMessage :: SetChannelCount { id : registration . id () , count : v , } ; registration . context () . send_control_msg (message) ; drop (guard) ; } pub (crate) fn inner (& self) -> ChannelConfigInner { self . inner . lock () . unwrap () . clone () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_node",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < AudioNodeOptions > for ChannelConfig { fn from (opts : AudioNodeOptions) -> Self { crate :: assert_valid_number_of_channels (opts . channel_count) ; let inner = ChannelConfigInner { count : opts . channel_count , count_mode : opts . channel_count_mode , interpretation : opts . channel_interpretation , } ; Self { inner : Arc :: new (Mutex :: new (inner)) } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::scheduled_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: AudioNode ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::scheduled_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { Event , EventHandler , EventType } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: analysis :: { Analyser , AnalyserRingBuffer , DEFAULT_FFT_SIZE , DEFAULT_MAX_DECIBELS , DEFAULT_MIN_DECIBELS , DEFAULT_SMOOTHING_TIME_CONSTANT , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AnalyserOptions { # [inline] fn clone (& self) -> AnalyserOptions { AnalyserOptions { fft_size : :: core :: clone :: Clone :: clone (& self . fft_size) , max_decibels : :: core :: clone :: Clone :: clone (& self . max_decibels) , min_decibels : :: core :: clone :: Clone :: clone (& self . min_decibels) , smoothing_time_constant : :: core :: clone :: Clone :: clone (& self . smoothing_time_constant) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AnalyserOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"AnalyserOptions\" , \"fft_size\" , & self . fft_size , \"max_decibels\" , & self . max_decibels , \"min_decibels\" , & self . min_decibels , \"smoothing_time_constant\" , & self . smoothing_time_constant , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AnalyserOptions { fn default () -> Self { Self { fft_size : DEFAULT_FFT_SIZE , max_decibels : DEFAULT_MAX_DECIBELS , min_decibels : DEFAULT_MIN_DECIBELS , smoothing_time_constant : DEFAULT_SMOOTHING_TIME_CONSTANT , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AnalyserNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"AnalyserNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"analyser\" , & & self . analyser) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for AnalyserNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AnalyserNode { pub fn new < C : BaseAudioContext > (context : & C , options : AnalyserOptions) -> Self { context . base () . register (move | registration | { let fft_size = options . fft_size ; let smoothing_time_constant = options . smoothing_time_constant ; let min_decibels = options . min_decibels ; let max_decibels = options . max_decibels ; let mut analyser = Analyser :: new () ; analyser . set_fft_size (fft_size) ; analyser . set_smoothing_time_constant (smoothing_time_constant) ; analyser . set_decibels (min_decibels , max_decibels) ; let render = AnalyserRenderer { ring_buffer : analyser . get_ring_buffer_clone () , } ; let node = AnalyserNode { registration , channel_config : options . audio_node_options . into () , analyser , } ; (node , Box :: new (render)) }) } # [doc = \" The size of the FFT used for frequency-domain analysis (in sample-frames)\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn fft_size (& self) -> usize { self . analyser . fft_size () } # [doc = \" Set FFT size\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if fft_size is not a power of two or not in the range [32, 32768]\"] pub fn set_fft_size (& mut self , fft_size : usize) { self . analyser . set_fft_size (fft_size) ; } # [doc = \" Time averaging parameter with the last analysis frame.\"] # [doc = \" A value from 0 -> 1 where 0 represents no time averaging with the last\"] # [doc = \" analysis frame. The default value is 0.8.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn smoothing_time_constant (& self) -> f64 { self . analyser . smoothing_time_constant () } # [doc = \" Set smoothing time constant\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if the value is set to a value less than 0 or more than 1.\"] pub fn set_smoothing_time_constant (& mut self , value : f64) { self . analyser . set_smoothing_time_constant (value) ; } # [doc = \" Minimum power value in the scaling range for the FFT analysis data for\"] # [doc = \" conversion to unsigned byte values. The default value is -100.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn min_decibels (& self) -> f64 { self . analyser . min_decibels () } # [doc = \" Set min decibels\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if the value is set to a value more than or equal\"] # [doc = \" to max decibels.\"] pub fn set_min_decibels (& mut self , value : f64) { self . analyser . set_decibels (value , self . max_decibels ()) ; } # [doc = \" Maximum power value in the scaling range for the FFT analysis data for\"] # [doc = \" conversion to unsigned byte values. The default value is -30.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn max_decibels (& self) -> f64 { self . analyser . max_decibels () } # [doc = \" Set max decibels\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if the value is set to a value less than or equal\"] # [doc = \" to min decibels.\"] pub fn set_max_decibels (& mut self , value : f64) { self . analyser . set_decibels (self . min_decibels () , value) ; } # [doc = \" Number of bins in the FFT results, is half the FFT size\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn frequency_bin_count (& self) -> usize { self . analyser . frequency_bin_count () } # [doc = \" Copy the current time domain data as f32 values into the provided buffer\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn get_float_time_domain_data (& mut self , buffer : & mut [f32]) { self . analyser . get_float_time_domain_data (buffer) ; } # [doc = \" Copy the current time domain data as u8 values into the provided buffer\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn get_byte_time_domain_data (& mut self , buffer : & mut [u8]) { self . analyser . get_byte_time_domain_data (buffer) ; } # [doc = \" Copy the current frequency data into the provided buffer\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn get_float_frequency_data (& mut self , buffer : & mut [f32]) { let current_time = self . registration . context () . current_time () ; self . analyser . get_float_frequency_data (buffer , current_time) ; } # [doc = \" Copy the current frequency data scaled between min_decibels and\"] # [doc = \" max_decibels into the provided buffer\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method may panic if the lock to the inner analyser is poisoned\"] pub fn get_byte_frequency_data (& mut self , buffer : & mut [u8]) { let current_time = self . registration . context () . current_time () ; self . analyser . get_byte_frequency_data (buffer , current_time) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::analyser",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for AnalyserRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; * output = input . clone () ; let mut mono = input . clone () ; mono . mix (1 , ChannelInterpretation :: Speakers) ; let data = mono . channel_data (0) . as_ref () ; self . ring_buffer . write (data) ; false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: Ordering ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor , AutomationRate } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { assert_valid_time_value , AtomicF64 , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioScheduledSourceNode , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioBufferSourceOptions { # [inline] fn clone (& self) -> AudioBufferSourceOptions { AudioBufferSourceOptions { buffer : :: core :: clone :: Clone :: clone (& self . buffer) , detune : :: core :: clone :: Clone :: clone (& self . detune) , loop_ : :: core :: clone :: Clone :: clone (& self . loop_) , loop_start : :: core :: clone :: Clone :: clone (& self . loop_start) , loop_end : :: core :: clone :: Clone :: clone (& self . loop_end) , playback_rate : :: core :: clone :: Clone :: clone (& self . playback_rate) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioBufferSourceOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"buffer\" , \"detune\" , \"loop_\" , \"loop_start\" , \"loop_end\" , \"playback_rate\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . buffer , & self . detune , & self . loop_ , & self . loop_start , & self . loop_end , & & self . playback_rate] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioBufferSourceOptions\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioBufferSourceOptions { fn default () -> Self { Self { buffer : None , detune : 0. , loop_ : false , loop_start : 0. , loop_end : 0. , playback_rate : 1. , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PlaybackInfo { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"PlaybackInfo\" , \"prev_frame_index\" , & self . prev_frame_index , \"k\" , & & self . k) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for PlaybackInfo { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for PlaybackInfo { # [inline] fn clone (& self) -> PlaybackInfo { let _ : :: core :: clone :: AssertParamIsClone < usize > ; let _ : :: core :: clone :: AssertParamIsClone < f32 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for LoopState { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"LoopState\" , \"is_looping\" , & self . is_looping , \"start\" , & self . start , \"end\" , & & self . end) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for LoopState { # [inline] fn clone (& self) -> LoopState { let _ : :: core :: clone :: AssertParamIsClone < bool > ; let _ : :: core :: clone :: AssertParamIsClone < f64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for LoopState { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ControlMessage { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { ControlMessage :: StartWithOffsetAndDuration (__self_0 , __self_1 , __self_2) => :: core :: fmt :: Formatter :: debug_tuple_field3_finish (f , \"StartWithOffsetAndDuration\" , __self_0 , __self_1 , & __self_2) , ControlMessage :: Stop (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Stop\" , & __self_0) , ControlMessage :: Loop (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Loop\" , & __self_0) , ControlMessage :: LoopStart (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"LoopStart\" , & __self_0) , ControlMessage :: LoopEnd (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"LoopEnd\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ControlMessage { # [inline] fn clone (& self) -> ControlMessage { match self { ControlMessage :: StartWithOffsetAndDuration (__self_0 , __self_1 , __self_2) => ControlMessage :: StartWithOffsetAndDuration (:: core :: clone :: Clone :: clone (__self_0) , :: core :: clone :: Clone :: clone (__self_1) , :: core :: clone :: Clone :: clone (__self_2)) , ControlMessage :: Stop (__self_0) => ControlMessage :: Stop (:: core :: clone :: Clone :: clone (__self_0)) , ControlMessage :: Loop (__self_0) => ControlMessage :: Loop (:: core :: clone :: Clone :: clone (__self_0)) , ControlMessage :: LoopStart (__self_0) => ControlMessage :: LoopStart (:: core :: clone :: Clone :: clone (__self_0)) , ControlMessage :: LoopEnd (__self_0) => ControlMessage :: LoopEnd (:: core :: clone :: Clone :: clone (__self_0)) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioBufferSourceNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"registration\" , \"channel_config\" , \"detune\" , \"playback_rate\" , \"buffer_time\" , \"buffer\" , \"loop_state\" , \"start_stop_count\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . registration , & self . channel_config , & self . detune , & self . playback_rate , & self . buffer_time , & self . buffer , & self . loop_state , & & self . start_stop_count] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioBufferSourceNode\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for AudioBufferSourceNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 0 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioScheduledSourceNode for AudioBufferSourceNode { fn start (& mut self) { let start = self . registration . context () . current_time () ; self . start_at_with_offset_and_duration (start , 0. , f64 :: MAX) ; } fn start_at (& mut self , when : f64) { self . start_at_with_offset_and_duration (when , 0. , f64 :: MAX) ; } fn stop (& mut self) { let stop = self . registration . context () . current_time () ; self . stop_at (stop) ; } fn stop_at (& mut self , when : f64) { assert_valid_time_value (when) ; match (& self . start_stop_count , & 1) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError cannot stop before start\"))) ; } } } ; self . start_stop_count += 1 ; self . registration . post_message (ControlMessage :: Stop (when)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioBufferSourceNode { # [doc = \" Create a new [`AudioBufferSourceNode`] instance\"] pub fn new < C : BaseAudioContext > (context : & C , options : AudioBufferSourceOptions) -> Self { let AudioBufferSourceOptions { buffer , detune , loop_ , loop_start , loop_end , playback_rate } = options ; let mut node = context . base () . register (move | registration | { let detune_param_options = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : f32 :: MAX , default_value : 0. , automation_rate : AutomationRate :: K , } ; let (mut d_param , d_proc) = context . create_audio_param (detune_param_options , & registration) ; d_param . set_automation_rate_constrained (true) ; d_param . set_value (detune) ; let playback_rate_param_options = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : f32 :: MAX , default_value : 1. , automation_rate : AutomationRate :: K , } ; let (mut pr_param , pr_proc) = context . create_audio_param (playback_rate_param_options , & registration) ; pr_param . set_automation_rate_constrained (true) ; pr_param . set_value (playback_rate) ; let loop_state = LoopState { is_looping : loop_ , start : loop_start , end : loop_end , } ; let renderer = AudioBufferSourceRenderer { start_time : f64 :: MAX , stop_time : f64 :: MAX , duration : f64 :: MAX , offset : 0. , buffer : None , detune : d_proc , playback_rate : pr_proc , loop_state , render_state : AudioBufferRendererState :: default () , ended_triggered : false , } ; let node = Self { registration , channel_config : ChannelConfig :: default () , detune : d_param , playback_rate : pr_param , buffer_time : Arc :: clone (& renderer . render_state . buffer_time) , buffer : None , loop_state , start_stop_count : 0 , } ; (node , Box :: new (renderer)) }) ; if let Some (buf) = buffer { node . set_buffer (buf) ; } node } # [doc = \" Start the playback at the given time and with a given offset\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the source was already started\"] pub fn start_at_with_offset (& mut self , start : f64 , offset : f64) { self . start_at_with_offset_and_duration (start , offset , f64 :: MAX) ; } # [doc = \" Start the playback at the given time, with a given offset, for a given duration\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the source was already started\"] pub fn start_at_with_offset_and_duration (& mut self , start : f64 , offset : f64 , duration : f64) { assert_valid_time_value (start) ; assert_valid_time_value (offset) ; assert_valid_time_value (duration) ; match (& self . start_stop_count , & 0) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError - Cannot call `start` twice\"))) ; } } } ; self . start_stop_count += 1 ; let control = ControlMessage :: StartWithOffsetAndDuration (start , offset , duration) ; self . registration . post_message (control) ; } # [doc = \" Current buffer value (nullable)\"] pub fn buffer (& self) -> Option < & AudioBuffer > { self . buffer . as_ref () } # [doc = \" Provide an [`AudioBuffer`] as the source of data to be played bask\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if a buffer has already been given to the source (though `new` or through\"] # [doc = \" `set_buffer`)\"] pub fn set_buffer (& mut self , audio_buffer : AudioBuffer) { let clone = audio_buffer . clone () ; if ! self . buffer . is_none () { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError - cannot assign buffer twice\")) ; } } ; self . buffer = Some (audio_buffer) ; self . registration . post_message (clone) ; } # [doc = \" K-rate [`AudioParam`] that defines the speed at which the [`AudioBuffer`]\"] # [doc = \" will be played, e.g.:\"] # [doc = \" - `0.5` will play the file at half speed\"] # [doc = \" - `-1` will play the file in reverse\"] # [doc = \"\"] # [doc = \" Note that playback rate will also alter the pitch of the [`AudioBuffer`]\"] pub fn playback_rate (& self) -> & AudioParam { & self . playback_rate } # [doc = \" Current playhead position in seconds within the [`AudioBuffer`].\"] # [doc = \"\"] # [doc = \" This value is updated at the end of each render quantum.\"] # [doc = \"\"] # [doc = \" Unofficial v2 API extension, not part of the spec yet.\"] # [doc = \" See also: <https://github.com/WebAudio/web-audio-api/issues/2397#issuecomment-709478405>\"] pub fn position (& self) -> f64 { self . buffer_time . load (Ordering :: Relaxed) } # [doc = \" K-rate [`AudioParam`] that defines a pitch transposition of the file,\"] # [doc = \" expressed in cents\"] # [doc = \"\"] # [doc = \" see <https://en.wikipedia.org/wiki/Cent_(music)>\"] pub fn detune (& self) -> & AudioParam { & self . detune } # [doc = \" Defines if the playback the [`AudioBuffer`] should be looped\"] # [allow (clippy :: missing_panics_doc)] pub fn loop_ (& self) -> bool { self . loop_state . is_looping } pub fn set_loop (& mut self , value : bool) { self . loop_state . is_looping = value ; self . registration . post_message (ControlMessage :: Loop (value)) ; } # [doc = \" Defines the loop start point, in the time reference of the [`AudioBuffer`]\"] pub fn loop_start (& self) -> f64 { self . loop_state . start } pub fn set_loop_start (& mut self , value : f64) { self . loop_state . start = value ; self . registration . post_message (ControlMessage :: LoopStart (value)) ; } # [doc = \" Defines the loop end point, in the time reference of the [`AudioBuffer`]\"] pub fn loop_end (& self) -> f64 { self . loop_state . end } pub fn set_loop_end (& mut self , value : f64) { self . loop_state . end = value ; self . registration . post_message (ControlMessage :: LoopEnd (value)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for AudioBufferRendererState { fn default () -> Self { Self { buffer_time : Arc :: new (AtomicF64 :: new (0.)) , started : false , entered_loop : false , buffer_time_elapsed : 0. , is_aligned : false , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioBufferSourceRenderer { fn handle_control_message (& mut self , control : & ControlMessage) { match control { ControlMessage :: StartWithOffsetAndDuration (when , offset , duration) => { self . start_time = * when ; self . offset = * offset ; self . duration = * duration ; } ControlMessage :: Stop (when) => self . stop_time = * when , ControlMessage :: Loop (is_looping) => self . loop_state . is_looping = * is_looping , ControlMessage :: LoopStart (loop_start) => self . loop_state . start = * loop_start , ControlMessage :: LoopEnd (loop_end) => self . loop_state . end = * loop_end , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::audio_buffer_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for AudioBufferSourceRenderer { fn process (& mut self , _inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let output = & mut outputs [0] ; let sample_rate = scope . sample_rate as f64 ; let dt = 1. / sample_rate ; let block_duration = dt * RENDER_QUANTUM_SIZE as f64 ; let next_block_time = scope . current_time + block_duration ; if self . start_time >= next_block_time { output . make_silent () ; return self . start_time != f64 :: MAX ; } let buffer = match & self . buffer { None => { output . make_silent () ; return false ; } Some (b) => b , } ; let LoopState { is_looping , start : loop_start , end : loop_end } = self . loop_state ; let mut actual_loop_start = 0. ; let mut actual_loop_end = 0. ; let detune = params . get (& self . detune) [0] ; let playback_rate = params . get (& self . playback_rate) [0] ; let computed_playback_rate = (playback_rate * (detune / 1200.) . exp2 ()) as f64 ; let buffer_duration = buffer . duration () ; let sampling_ratio = buffer . sample_rate () as f64 / sample_rate ; let mut buffer_time = self . render_state . buffer_time . load (Ordering :: Relaxed) ; if scope . current_time >= self . stop_time || self . render_state . buffer_time_elapsed >= self . duration || ! is_looping && (computed_playback_rate > 0. && buffer_time >= buffer_duration || computed_playback_rate < 0. && buffer_time < 0.) { output . make_silent () ; if ! self . ended_triggered { scope . send_ended_event () ; self . ended_triggered = true ; } return false ; } output . set_number_of_channels (buffer . number_of_channels ()) ; let block_time = scope . current_time ; if ! self . render_state . started && self . start_time < block_time { self . start_time = block_time ; } if self . start_time == block_time && self . offset == 0. { self . render_state . is_aligned = true ; } if sampling_ratio != 1. || computed_playback_rate != 1. { self . render_state . is_aligned = false ; } if loop_start != 0. || (loop_end != 0. && loop_end != self . duration) { self . render_state . is_aligned = false ; } if self . render_state . is_aligned { if self . start_time == block_time { self . render_state . started = true ; } if buffer_time + block_duration > buffer_duration || buffer_time + block_duration > self . duration || block_time + block_duration > self . stop_time { let end_index = if block_time + block_duration > self . stop_time || buffer_time + block_duration > self . duration { let dt = (self . stop_time - block_time) . min (self . duration - buffer_time) ; let end_buffer_time = buffer_time + dt ; let end_index = (end_buffer_time * sample_rate) . round () as usize ; end_index . min (buffer . length ()) } else { buffer . length () } ; let mut loop_point_index : Option < usize > = None ; buffer . channels () . iter () . zip (output . channels_mut () . iter_mut ()) . for_each (| (buffer_channel , output_channel) | { let buffer_channel = buffer_channel . as_slice () ; let mut start_index = (buffer_time * sample_rate) . round () as usize ; let mut offset = 0 ; for (index , o) in output_channel . iter_mut () . enumerate () { let mut buffer_index = start_index + index - offset ; * o = if buffer_index < end_index { buffer_channel [buffer_index] } else { if is_looping && buffer_index == end_index { loop_point_index = Some (index) ; start_index = 0 ; offset = index ; buffer_index = 0 ; } if is_looping { buffer_channel [buffer_index] } else { 0. } } ; } }) ; if let Some (loop_point_index) = loop_point_index { buffer_time = ((RENDER_QUANTUM_SIZE - loop_point_index) as f64 / sample_rate) % buffer_duration ; } else { buffer_time += block_duration ; } } else { let start_index = (buffer_time * sample_rate) . round () as usize ; let end_index = start_index + RENDER_QUANTUM_SIZE ; buffer . channels () . iter () . zip (output . channels_mut () . iter_mut ()) . for_each (| (buffer_channel , output_channel) | { let buffer_channel = buffer_channel . as_slice () ; output_channel . copy_from_slice (& buffer_channel [start_index .. end_index]) ; }) ; buffer_time += block_duration ; } self . render_state . buffer_time . store (buffer_time , Ordering :: Relaxed) ; self . render_state . buffer_time_elapsed += block_duration ; return true ; } if is_looping { if loop_start >= 0. && loop_end > 0. && loop_start < loop_end { actual_loop_start = loop_start ; actual_loop_end = loop_end . min (buffer_duration) ; } else { actual_loop_start = 0. ; actual_loop_end = buffer_duration ; } } else { self . render_state . entered_loop = false ; } let mut playback_infos = [None ; RENDER_QUANTUM_SIZE] ; for (i , playback_info) in playback_infos . iter_mut () . enumerate () { let current_time = block_time + i as f64 * dt ; if current_time < self . start_time || current_time >= self . stop_time || self . render_state . buffer_time_elapsed >= self . duration { continue ; } if ! self . render_state . started { self . offset += current_time - self . start_time ; if is_looping && computed_playback_rate >= 0. && self . offset >= actual_loop_end { self . offset = actual_loop_end ; } if is_looping && computed_playback_rate < 0. && self . offset < actual_loop_start { self . offset = actual_loop_start ; } buffer_time = self . offset ; self . render_state . started = true ; } if is_looping { if ! self . render_state . entered_loop { if self . offset < actual_loop_end && buffer_time >= actual_loop_start { self . render_state . entered_loop = true ; } if self . offset >= actual_loop_end && buffer_time < actual_loop_end { self . render_state . entered_loop = true ; } } if self . render_state . entered_loop { while buffer_time >= actual_loop_end { buffer_time -= actual_loop_end - actual_loop_start ; } while buffer_time < actual_loop_start { buffer_time += actual_loop_end - actual_loop_start ; } } } if buffer_time >= 0. && buffer_time < buffer_duration { let position = buffer_time * sampling_ratio ; let playhead = position * sample_rate ; let playhead_floored = playhead . floor () ; let prev_frame_index = playhead_floored as usize ; let k = (playhead - playhead_floored) as f32 ; * playback_info = Some (PlaybackInfo { prev_frame_index , k }) ; } let time_incr = dt * computed_playback_rate ; buffer_time += time_incr ; self . render_state . buffer_time_elapsed += time_incr ; } buffer . channels () . iter () . zip (output . channels_mut () . iter_mut ()) . for_each (| (buffer_channel , output_channel) | { let buffer_channel = buffer_channel . as_slice () ; playback_infos . iter () . zip (output_channel . iter_mut ()) . for_each (| (playhead , o) | { * o = match playhead { Some (PlaybackInfo { prev_frame_index , k }) => { let prev_sample = buffer_channel [* prev_frame_index] ; let next_sample = match buffer_channel . get (prev_frame_index + 1) { Some (val) => * val , None => 0. , } ; (1. - k) . mul_add (prev_sample , k * next_sample) } None => 0. , } ; }) ; }) ; self . render_state . buffer_time . store (buffer_time , Ordering :: Relaxed) ; true } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (control) = msg . downcast_ref :: < ControlMessage > () { self . handle_control_message (control) ; return ; } ; if let Some (buffer) = msg . downcast_mut :: < AudioBuffer > () { if let Some (current_buffer) = & mut self . buffer { std :: mem :: swap (current_buffer , buffer) ; } else { let tombstone_buffer = AudioBuffer { channels : Default :: default () , sample_rate : Default :: default () , } ; self . buffer = Some (std :: mem :: replace (buffer , tombstone_buffer)) ; } return ; } ; { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"AudioBufferSourceRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::audio_buffer_source\" , \"web_audio_api::node::audio_buffer_source\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/audio_buffer_source.rs\") , 772u32 , ()) ; } } ; } fn before_drop (& mut self , scope : & AudioWorkletGlobalScope) { if ! self . ended_triggered && scope . current_time >= self . start_time { scope . send_ended_event () ; self . ended_triggered = true ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: f64 :: consts :: { PI , SQRT_2 } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use arrayvec :: ArrayVec ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use num_complex :: Complex ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { MAX_CHANNELS , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for Coefficients { # [inline] fn clone (& self) -> Coefficients { let _ : :: core :: clone :: AssertParamIsClone < f64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for Coefficients { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for Coefficients { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"Coefficients\" , \"b0\" , & self . b0 , \"b1\" , & self . b1 , \"b2\" , & self . b2 , \"a1\" , & self . a1 , \"a2\" , & & self . a2) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for Coefficients { # [inline] fn default () -> Coefficients { Coefficients { b0 : :: core :: default :: Default :: default () , b1 : :: core :: default :: Default :: default () , b2 : :: core :: default :: Default :: default () , a1 : :: core :: default :: Default :: default () , a2 : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for BiquadFilterType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { BiquadFilterType :: Lowpass => \"Lowpass\" , BiquadFilterType :: Highpass => \"Highpass\" , BiquadFilterType :: Bandpass => \"Bandpass\" , BiquadFilterType :: Notch => \"Notch\" , BiquadFilterType :: Allpass => \"Allpass\" , BiquadFilterType :: Peaking => \"Peaking\" , BiquadFilterType :: Lowshelf => \"Lowshelf\" , BiquadFilterType :: Highshelf => \"Highshelf\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for BiquadFilterType { # [inline] fn clone (& self) -> BiquadFilterType { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for BiquadFilterType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for BiquadFilterType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for BiquadFilterType { # [inline] fn eq (& self , other : & BiquadFilterType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for BiquadFilterType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for BiquadFilterType { fn default () -> Self { Self :: Lowpass } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u32 > for BiquadFilterType { fn from (i : u32) -> Self { match i { 0 => BiquadFilterType :: Lowpass , 1 => BiquadFilterType :: Highpass , 2 => BiquadFilterType :: Bandpass , 3 => BiquadFilterType :: Notch , 4 => BiquadFilterType :: Allpass , 5 => BiquadFilterType :: Peaking , 6 => BiquadFilterType :: Lowshelf , 7 => BiquadFilterType :: Highshelf , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for BiquadFilterOptions { # [inline] fn clone (& self) -> BiquadFilterOptions { BiquadFilterOptions { q : :: core :: clone :: Clone :: clone (& self . q) , detune : :: core :: clone :: Clone :: clone (& self . detune) , frequency : :: core :: clone :: Clone :: clone (& self . frequency) , gain : :: core :: clone :: Clone :: clone (& self . gain) , type_ : :: core :: clone :: Clone :: clone (& self . type_) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for BiquadFilterOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"q\" , \"detune\" , \"frequency\" , \"gain\" , \"type_\" , \"audio_node_options\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . q , & self . detune , & self . frequency , & self . gain , & self . type_ , & & self . audio_node_options] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"BiquadFilterOptions\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for BiquadFilterOptions { fn default () -> Self { Self { q : 1. , detune : 0. , frequency : 350. , gain : 0. , type_ : BiquadFilterType :: default () , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for BiquadFilterNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"registration\" , \"channel_config\" , \"q\" , \"detune\" , \"frequency\" , \"gain\" , \"type_\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . registration , & self . channel_config , & self . q , & self . detune , & self . frequency , & self . gain , & & self . type_] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"BiquadFilterNode\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for BiquadFilterNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl BiquadFilterNode { # [doc = \" returns a `BiquadFilterNode` instance\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `context` - audio context in which the audio node will live.\"] # [doc = \" * `options` - biquad filter options\"] pub fn new < C : BaseAudioContext > (context : & C , options : BiquadFilterOptions) -> Self { context . base () . register (move | registration | { let sample_rate = context . sample_rate () ; let BiquadFilterOptions { q , detune , frequency , gain , type_ , audio_node_options : channel_config } = options ; let q_param_options = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : f32 :: MAX , default_value : 1. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (q_param , q_proc) = context . create_audio_param (q_param_options , & registration) ; q_param . set_value (q) ; let detune_param_options = AudioParamDescriptor { name : String :: new () , min_value : - 153_600. , max_value : 153_600. , default_value : 0. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (d_param , d_proc) = context . create_audio_param (detune_param_options , & registration) ; d_param . set_value (detune) ; let freq_options = AudioParamDescriptor { name : String :: new () , min_value : 0. , max_value : sample_rate / 2. , default_value : 350. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (f_param , f_proc) = context . create_audio_param (freq_options , & registration) ; f_param . set_value (frequency) ; let gain_options = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : 40. * f32 :: MAX . log10 () , default_value : 0. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (g_param , g_proc) = context . create_audio_param (gain_options , & registration) ; g_param . set_value (gain) ; let renderer = BiquadFilterRenderer { gain : g_proc , detune : d_proc , frequency : f_proc , q : q_proc , type_ , xy : ArrayVec :: new () , } ; let node = Self { registration , channel_config : channel_config . into () , type_ , q : q_param , detune : d_param , frequency : f_param , gain : g_param , } ; (node , Box :: new (renderer)) }) } # [doc = \" Returns the gain audio parameter\"] # [must_use] pub fn gain (& self) -> & AudioParam { & self . gain } # [doc = \" Returns the frequency audio parameter\"] # [must_use] pub fn frequency (& self) -> & AudioParam { & self . frequency } # [doc = \" Returns the detune audio parameter\"] # [must_use] pub fn detune (& self) -> & AudioParam { & self . detune } # [doc = \" Returns the Q audio parameter\"] # [must_use] pub fn q (& self) -> & AudioParam { & self . q } # [doc = \" Returns the biquad filter type\"] # [must_use] pub fn type_ (& self) -> BiquadFilterType { self . type_ } # [doc = \" biquad filter type setter\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `type_` - the biquad filter type (lowpass, highpass,...)\"] pub fn set_type (& mut self , type_ : BiquadFilterType) { self . type_ = type_ ; self . registration . post_message (type_) ; } # [doc = \" Returns the frequency response for the specified frequencies\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `frequency_hz` - frequencies for which frequency response of the filter should be calculated\"] # [doc = \" * `mag_response` - magnitude of the frequency response of the filter\"] # [doc = \" * `phase_response` - phase of the frequency response of the filter\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if arguments' lengths don't match\"] # [doc = \"\"] pub fn get_frequency_response (& self , frequency_hz : & [f32] , mag_response : & mut [f32] , phase_response : & mut [f32]) { if ! (frequency_hz . len () == mag_response . len () && mag_response . len () == phase_response . len ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Parameter lengths must match\")) ; } } ; let sample_rate = self . context () . sample_rate () ; let n_quist = sample_rate / 2. ; let type_ = self . type_ () ; let frequency = self . frequency () . value () ; let detune = self . detune () . value () ; let gain = self . gain () . value () ; let q = self . q () . value () ; let computed_freq = get_computed_freq (frequency , detune , sample_rate) ; let Coefficients { b0 , b1 , b2 , a1 , a2 } = calculate_coefs (type_ , sample_rate as f64 , computed_freq as f64 , gain as f64 , q as f64) ; for (i , & freq) in frequency_hz . iter () . enumerate () { if freq < 0. || freq > n_quist { mag_response [i] = f32 :: NAN ; phase_response [i] = f32 :: NAN ; } else { let f = freq / n_quist ; let omega = - 1. * PI * f64 :: from (f) ; let z = Complex :: new (omega . cos () , omega . sin ()) ; let numerator = b0 + (b1 + b2 * z) * z ; let denominator = Complex :: new (1. , 0.) + (a1 + a2 * z) * z ; let response = numerator / denominator ; let (mag , phase) = response . to_polar () ; mag_response [i] = mag as f32 ; phase_response [i] = phase as f32 ; } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::biquad_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for BiquadFilterRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; let sample_rate = scope . sample_rate ; if input . is_silent () { let mut ended = true ; if self . xy . iter () . any (| v | v . iter () . copied () . any (f64 :: is_normal)) { ended = false ; } if ended { output . make_silent () ; return false ; } } if ! input . is_silent () { let num_channels = input . number_of_channels () ; if num_channels != self . xy . len () { self . xy . truncate (num_channels) ; for _ in self . xy . len () .. num_channels { self . xy . push ([0. ; 4]) ; } } output . set_number_of_channels (num_channels) ; } else { let num_channels = self . xy . len () ; output . set_number_of_channels (num_channels) ; } let type_ = self . type_ ; let frequency = params . get (& self . frequency) ; let detune = params . get (& self . detune) ; let q = params . get (& self . q) ; let gain = params . get (& self . gain) ; let sample_rate_f64 = f64 :: from (sample_rate) ; let computed_freq = get_computed_freq (frequency [0] , detune [0] , sample_rate) ; let coef = calculate_coefs (type_ , sample_rate_f64 , f64 :: from (computed_freq) , f64 :: from (gain [0]) , f64 :: from (q [0])) ; let mut coefs_list = [coef ; RENDER_QUANTUM_SIZE] ; if frequency . len () != 1 || detune . len () != 1 || q . len () != 1 || gain . len () != 1 { coefs_list . iter_mut () . zip (frequency . iter () . cycle ()) . zip (detune . iter () . cycle ()) . zip (q . iter () . cycle ()) . zip (gain . iter () . cycle ()) . skip (1) . for_each (| ((((coefs , & f) , & d) , & q) , & g) | { let computed_freq = get_computed_freq (f , d , sample_rate) ; * coefs = calculate_coefs (type_ , sample_rate_f64 , f64 :: from (computed_freq) , f64 :: from (g) , f64 :: from (q)) ; }) ; } ; for (channel_number , output_channel) in output . channels_mut () . iter_mut () . enumerate () { let input_channel = if input . is_silent () { input . channel_data (0) } else { input . channel_data (channel_number) } ; let (mut x1 , mut x2 , mut y1 , mut y2) = match self . xy [channel_number] { [x1 , x2 , y1 , y2] => (x1 , x2 , y1 , y2) , } ; output_channel . iter_mut () . zip (input_channel . iter ()) . zip (coefs_list . iter ()) . for_each (| ((o , & i) , c) | { let x = f64 :: from (i) ; let y = c . b0 * x + c . b1 * x1 + c . b2 * x2 - c . a1 * y1 - c . a2 * y2 ; x2 = x1 ; x1 = x ; y2 = y1 ; y1 = y ; * o = y as f32 ; }) ; self . xy [channel_number] = [x1 , x2 , y1 , y2] ; } true } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (& type_) = msg . downcast_ref :: < BiquadFilterType > () { self . type_ = type_ ; return ; } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"BiquadFilterRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::biquad_filter\" , \"web_audio_api::node::biquad_filter\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/biquad_filter.rs\") , 702u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: fmt :: Debug ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: MAX_CHANNELS ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelMergerOptions { # [inline] fn clone (& self) -> ChannelMergerOptions { ChannelMergerOptions { number_of_inputs : :: core :: clone :: Clone :: clone (& self . number_of_inputs) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelMergerOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"ChannelMergerOptions\" , \"number_of_inputs\" , & self . number_of_inputs , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for ChannelMergerOptions { fn default () -> Self { Self { number_of_inputs : 6 , audio_node_options : AudioNodeOptions { channel_count : 1 , channel_count_mode : ChannelCountMode :: Explicit , channel_interpretation : ChannelInterpretation :: Speakers , } , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelMergerNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ChannelMergerNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"number_of_inputs\" , & & self . number_of_inputs) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for ChannelMergerNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn set_channel_count (& self , count : usize) { assert_valid_channel_count (count) ; } fn set_channel_count_mode (& self , mode : ChannelCountMode) { assert_valid_channel_count_mode (mode) ; self . channel_config . set_count_mode (mode , self . registration ()) ; } fn number_of_inputs (& self) -> usize { self . number_of_inputs } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ChannelMergerNode { pub fn new < C : BaseAudioContext > (context : & C , options : ChannelMergerOptions) -> Self { context . base () . register (move | registration | { assert_valid_number_of_channels (options . number_of_inputs) ; assert_valid_channel_count (options . audio_node_options . channel_count) ; assert_valid_channel_count_mode (options . audio_node_options . channel_count_mode) ; let node = ChannelMergerNode { registration , channel_config : options . audio_node_options . into () , number_of_inputs : options . number_of_inputs , } ; let render = ChannelMergerRenderer { } ; (node , Box :: new (render)) }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelMergerRenderer { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , \"ChannelMergerRenderer\") } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_merger",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for ChannelMergerRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let output = & mut outputs [0] ; if inputs . iter () . any (| input | ! input . is_silent ()) { output . set_number_of_channels (inputs . len ()) ; inputs . iter () . enumerate () . for_each (| (i , input) | { * output . channel_data_mut (i) = input . channel_data (0) . clone () ; }) ; } else { output . make_silent () ; } false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: fmt :: Debug ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: MAX_CHANNELS ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "const DEFAULT_NUMBER_OF_OUTPUTS : usize = 6 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ChannelSplitterOptions { # [inline] fn clone (& self) -> ChannelSplitterOptions { ChannelSplitterOptions { number_of_outputs : :: core :: clone :: Clone :: clone (& self . number_of_outputs) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelSplitterOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"ChannelSplitterOptions\" , \"number_of_outputs\" , & self . number_of_outputs , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for ChannelSplitterOptions { fn default () -> Self { Self { number_of_outputs : DEFAULT_NUMBER_OF_OUTPUTS , audio_node_options : AudioNodeOptions { channel_count : DEFAULT_NUMBER_OF_OUTPUTS , channel_count_mode : ChannelCountMode :: Explicit , channel_interpretation : ChannelInterpretation :: Discrete , } , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelSplitterNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ChannelSplitterNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"number_of_outputs\" , & & self . number_of_outputs) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for ChannelSplitterNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn set_channel_count (& self , count : usize) { assert_valid_channel_count (count , self . number_of_outputs) ; } fn set_channel_count_mode (& self , mode : ChannelCountMode) { assert_valid_channel_count_mode (mode) ; self . channel_config . set_count_mode (mode , self . registration ()) ; } fn set_channel_interpretation (& self , interpretation : ChannelInterpretation) { assert_valid_channel_interpretation (interpretation) ; self . channel_config . set_interpretation (interpretation , self . registration ()) ; } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { self . number_of_outputs } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ChannelSplitterNode { pub fn new < C : BaseAudioContext > (context : & C , mut options : ChannelSplitterOptions) -> Self { context . base () . register (move | registration | { assert_valid_number_of_channels (options . number_of_outputs) ; if options . audio_node_options . channel_count != DEFAULT_NUMBER_OF_OUTPUTS { assert_valid_channel_count (options . audio_node_options . channel_count , options . number_of_outputs) ; } options . audio_node_options . channel_count = options . number_of_outputs ; assert_valid_channel_count_mode (options . audio_node_options . channel_count_mode) ; assert_valid_channel_interpretation (options . audio_node_options . channel_interpretation) ; let node = ChannelSplitterNode { registration , channel_config : options . audio_node_options . into () , number_of_outputs : options . number_of_outputs , } ; let render = ChannelSplitterRenderer { number_of_outputs : options . number_of_outputs , } ; (node , Box :: new (render)) }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ChannelSplitterRenderer { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"ChannelSplitterRenderer\" , \"number_of_outputs\" , & & self . number_of_outputs) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::channel_splitter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for ChannelSplitterRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; match (& self . number_of_outputs , & outputs . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; for (i , output) in outputs . iter_mut () . enumerate () { output . set_number_of_channels (1) ; if i < input . number_of_channels () { * output . channel_data_mut (0) = input . channel_data (i) . clone () ; } else { output . make_silent () ; } } false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor , AutomationRate } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { assert_valid_time_value , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioScheduledSourceNode , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ConstantSourceOptions { # [inline] fn clone (& self) -> ConstantSourceOptions { ConstantSourceOptions { offset : :: core :: clone :: Clone :: clone (& self . offset) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ConstantSourceOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"ConstantSourceOptions\" , \"offset\" , & & self . offset) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for ConstantSourceOptions { fn default () -> Self { Self { offset : 1. } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for Schedule { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { Schedule :: Start (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Start\" , & __self_0) , Schedule :: Stop (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Stop\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for Schedule { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for Schedule { # [inline] fn clone (& self) -> Schedule { let _ : :: core :: clone :: AssertParamIsClone < f64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ConstantSourceNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"ConstantSourceNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"offset\" , & self . offset , \"start_stop_count\" , & & self . start_stop_count) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for ConstantSourceNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 0 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioScheduledSourceNode for ConstantSourceNode { fn start (& mut self) { let when = self . registration . context () . current_time () ; self . start_at (when) ; } fn start_at (& mut self , when : f64) { assert_valid_time_value (when) ; match (& self . start_stop_count , & 0) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError - Cannot call `start` twice\"))) ; } } } ; self . start_stop_count += 1 ; self . registration . post_message (Schedule :: Start (when)) ; } fn stop (& mut self) { let when = self . registration . context () . current_time () ; self . stop_at (when) ; } fn stop_at (& mut self , when : f64) { assert_valid_time_value (when) ; match (& self . start_stop_count , & 1) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError cannot stop before start\"))) ; } } } ; self . start_stop_count += 1 ; self . registration . post_message (Schedule :: Stop (when)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ConstantSourceNode { pub fn new < C : BaseAudioContext > (context : & C , options : ConstantSourceOptions) -> Self { context . base () . register (move | registration | { let ConstantSourceOptions { offset } = options ; let param_options = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : f32 :: MAX , default_value : 1. , automation_rate : AutomationRate :: A , } ; let (param , proc) = context . create_audio_param (param_options , & registration) ; param . set_value (offset) ; let render = ConstantSourceRenderer { offset : proc , start_time : f64 :: MAX , stop_time : f64 :: MAX , ended_triggered : false , } ; let node = ConstantSourceNode { registration , channel_config : ChannelConfig :: default () , offset : param , start_stop_count : 0 , } ; (node , Box :: new (render)) }) } pub fn offset (& self) -> & AudioParam { & self . offset } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::constant_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for ConstantSourceRenderer { fn process (& mut self , _inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let output = & mut outputs [0] ; let dt = 1. / scope . sample_rate as f64 ; let next_block_time = scope . current_time + dt * RENDER_QUANTUM_SIZE as f64 ; if self . start_time >= next_block_time { output . make_silent () ; return self . start_time != f64 :: MAX ; } output . force_mono () ; let offset = params . get (& self . offset) ; let output_channel = output . channel_data_mut (0) ; if offset . len () == 1 && self . start_time <= scope . current_time && self . stop_time >= next_block_time { output_channel . fill (offset [0]) ; } else { let mut current_time = scope . current_time ; output_channel . iter_mut () . zip (offset . iter () . cycle ()) . for_each (| (o , & value) | { if current_time < self . start_time || current_time >= self . stop_time { * o = 0. ; } else { * o = value ; } current_time += dt ; }) ; } let still_running = self . stop_time >= next_block_time ; if ! still_running { if ! self . ended_triggered { scope . send_ended_event () ; self . ended_triggered = true ; } } still_running } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (schedule) = msg . downcast_ref :: < Schedule > () { match * schedule { Schedule :: Start (v) => self . start_time = v , Schedule :: Stop (v) => self . stop_time = v , } return ; } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"ConstantSourceRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::constant_source\" , \"web_audio_api::node::constant_source\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/constant_source.rs\") , 256u32 , ()) ; } } ; } fn before_drop (& mut self , scope : & AudioWorkletGlobalScope) { if ! self . ended_triggered && scope . current_time >= self . start_time { scope . send_ended_event () ; self . ended_triggered = true ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use realfft :: { num_complex :: Complex , ComplexToReal , RealFftPlanner , RealToComplex , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ConvolverOptions { # [inline] fn clone (& self) -> ConvolverOptions { ConvolverOptions { buffer : :: core :: clone :: Clone :: clone (& self . buffer) , disable_normalization : :: core :: clone :: Clone :: clone (& self . disable_normalization) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ConvolverOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ConvolverOptions\" , \"buffer\" , & self . buffer , \"disable_normalization\" , & self . disable_normalization , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for ConvolverOptions { # [inline] fn default () -> ConvolverOptions { ConvolverOptions { buffer : :: core :: default :: Default :: default () , disable_normalization : :: core :: default :: Default :: default () , audio_node_options : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ConvolverNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"ConvolverNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"normalize\" , & self . normalize , \"buffer\" , & & self . buffer) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for ConvolverNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ConvolverNode { # [doc = \" returns a `ConvolverNode` instance\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `context` - audio context in which the audio node will live.\"] # [doc = \" * `options` - convolver options\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics when an AudioBuffer is provided via the `ConvolverOptions` with a sample rate\"] # [doc = \" different from the audio context sample rate.\"] pub fn new < C : BaseAudioContext > (context : & C , options : ConvolverOptions) -> Self { let ConvolverOptions { buffer , disable_normalization , audio_node_options : channel_config } = options ; let mut node = context . base () . register (move | registration | { let renderer = ConvolverRenderer { inner : None } ; let node = Self { registration , channel_config : channel_config . into () , normalize : ! disable_normalization , buffer : None , } ; (node , Box :: new (renderer)) }) ; if let Some (buffer) = buffer { node . set_buffer (buffer) ; } node } # [doc = \" Get the current impulse response buffer\"] pub fn buffer (& self) -> Option < & AudioBuffer > { self . buffer . as_ref () } # [doc = \" Set or update the impulse response buffer\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics when the sample rate of the provided AudioBuffer differs from the audio context\"] # [doc = \" sample rate.\"] pub fn set_buffer (& mut self , buffer : AudioBuffer) { let sample_rate = buffer . sample_rate () ; match (& sample_rate , & self . context () . sample_rate ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"NotSupportedError - sample rate of the convolution buffer must match the audio context\"))) ; } } } ; let number_of_channels = buffer . number_of_channels () ; if ! [1 , 2 , 4] . contains (& number_of_channels) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - the convolution buffer must consist of 1, 2 or 4 channels\")) ; } } ; let scale = if self . normalize { normalize_buffer (& buffer) } else { 1. } ; let length = buffer . length () ; let padded_length = length . next_power_of_two () . max (2 * RENDER_QUANTUM_SIZE) ; let samples : Vec < _ > = (0 .. number_of_channels) . map (| _ | { let mut samples = :: alloc :: vec :: from_elem (0. , padded_length) ; samples [.. length] . iter_mut () . zip (buffer . get_channel_data (0)) . for_each (| (o , i) | * o = * i * scale) ; samples }) . collect () ; let padded_buffer = AudioBuffer :: from (samples , sample_rate) ; let convolve = ConvolverRendererInner :: new (padded_buffer) ; self . registration . post_message (Some (convolve)) ; self . buffer = Some (buffer) ; } # [doc = \" Denotes if the response buffer will be scaled with an equal-power normalization\"] pub fn normalize (& self) -> bool { self . normalize } # [doc = \" Update the `normalize` setting. This will only have an effect when `set_buffer` is called.\"] pub fn set_normalize (& mut self , value : bool) { self . normalize = value ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Fft { fn new (length : usize) -> Self { let mut fft_planner = RealFftPlanner :: < f32 > :: new () ; let fft_forward = fft_planner . plan_fft_forward (length) ; let fft_inverse = fft_planner . plan_fft_inverse (length) ; let fft_input = fft_forward . make_input_vec () ; let fft_scratch = fft_forward . make_scratch_vec () ; let fft_output = fft_forward . make_output_vec () ; Self { fft_forward , fft_inverse , fft_input , fft_scratch , fft_output , } } fn real (& mut self) -> & mut [f32] { & mut self . fft_input [..] } fn complex (& mut self) -> & mut [Complex < f32 >] { & mut self . fft_output [..] } fn process (& mut self) -> & [Complex < f32 >] { self . fft_forward . process_with_scratch (& mut self . fft_input , & mut self . fft_output , & mut self . fft_scratch) . unwrap () ; & self . fft_output [..] } fn inverse (& mut self) -> & [f32] { self . fft_inverse . process_with_scratch (& mut self . fft_output , & mut self . fft_input , & mut self . fft_scratch) . unwrap () ; & self . fft_input [..] } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ConvolverRendererInner { fn new (response : AudioBuffer) -> Self { let response = response . channel_data (0) . as_slice () ; let mut fft2 = Fft :: new (2 * RENDER_QUANTUM_SIZE) ; let p = response . len () ; let num_ir_blocks = p / RENDER_QUANTUM_SIZE ; let mut h = :: alloc :: vec :: from_elem (Complex :: default () , num_ir_blocks * 2 * RENDER_QUANTUM_SIZE) ; for (resp_fft , resp) in h . chunks_mut (2 * RENDER_QUANTUM_SIZE) . zip (response . chunks (RENDER_QUANTUM_SIZE)) { fft2 . real () [.. RENDER_QUANTUM_SIZE] . copy_from_slice (resp) ; fft2 . real () [RENDER_QUANTUM_SIZE ..] . fill (0.) ; resp_fft [.. fft2 . complex () . len ()] . copy_from_slice (fft2 . process ()) ; } let fdl = :: alloc :: vec :: from_elem (Complex :: default () , 2 * RENDER_QUANTUM_SIZE * num_ir_blocks) ; let out = :: alloc :: vec :: from_elem (0. , 2 * RENDER_QUANTUM_SIZE - 1) ; Self { num_ir_blocks , h , fdl , out , fft2 } } fn process (& mut self , input : & [f32] , output : & mut [f32]) { self . fft2 . real () [.. RENDER_QUANTUM_SIZE] . copy_from_slice (input) ; self . fft2 . real () [RENDER_QUANTUM_SIZE ..] . fill (0.) ; let spectrum = self . fft2 . process () ; self . fdl . chunks_mut (2 * RENDER_QUANTUM_SIZE) . zip (self . h . chunks (2 * RENDER_QUANTUM_SIZE)) . for_each (| (fdl_c , h_c) | { fdl_c . iter_mut () . zip (h_c) . zip (spectrum) . for_each (| ((f , h) , s) | * f += h * s) }) ; let c_len = self . fft2 . complex () . len () ; self . fft2 . complex () . copy_from_slice (& self . fdl [.. c_len]) ; let inverse = self . fft2 . inverse () ; self . out . iter_mut () . zip (inverse) . for_each (| (o , i) | { * o += i / (2 * RENDER_QUANTUM_SIZE) as f32 ; }) ; output . copy_from_slice (& self . out [.. RENDER_QUANTUM_SIZE]) ; roll_zero (& mut self . fdl [..] , 2 * RENDER_QUANTUM_SIZE) ; roll_zero (& mut self . out [..] , RENDER_QUANTUM_SIZE) ; } fn tail (& mut self , output : & mut AudioRenderQuantum) -> bool { if self . num_ir_blocks == 0 { output . make_silent () ; return false ; } self . num_ir_blocks -= 1 ; let c_len = self . fft2 . complex () . len () ; self . fft2 . complex () . copy_from_slice (& self . fdl [.. c_len]) ; let inverse = self . fft2 . inverse () ; self . out . iter_mut () . zip (inverse) . for_each (| (o , i) | { * o += i / (2 * RENDER_QUANTUM_SIZE) as f32 ; }) ; output . channel_data_mut (0) . copy_from_slice (& self . out [.. RENDER_QUANTUM_SIZE]) ; roll_zero (& mut self . fdl [..] , 2 * RENDER_QUANTUM_SIZE) ; roll_zero (& mut self . out [..] , RENDER_QUANTUM_SIZE) ; self . num_ir_blocks > 0 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::convolver",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for ConvolverRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; output . force_mono () ; let convolver = match & mut self . inner { None => { * output = input . clone () ; return ! input . is_silent () ; } Some (convolver) => convolver , } ; if input . is_silent () { return convolver . tail (output) ; } let mut mono = input . clone () ; mono . mix (1 , ChannelInterpretation :: Speakers) ; let input = & mono . channel_data (0) [..] ; let output = & mut output . channel_data_mut (0) [..] ; convolver . process (input , output) ; true } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (convolver) = msg . downcast_mut :: < Option < ConvolverRendererInner > > () { std :: mem :: swap (& mut self . inner , convolver) ; return ; } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"ConvolverRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::convolver\" , \"web_audio_api::node::convolver\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/convolver.rs\") , 460u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: cell :: { Cell , RefCell , RefMut } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: rc :: Rc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for DelayOptions { # [inline] fn clone (& self) -> DelayOptions { DelayOptions { max_delay_time : :: core :: clone :: Clone :: clone (& self . max_delay_time) , delay_time : :: core :: clone :: Clone :: clone (& self . delay_time) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for DelayOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"DelayOptions\" , \"max_delay_time\" , & self . max_delay_time , \"delay_time\" , & self . delay_time , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for DelayOptions { fn default () -> Self { Self { max_delay_time : 1. , delay_time : 0. , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for PlaybackInfo { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for PlaybackInfo { # [inline] fn clone (& self) -> PlaybackInfo { let _ : :: core :: clone :: AssertParamIsClone < usize > ; let _ : :: core :: clone :: AssertParamIsClone < f32 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PlaybackInfo { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"PlaybackInfo\" , \"prev_block_index\" , & self . prev_block_index , \"prev_frame_index\" , & self . prev_frame_index , \"k\" , & & self . k) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for PlaybackInfo { # [inline] fn default () -> PlaybackInfo { PlaybackInfo { prev_block_index : :: core :: default :: Default :: default () , prev_frame_index : :: core :: default :: Default :: default () , k : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for DelayNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"DelayNode\" , \"reader_registration\" , & self . reader_registration , \"writer_registration\" , & self . writer_registration , \"delay_time\" , & self . delay_time , \"channel_config\" , & & self . channel_config) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for DelayNode { fn registration (& self) -> & AudioContextRegistration { & self . writer_registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } # [doc = \" Connect a specific output of this AudioNode to a specific input of another node.\"] fn connect_from_output_to_input < 'a > (& self , dest : & 'a dyn AudioNode , output : usize , input : usize) -> & 'a dyn AudioNode { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to connect nodes from different contexts\")) ; } } ; if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; if ! (dest . number_of_inputs () > input) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - input port {0} is out of bounds\" , input)) ; } } ; self . context () . connect (self . reader_registration . id () , dest . registration () . id () , output , input) ; dest } # [doc = \" Disconnects all outgoing connections from the AudioNode.\"] fn disconnect (& self) { self . context () . disconnect (self . reader_registration . id () , None , None , None) ; } # [doc = \" Disconnects all outputs of the AudioNode that go to a specific destination AudioNode.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - the source node was not connected to the destination node\"] fn disconnect_dest (& self , dest : & dyn AudioNode) { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to disconnect nodes from different contexts\")) ; } } ; self . context () . disconnect (self . reader_registration . id () , None , Some (dest . registration () . id ()) , None) ; } # [doc = \" Disconnects all outgoing connections at the given output port from the AudioNode.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - if the output port is out of bounds for this node\"] fn disconnect_output (& self , output : usize) { if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; self . context () . disconnect (self . reader_registration . id () , Some (output) , None , None) ; } # [doc = \" Disconnects a specific output of the AudioNode to a specific destination AudioNode\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - if the output port is out of bounds for the source node\"] # [doc = \" - the source node was not connected to the destination node\"] fn disconnect_dest_from_output (& self , dest : & dyn AudioNode , output : usize) { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to disconnect nodes from different contexts\")) ; } } ; if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; self . context () . disconnect (self . reader_registration . id () , Some (output) , Some (dest . registration () . id ()) , None) ; } # [doc = \" Disconnects a specific output of the AudioNode to a specific input of some destination\"] # [doc = \" AudioNode\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic when\"] # [doc = \" - the AudioContext of the source and destination does not match\"] # [doc = \" - if the input port is out of bounds for the destination node\"] # [doc = \" - if the output port is out of bounds for the source node\"] # [doc = \" - the source node was not connected to the destination node\"] fn disconnect_dest_from_output_to_input (& self , dest : & dyn AudioNode , output : usize , input : usize) { if ! (self . context () == dest . context ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Attempting to disconnect nodes from different contexts\")) ; } } ; if ! (self . number_of_outputs () > output) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - output port {0} is out of bounds\" , output)) ; } } ; if ! (dest . number_of_inputs () > input) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - input port {0} is out of bounds\" , input)) ; } } ; self . context () . disconnect (self . reader_registration . id () , Some (output) , Some (dest . registration () . id ()) , Some (input)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl DelayNode { # [doc = \" Create a new DelayNode\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics when the max delay value is smaller than zero or langer than three minutes.\"] pub fn new < C : BaseAudioContext > (context : & C , options : DelayOptions) -> Self { let sample_rate = context . sample_rate () as f64 ; if ! (options . max_delay_time > 0. && options . max_delay_time < 180.) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - maxDelayTime MUST be greater than zero and less than three minutes\")) ; } } ; let max_delay_time = options . max_delay_time ; let num_quanta = (max_delay_time * sample_rate / RENDER_QUANTUM_SIZE as f64) . ceil () as usize ; let ring_buffer = Vec :: with_capacity (num_quanta + 1) ; let shared_ring_buffer = Rc :: new (RefCell :: new (ring_buffer)) ; let shared_ring_buffer_clone = Rc :: clone (& shared_ring_buffer) ; let last_written_index = Rc :: new (Cell :: < Option < usize > > :: new (None)) ; let last_written_index_clone = Rc :: clone (& last_written_index) ; let latest_frame_written = Rc :: new (Cell :: new (u64 :: MAX)) ; let latest_frame_written_clone = Rc :: clone (& latest_frame_written) ; let node = context . base () . register (move | writer_registration | { let node = context . base () . register (move | reader_registration | { let param_opts = AudioParamDescriptor { name : String :: new () , min_value : 0. , max_value : max_delay_time as f32 , default_value : 0. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (param , proc) = context . create_audio_param (param_opts , & reader_registration) ; param . set_value (options . delay_time as f32) ; let reader_render = DelayReader { delay_time : proc , ring_buffer : shared_ring_buffer_clone , index : 0 , last_written_index : last_written_index_clone , in_cycle : false , last_written_index_checked : None , latest_frame_written : latest_frame_written_clone , } ; let node = DelayNode { reader_registration , writer_registration , channel_config : options . audio_node_options . into () , delay_time : param , } ; (node , Box :: new (reader_render)) }) ; let writer_render = DelayWriter { ring_buffer : shared_ring_buffer , index : 0 , last_written_index , latest_frame_written , } ; (node , Box :: new (writer_render)) }) ; let writer_id = node . writer_registration . id () ; let reader_id = node . reader_registration . id () ; context . base () . mark_cycle_breaker (& node . writer_registration) ; context . base () . connect (writer_id , reader_id , 0 , 0) ; node } # [doc = \" A-rate [`AudioParam`] representing the amount of delay (in seconds) to apply.\"] pub fn delay_time (& self) -> & AudioParam { & self . delay_time } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [allow (clippy :: non_send_fields_in_send_ty)] unsafe impl Send for DelayWriter { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Drop for DelayWriter { fn drop (& mut self) { let last_written_index = if self . index == 0 { self . ring_buffer . borrow () . capacity () - 1 } else { self . index - 1 } ; self . last_written_index . set (Some (last_written_index)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl RingBufferChecker for DelayWriter { # [inline (always)] fn ring_buffer_mut (& self) -> RefMut < '_ , Vec < AudioRenderQuantum > > { self . ring_buffer . borrow_mut () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for DelayWriter { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let input = inputs [0] . clone () ; let output = & mut outputs [0] ; self . check_ring_buffer_size (& input) ; self . check_ring_buffer_up_down_mix (& input) ; let mut buffer = self . ring_buffer . borrow_mut () ; buffer [self . index] = input ; self . index = (self . index + 1) % buffer . capacity () ; self . latest_frame_written . set (scope . current_frame) ; output . make_silent () ; false } fn has_side_effects (& self) -> bool { true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl DelayWriter { # [inline (always)] fn check_ring_buffer_up_down_mix (& self , input : & AudioRenderQuantum) { let mut ring_buffer = self . ring_buffer_mut () ; let buffer_number_of_channels = ring_buffer [0] . number_of_channels () ; let input_number_of_channels = input . number_of_channels () ; if buffer_number_of_channels != input_number_of_channels { for render_quantum in ring_buffer . iter_mut () { render_quantum . mix (input_number_of_channels , ChannelInterpretation :: Speakers) ; } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [allow (clippy :: non_send_fields_in_send_ty)] unsafe impl Send for DelayReader { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl RingBufferChecker for DelayReader { # [inline (always)] fn ring_buffer_mut (& self) -> RefMut < '_ , Vec < AudioRenderQuantum > > { self . ring_buffer . borrow_mut () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for DelayReader { fn process (& mut self , _inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let output = & mut outputs [0] ; self . check_ring_buffer_size (output) ; let ring_buffer = self . ring_buffer . borrow () ; let number_of_channels = ring_buffer [0] . number_of_channels () ; output . set_number_of_channels (number_of_channels) ; if ! self . in_cycle { let latest_frame_written = self . latest_frame_written . get () ; self . in_cycle = latest_frame_written != scope . current_frame ; } let delay = params . get (& self . delay_time) ; let sample_rate = scope . sample_rate as f64 ; let dt = 1. / sample_rate ; let quantum_duration = RENDER_QUANTUM_SIZE as f64 * dt ; let ring_size = ring_buffer . len () as i32 ; let ring_index = self . index as i32 ; let mut playback_infos = [PlaybackInfo :: default () ; RENDER_QUANTUM_SIZE] ; if delay . len () == 1 { playback_infos [0] = Self :: get_playback_infos (f64 :: from (delay [0]) , self . in_cycle , 0. , quantum_duration , sample_rate , ring_size , ring_index) ; for i in 1 .. RENDER_QUANTUM_SIZE { let PlaybackInfo { prev_block_index , prev_frame_index , k } = playback_infos [i - 1] ; let mut prev_block_index = prev_block_index ; let mut prev_frame_index = prev_frame_index + 1 ; if prev_frame_index >= RENDER_QUANTUM_SIZE { prev_block_index = (prev_block_index + 1) % ring_buffer . len () ; prev_frame_index = 0 ; } playback_infos [i] = PlaybackInfo { prev_block_index , prev_frame_index , k } ; } } else { delay . iter () . zip (playback_infos . iter_mut ()) . enumerate () . for_each (| (index , (& d , infos)) | { * infos = Self :: get_playback_infos (f64 :: from (d) , self . in_cycle , index as f64 , quantum_duration , sample_rate , ring_size , ring_index) ; }) ; } let mut is_actively_processing = false ; for (channel_number , output_channel) in output . channels_mut () . iter_mut () . enumerate () { let mut block_index = playback_infos [0] . prev_block_index ; let mut channel_data = ring_buffer [block_index] . channel_data (channel_number) ; output_channel . iter_mut () . zip (playback_infos . iter_mut ()) . for_each (| (o , infos) | { let PlaybackInfo { prev_block_index , prev_frame_index , k } = * infos ; let mut next_block_index = prev_block_index ; let mut next_frame_index = prev_frame_index + 1 ; if next_frame_index >= RENDER_QUANTUM_SIZE { next_block_index = (next_block_index + 1) % ring_buffer . len () ; next_frame_index = 0 ; } if block_index != prev_block_index { block_index = prev_block_index ; channel_data = ring_buffer [block_index] . channel_data (channel_number) ; } let prev_sample = channel_data [prev_frame_index] ; if block_index != next_block_index { block_index = next_block_index ; channel_data = ring_buffer [block_index] . channel_data (channel_number) ; } let next_sample = channel_data [next_frame_index] ; let value = (1. - k) . mul_add (prev_sample , k * next_sample) ; if value . is_normal () { is_actively_processing = true ; } * o = value ; }) ; } if ! is_actively_processing { output . make_silent () ; } if match self . last_written_index_checked { Some (index) if index == self . index => true , _ => false , } { return false ; } let last_written_index = self . last_written_index . get () ; if last_written_index . is_some () && self . last_written_index_checked . is_none () { self . last_written_index_checked = last_written_index ; } self . index = (self . index + 1) % ring_buffer . capacity () ; true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::delay",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl DelayReader { # [inline (always)] fn get_playback_infos (delay : f64 , in_cycle : bool , sample_index : f64 , quantum_duration : f64 , sample_rate : f64 , ring_size : i32 , ring_index : i32) -> PlaybackInfo { let clamped_delay = if in_cycle { delay . max (quantum_duration) } else { delay } ; let num_samples = clamped_delay * sample_rate ; let position = sample_index - num_samples ; let position_floored = position . floor () ; let num_frames = RENDER_QUANTUM_SIZE as i32 ; let block_offset = (position_floored / num_frames as f64) . floor () ; let mut prev_block_index = ring_index + block_offset as i32 ; if prev_block_index < 0 { prev_block_index += ring_size ; } let mut frame_offset = position_floored as i32 % num_frames ; if frame_offset == 0 { frame_offset = - num_frames ; } let prev_frame_index = if frame_offset <= 0 { num_frames + frame_offset } else { frame_offset } ; let k = (position - position_floored) as f32 ; PlaybackInfo { prev_block_index : prev_block_index as usize , prev_frame_index : prev_frame_index as usize , k , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioDestinationNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AudioDestinationNode\" , \"registration\" , & self . registration , \"channel_config\" , & & self . channel_config) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for AudioDestinationNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } fn set_channel_count (& self , v : usize) { if ! (! self . registration . context () . offline () || v == self . max_channel_count ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - not allowed to change OfflineAudioContext destination channel count\")) ; } } ; if ! (v <= self . max_channel_count ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - channel count cannot be greater than maxChannelCount ({0})\" , self . max_channel_count ())) ; } } ; self . channel_config . set_count (v , self . registration ()) ; } fn set_channel_count_mode (& self , v : ChannelCountMode) { if ! (! self . registration . context () . offline () || v == ChannelCountMode :: Explicit) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError - AudioDestinationNode has channel count mode constraints\")) ; } } ; self . channel_config . set_count_mode (v , self . registration ()) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioDestinationNode { pub (crate) fn new < C : BaseAudioContext > (context : & C , channel_count : usize) -> Self { context . base () . register (move | registration | { let channel_config = AudioNodeOptions { channel_count , channel_count_mode : ChannelCountMode :: Explicit , channel_interpretation : ChannelInterpretation :: Speakers , } . into () ; let node = Self { registration , channel_config } ; let proc = DestinationRenderer { } ; (node , Box :: new (proc)) }) } pub (crate) fn into_channel_config (self) -> ChannelConfig { self . channel_config } pub (crate) fn from_raw_parts (registration : AudioContextRegistration , channel_config : ChannelConfig) -> Self { Self { registration , channel_config } } # [doc = \" The maximum number of channels that the channelCount attribute can be set to (the max\"] # [doc = \" number of channels that the hardware is capable of supporting).\"] # [doc = \" <https://www.w3.org/TR/webaudio/#dom-audiodestinationnode-maxchannelcount>\"] pub fn max_channel_count (& self) -> usize { self . registration . context () . base () . max_channel_count () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for DestinationRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; * output = input . clone () ; true } fn has_side_effects (& self) -> bool { true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: Ordering ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AtomicF32 , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for DynamicsCompressorOptions { # [inline] fn clone (& self) -> DynamicsCompressorOptions { DynamicsCompressorOptions { attack : :: core :: clone :: Clone :: clone (& self . attack) , knee : :: core :: clone :: Clone :: clone (& self . knee) , ratio : :: core :: clone :: Clone :: clone (& self . ratio) , release : :: core :: clone :: Clone :: clone (& self . release) , threshold : :: core :: clone :: Clone :: clone (& self . threshold) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for DynamicsCompressorOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"attack\" , \"knee\" , \"ratio\" , \"release\" , \"threshold\" , \"audio_node_options\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . attack , & self . knee , & self . ratio , & self . release , & self . threshold , & & self . audio_node_options] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"DynamicsCompressorOptions\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for DynamicsCompressorOptions { fn default () -> Self { Self { attack : 0.003 , knee : 30. , ratio : 12. , release : 0.25 , threshold : - 24. , audio_node_options : AudioNodeOptions { channel_count : 2 , channel_count_mode : ChannelCountMode :: ClampedMax , channel_interpretation : ChannelInterpretation :: Speakers , } , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for DynamicsCompressorNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"registration\" , \"channel_config\" , \"attack\" , \"knee\" , \"ratio\" , \"release\" , \"threshold\" , \"reduction\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . registration , & self . channel_config , & self . attack , & self . knee , & self . ratio , & self . release , & self . threshold , & & self . reduction] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"DynamicsCompressorNode\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for DynamicsCompressorNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } fn set_channel_count (& self , count : usize) { assert_valid_channel_count (count) ; self . channel_config . set_count (count , self . registration ()) ; } fn set_channel_count_mode (& self , mode : ChannelCountMode) { assert_valid_channel_count_mode (mode) ; self . channel_config . set_count_mode (mode , self . registration ()) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl DynamicsCompressorNode { pub fn new < C : BaseAudioContext > (context : & C , options : DynamicsCompressorOptions) -> Self { context . base () . register (move | registration | { assert_valid_channel_count (options . audio_node_options . channel_count) ; assert_valid_channel_count_mode (options . audio_node_options . channel_count_mode) ; let attack_param_opts = AudioParamDescriptor { name : String :: new () , min_value : 0. , max_value : 1. , default_value : 0.003 , automation_rate : crate :: param :: AutomationRate :: K , } ; let (mut attack_param , attack_proc) = context . create_audio_param (attack_param_opts , & registration) ; attack_param . set_automation_rate_constrained (true) ; attack_param . set_value (options . attack) ; let knee_param_opts = AudioParamDescriptor { name : String :: new () , min_value : 0. , max_value : 40. , default_value : 30. , automation_rate : crate :: param :: AutomationRate :: K , } ; let (mut knee_param , knee_proc) = context . create_audio_param (knee_param_opts , & registration) ; knee_param . set_automation_rate_constrained (true) ; knee_param . set_value (options . knee) ; let ratio_param_opts = AudioParamDescriptor { name : String :: new () , min_value : 1. , max_value : 20. , default_value : 12. , automation_rate : crate :: param :: AutomationRate :: K , } ; let (mut ratio_param , ratio_proc) = context . create_audio_param (ratio_param_opts , & registration) ; ratio_param . set_automation_rate_constrained (true) ; ratio_param . set_value (options . ratio) ; let release_param_opts = AudioParamDescriptor { name : String :: new () , min_value : 0. , max_value : 1. , default_value : 0.25 , automation_rate : crate :: param :: AutomationRate :: K , } ; let (mut release_param , release_proc) = context . create_audio_param (release_param_opts , & registration) ; release_param . set_automation_rate_constrained (true) ; release_param . set_value (options . release) ; let threshold_param_opts = AudioParamDescriptor { name : String :: new () , min_value : - 100. , max_value : 0. , default_value : - 24. , automation_rate : crate :: param :: AutomationRate :: K , } ; let (mut threshold_param , threshold_proc) = context . create_audio_param (threshold_param_opts , & registration) ; threshold_param . set_automation_rate_constrained (true) ; threshold_param . set_value (options . threshold) ; let reduction = Arc :: new (AtomicF32 :: new (0.)) ; let ring_buffer_size = (context . sample_rate () * 0.006 / RENDER_QUANTUM_SIZE as f32) . ceil () as usize + 1 ; let ring_buffer = Vec :: < AudioRenderQuantum > :: with_capacity (ring_buffer_size) ; let render = DynamicsCompressorRenderer { attack : attack_proc , knee : knee_proc , ratio : ratio_proc , release : release_proc , threshold : threshold_proc , reduction : Arc :: clone (& reduction) , ring_buffer , ring_index : 0 , prev_detector_value : 0. , } ; let node = DynamicsCompressorNode { registration , channel_config : options . audio_node_options . into () , attack : attack_param , knee : knee_param , ratio : ratio_param , release : release_param , threshold : threshold_param , reduction , } ; (node , Box :: new (render)) }) } pub fn attack (& self) -> & AudioParam { & self . attack } pub fn knee (& self) -> & AudioParam { & self . knee } pub fn ratio (& self) -> & AudioParam { & self . ratio } pub fn release (& self) -> & AudioParam { & self . release } pub fn threshold (& self) -> & AudioParam { & self . threshold } pub fn reduction (& self) -> f32 { self . reduction . load (Ordering :: Relaxed) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [allow (clippy :: non_send_fields_in_send_ty)] unsafe impl Send for DynamicsCompressorRenderer { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::dynamics_compressor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for DynamicsCompressorRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let input = inputs [0] . clone () ; let output = & mut outputs [0] ; let sample_rate = scope . sample_rate ; let ring_size = self . ring_buffer . capacity () ; if self . ring_buffer . len () < ring_size { let mut silence = input . clone () ; silence . make_silent () ; self . ring_buffer . resize (ring_size , silence) ; } let threshold = params . get (& self . threshold) [0] ; let knee = params . get (& self . knee) [0] ; let ratio = params . get (& self . ratio) [0] ; let threshold = if knee > 0. { threshold + knee / 2. } else { threshold } ; let half_knee = knee / 2. ; let knee_partial = (1. / ratio - 1.) / (2. * knee) ; let attack = params . get (& self . attack) [0] ; let release = params . get (& self . release) [0] ; let attack_tau = (- 1. / (attack * sample_rate)) . exp () ; let release_tau = (- 1. / (release * sample_rate)) . exp () ; let full_range_gain = threshold + (- threshold / ratio) ; let full_range_makeup = 1. / db_to_lin (full_range_gain) ; let makeup_gain = lin_to_db (full_range_makeup . powf (0.6)) ; let mut prev_detector_value = self . prev_detector_value ; let mut reduction_gain = 0. ; let mut reduction_gains = [0. ; 128] ; let mut detector_values = [0. ; 128] ; for i in 0 .. RENDER_QUANTUM_SIZE { let mut max = f32 :: MIN ; for channel in input . channels () . iter () { let sample = channel [i] . abs () ; if sample > max { max = sample ; } } let sample_db = lin_to_db (max) ; let sample_attenuated = if sample_db <= threshold - half_knee { sample_db } else if sample_db <= threshold + half_knee { sample_db + (sample_db - threshold + half_knee) . powi (2) * knee_partial } else { threshold + (sample_db - threshold) / ratio } ; let sample_attenuation = sample_db - sample_attenuated ; let detector_value = if sample_attenuation > prev_detector_value { attack_tau * prev_detector_value + (1. - attack_tau) * sample_attenuation } else { release_tau * prev_detector_value + (1. - release_tau) * sample_attenuation } ; detector_values [i] = detector_value ; reduction_gain = - 1. * detector_value + makeup_gain ; reduction_gains [i] = db_to_lin (reduction_gain) ; prev_detector_value = detector_value ; } self . prev_detector_value = prev_detector_value ; self . reduction . store (reduction_gain , Ordering :: Relaxed) ; self . ring_buffer [self . ring_index] = input ; let read_index = (self . ring_index + 1) % ring_size ; let delayed = & self . ring_buffer [read_index] ; self . ring_index = read_index ; * output = delayed . clone () ; if output . is_silent () { output . make_silent () ; return false ; } output . channels_mut () . iter_mut () . for_each (| channel | { channel . iter_mut () . zip (reduction_gains . iter ()) . for_each (| (o , g) | * o *= g) ; }) ; true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for GainOptions { # [inline] fn clone (& self) -> GainOptions { GainOptions { gain : :: core :: clone :: Clone :: clone (& self . gain) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for GainOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"GainOptions\" , \"gain\" , & self . gain , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for GainOptions { fn default () -> Self { Self { gain : 1. , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for GainNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"GainNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"gain\" , & & self . gain) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for GainNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl GainNode { pub fn new < C : BaseAudioContext > (context : & C , options : GainOptions) -> Self { context . base () . register (move | registration | { let param_opts = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : f32 :: MAX , default_value : 1. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (param , proc) = context . create_audio_param (param_opts , & registration) ; param . set_value (options . gain) ; let render = GainRenderer { gain : proc } ; let node = GainNode { registration , channel_config : options . audio_node_options . into () , gain : param , } ; (node , Box :: new (render)) }) } pub fn gain (& self) -> & AudioParam { & self . gain } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::gain",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for GainRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; if input . is_silent () { output . make_silent () ; return false ; } let gain = params . get (& self . gain) ; if gain . len () == 1 { let threshold = 1e-6 ; let diff_to_zero = gain [0] . abs () ; if diff_to_zero <= threshold { output . make_silent () ; return false ; } let diff_to_one = (1. - gain [0]) . abs () ; if diff_to_one <= threshold { * output = input . clone () ; return false ; } } * output = input . clone () ; if gain . len () == 1 { let g = gain [0] ; output . channels_mut () . iter_mut () . for_each (| channel | { channel . iter_mut () . for_each (| o | * o *= g) ; }) ; } else { output . channels_mut () . iter_mut () . for_each (| channel | { channel . iter_mut () . zip (gain . iter () . cycle ()) . for_each (| (o , g) | * o *= g) ; }) ; } false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use arrayvec :: ArrayVec ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use num_complex :: Complex ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: f64 :: consts :: PI ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: MAX_CHANNELS ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [doc = \" Filter order is limited to 20\"] const MAX_IIR_COEFFS_LEN : usize = 20 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for IIRFilterOptions { # [inline] fn clone (& self) -> IIRFilterOptions { IIRFilterOptions { audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , feedforward : :: core :: clone :: Clone :: clone (& self . feedforward) , feedback : :: core :: clone :: Clone :: clone (& self . feedback) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for IIRFilterOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"IIRFilterOptions\" , \"audio_node_options\" , & self . audio_node_options , \"feedforward\" , & self . feedforward , \"feedback\" , & & self . feedback) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for IIRFilterNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"IIRFilterNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"feedforward\" , & self . feedforward , \"feedback\" , & & self . feedback) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for IIRFilterNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl IIRFilterNode { # [doc = \" Creates an `IirFilterNode`\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" - `context` - Audio context in which the node will live\"] # [doc = \" - `options` - node options\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if:\"] # [doc = \" - coefs length is 0 and greater than 20\"] # [doc = \" - feedforward coefs are all zeros\"] # [doc = \" - feedback first coef is zero\"] # [doc = \"\"] pub fn new < C : BaseAudioContext > (context : & C , options : IIRFilterOptions) -> Self { context . base () . register (move | registration | { let IIRFilterOptions { feedforward , feedback , audio_node_options : channel_config } = options ; assert_valid_feedforward_coefs (& feedforward) ; assert_valid_feedback_coefs (& feedback) ; let render = IirFilterRenderer :: new (feedforward . clone () , feedback . clone ()) ; let node = Self { registration , channel_config : channel_config . into () , feedforward , feedback , } ; (node , Box :: new (render)) }) } # [doc = \" Returns the frequency response for the specified frequencies\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" - `frequency_hz` - frequencies for which frequency response of the filter should be calculated\"] # [doc = \" - `mag_response` - magnitude of the frequency response of the filter\"] # [doc = \" - `phase_response` - phase of the frequency response of the filter\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if arguments' lengths don't match\"] # [doc = \"\"] pub fn get_frequency_response (& self , frequency_hz : & [f32] , mag_response : & mut [f32] , phase_response : & mut [f32]) { if ! (frequency_hz . len () == mag_response . len () && mag_response . len () == phase_response . len ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidAccessError - Parameter lengths must match\")) ; } } ; let sample_rate = self . context () . sample_rate () as f64 ; let nquist = sample_rate / 2. ; for (i , & f) in frequency_hz . iter () . enumerate () { let freq = f64 :: from (f) ; if freq < 0. || freq > nquist { mag_response [i] = f32 :: NAN ; phase_response [i] = f32 :: NAN ; } else { let z = - 2.0 * PI * freq / sample_rate ; let mut num : Complex < f64 > = Complex :: new (0. , 0.) ; let mut denom : Complex < f64 > = Complex :: new (0. , 0.) ; for (idx , & b) in self . feedforward . iter () . enumerate () { num += Complex :: from_polar (b , idx as f64 * z) ; } for (idx , & a) in self . feedback . iter () . enumerate () { denom += Complex :: from_polar (a , idx as f64 * z) ; } let response = num / denom ; let (mag , phase) = response . to_polar () ; mag_response [i] = mag as f32 ; phase_response [i] = phase as f32 ; } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl IirFilterRenderer { # [doc = \" Build an `IirFilterNode` renderer\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `config` - renderer config\"] fn new (mut feedforward : Vec < f64 > , mut feedback : Vec < f64 >) -> Self { match (feedforward . len () , feedback . len ()) { (feedforward_len , feedback_len) if feedforward_len > feedback_len => { feedforward = feedforward . into_iter () . chain (std :: iter :: repeat (0.)) . take (feedback_len) . collect () ; } (feedforward_len , feedback_len) if feedforward_len < feedback_len => { feedback = feedback . into_iter () . chain (std :: iter :: repeat (0.)) . take (feedforward_len) . collect () ; } _ => () , } ; let a0 = feedback [0] ; let mut norm_coeffs : Vec < (f64 , f64) > = feedforward . into_iter () . zip (feedback) . collect () ; norm_coeffs . iter_mut () . for_each (| (b , a) | { * b /= a0 ; * a /= a0 ; }) ; let coeffs_len = norm_coeffs . len () ; let mut states = ArrayVec :: new () ; states . push (:: alloc :: vec :: from_elem (0. , coeffs_len)) ; states . push (:: alloc :: vec :: from_elem (0. , coeffs_len)) ; Self { norm_coeffs , states } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::iir_filter",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for IirFilterRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; if input . is_silent () { let mut ended = true ; self . states . iter () . all (| state | { if state . iter () . any (| & v | v . is_normal ()) { ended = false ; } ended }) ; if ended { output . make_silent () ; return false ; } } if ! input . is_silent () { let num_channels = input . number_of_channels () ; if num_channels != self . states . len () { self . states . truncate (num_channels) ; for _ in self . states . len () .. num_channels { self . states . push (:: alloc :: vec :: from_elem (0. , self . norm_coeffs . len ())) ; } } output . set_number_of_channels (num_channels) ; } else { let num_channels = self . states . len () ; output . set_number_of_channels (num_channels) ; } for (channel_number , output_channel) in output . channels_mut () . iter_mut () . enumerate () { let input_channel = if input . is_silent () { input . channel_data (0) } else { input . channel_data (channel_number) } ; let channel_state = & mut self . states [channel_number] ; for (& i , o) in input_channel . iter () . zip (output_channel . iter_mut ()) { let input = f64 :: from (i) ; let b0 = self . norm_coeffs [0] . 0 ; let last_state = channel_state [0] ; let output = b0 . mul_add (input , last_state) ; for (i , (b , a)) in self . norm_coeffs . iter () . skip (1) . enumerate () { let state = channel_state [i + 1] ; channel_state [i] = b * input - a * output + state ; } # [cfg (debug_assertions)] if output . is_nan () || output . is_infinite () { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"An unstable filter is processed.\") , lvl , & (\"web_audio_api::node::iir_filter\" , \"web_audio_api::node::iir_filter\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/iir_filter.rs\") , 399u32 , ()) ; } } ; } * o = output as f32 ; } } true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: resampling :: Resampler ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: MediaElement ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , ChannelConfig , MediaStreamRenderer } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl < 'a > :: core :: fmt :: Debug for MediaElementAudioSourceOptions < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"MediaElementAudioSourceOptions\" , \"media_element\" , & & self . media_element) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaElementAudioSourceNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"MediaElementAudioSourceNode\" , \"registration\" , & self . registration , \"channel_config\" , & & self . channel_config) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for MediaElementAudioSourceNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 0 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_element_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MediaElementAudioSourceNode { # [doc = \" Create a new `MediaElementAudioSourceNode`\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method will panic when there already exists a source node for the given\"] # [doc = \" `MediaElement`. You can only set up a single source node per element!\"] pub fn new < C : BaseAudioContext > (context : & C , options : MediaElementAudioSourceOptions < '_ >) -> Self { context . base () . register (move | registration | { let node = MediaElementAudioSourceNode { registration , channel_config : ChannelConfig :: default () , } ; let stream = options . media_element . take_stream () . expect (\"InvalidStateError - stream already taken\") ; let resampler = Resampler :: new (context . sample_rate () , RENDER_QUANTUM_SIZE , stream) ; let render = MediaStreamRenderer :: new (resampler) ; (node , Box :: new (render)) }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_streams :: { MediaStream , MediaStreamTrack } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { self , Receiver , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaStreamAudioDestinationNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"MediaStreamAudioDestinationNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"stream\" , & & self . stream) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for MediaStreamAudioDestinationNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 0 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MediaStreamAudioDestinationNode { # [doc = \" Create a new MediaStreamAudioDestinationNode\"] pub fn new < C : BaseAudioContext > (context : & C , options : AudioNodeOptions) -> Self { context . base () . register (move | registration | { let (send , recv) = crossbeam_channel :: bounded (1) ; let iter = AudioDestinationNodeStream { receiver : recv . clone () } ; let track = MediaStreamTrack :: from_iter (iter) ; let stream = MediaStream :: from_tracks (< [_] > :: into_vec (# [rustc_box] :: alloc :: boxed :: Box :: new ([track]))) ; let node = MediaStreamAudioDestinationNode { registration , channel_config : options . into () , stream , } ; let render = DestinationRenderer { send , recv } ; (node , Box :: new (render)) }) } # [doc = \" A [`MediaStream`] producing audio buffers with the same number of channels as the node\"] # [doc = \" itself\"] pub fn stream (& self) -> & MediaStream { & self . stream } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for DestinationRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , _outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let samples : Vec < _ > = input . channels () . iter () . map (| c | c . to_vec ()) . collect () ; let buffer = AudioBuffer :: from (samples , scope . sample_rate) ; if self . recv . try_recv () . is_ok () { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"MediaStreamDestination buffer dropped\") , lvl , & (\"web_audio_api::node::media_stream_destination\" , \"web_audio_api::node::media_stream_destination\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/media_stream_destination.rs\") , 136u32 , ()) ; } } ; } let _ = self . send . send (buffer) ; false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_destination",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Iterator for AudioDestinationNodeStream { type Item = Result < AudioBuffer , Box < dyn Error + Send + Sync > > ; fn next (& mut self) -> Option < Self :: Item > { match self . receiver . recv () { Ok (buf) => Some (Ok (buf)) , Err (e) => Some (Err (Box :: new (e))) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_streams :: MediaStream ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: resampling :: Resampler ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , ChannelConfig , MediaStreamRenderer } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl < 'a > :: core :: fmt :: Debug for MediaStreamAudioSourceOptions < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"MediaStreamAudioSourceOptions\" , \"media_stream\" , & & self . media_stream) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaStreamAudioSourceNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"MediaStreamAudioSourceNode\" , \"registration\" , & self . registration , \"channel_config\" , & & self . channel_config) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for MediaStreamAudioSourceNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 0 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MediaStreamAudioSourceNode { # [doc = \" Create a new `MediaStreamAudioSourceNode`\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This method will panic when the provided `MediaStream` does not contain any audio tracks.\"] pub fn new < C : BaseAudioContext > (context : & C , options : MediaStreamAudioSourceOptions < '_ >) -> Self { context . base () . register (move | registration | { let node = MediaStreamAudioSourceNode { registration , channel_config : ChannelConfig :: default () , } ; let resampler = Resampler :: new (context . sample_rate () , RENDER_QUANTUM_SIZE , options . media_stream . get_tracks () [0] . iter ()) ; let render = MediaStreamRenderer :: new (resampler) ; (node , Box :: new (render)) }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_streams :: MediaStreamTrack ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: resampling :: Resampler ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , ChannelConfig , MediaStreamRenderer } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl < 'a > :: core :: fmt :: Debug for MediaStreamTrackAudioSourceOptions < 'a > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"MediaStreamTrackAudioSourceOptions\" , \"media_stream_track\" , & & self . media_stream_track) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for MediaStreamTrackAudioSourceNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"MediaStreamTrackAudioSourceNode\" , \"registration\" , & self . registration , \"channel_config\" , & & self . channel_config) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for MediaStreamTrackAudioSourceNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 0 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::media_stream_track_source",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MediaStreamTrackAudioSourceNode { pub fn new < C : BaseAudioContext > (context : & C , options : MediaStreamTrackAudioSourceOptions < '_ >) -> Self { context . base () . register (move | registration | { let node = MediaStreamTrackAudioSourceNode { registration , channel_config : ChannelConfig :: default () , } ; let resampler = Resampler :: new (context . sample_rate () , RENDER_QUANTUM_SIZE , options . media_stream_track . iter ()) ; let render = MediaStreamRenderer :: new (resampler) ; (node , Box :: new (render)) }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: fmt :: Debug ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor , AutomationRate } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: PeriodicWave ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { assert_valid_time_value , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { precomputed_sine_table , AudioNode , AudioNodeOptions , AudioScheduledSourceNode , ChannelConfig , TABLE_LENGTH_USIZE , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for OscillatorOptions { # [inline] fn clone (& self) -> OscillatorOptions { OscillatorOptions { type_ : :: core :: clone :: Clone :: clone (& self . type_) , frequency : :: core :: clone :: Clone :: clone (& self . frequency) , detune : :: core :: clone :: Clone :: clone (& self . detune) , periodic_wave : :: core :: clone :: Clone :: clone (& self . periodic_wave) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for OscillatorOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"OscillatorOptions\" , \"type_\" , & self . type_ , \"frequency\" , & self . frequency , \"detune\" , & self . detune , \"periodic_wave\" , & self . periodic_wave , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for OscillatorOptions { fn default () -> Self { Self { type_ : OscillatorType :: default () , frequency : 440. , detune : 0. , periodic_wave : None , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for OscillatorType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { OscillatorType :: Sine => \"Sine\" , OscillatorType :: Square => \"Square\" , OscillatorType :: Sawtooth => \"Sawtooth\" , OscillatorType :: Triangle => \"Triangle\" , OscillatorType :: Custom => \"Custom\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for OscillatorType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for OscillatorType { # [inline] fn clone (& self) -> OscillatorType { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for OscillatorType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for OscillatorType { # [inline] fn eq (& self , other : & OscillatorType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for OscillatorType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for OscillatorType { fn default () -> Self { Self :: Sine } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u32 > for OscillatorType { fn from (i : u32) -> Self { match i { 0 => OscillatorType :: Sine , 1 => OscillatorType :: Square , 2 => OscillatorType :: Sawtooth , 3 => OscillatorType :: Triangle , 4 => OscillatorType :: Custom , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for Schedule { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { Schedule :: Start (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Start\" , & __self_0) , Schedule :: Stop (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Stop\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for Schedule { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for Schedule { # [inline] fn clone (& self) -> Schedule { let _ : :: core :: clone :: AssertParamIsClone < f64 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for OscillatorNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"registration\" , \"channel_config\" , \"frequency\" , \"detune\" , \"type_\" , \"start_stop_count\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . registration , & self . channel_config , & self . frequency , & self . detune , & self . type_ , & & self . start_stop_count] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"OscillatorNode\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for OscillatorNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } # [doc = \" `OscillatorNode` is a source node. A source node is by definition with no input\"] fn number_of_inputs (& self) -> usize { 0 } # [doc = \" `OscillatorNode` is a mono source node.\"] fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioScheduledSourceNode for OscillatorNode { fn start (& mut self) { let when = self . registration . context () . current_time () ; self . start_at (when) ; } fn start_at (& mut self , when : f64) { assert_valid_time_value (when) ; match (& self . start_stop_count , & 0) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError - Cannot call `start` twice\"))) ; } } } ; self . start_stop_count += 1 ; self . registration . post_message (Schedule :: Start (when)) ; } fn stop (& mut self) { let when = self . registration . context () . current_time () ; self . stop_at (when) ; } fn stop_at (& mut self , when : f64) { assert_valid_time_value (when) ; match (& self . start_stop_count , & 1) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError cannot stop before start\"))) ; } } } ; self . start_stop_count += 1 ; self . registration . post_message (Schedule :: Stop (when)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl OscillatorNode { # [doc = \" Returns an `OscillatorNode`\"] # [doc = \"\"] # [doc = \" # Arguments:\"] # [doc = \"\"] # [doc = \" * `context` - The `AudioContext`\"] # [doc = \" * `options` - The OscillatorOptions\"] pub fn new < C : BaseAudioContext > (context : & C , options : OscillatorOptions) -> Self { let OscillatorOptions { type_ , frequency , detune , audio_node_options : channel_config , periodic_wave } = options ; let mut node = context . base () . register (move | registration | { let sample_rate = context . sample_rate () ; let nyquist = sample_rate / 2. ; let freq_param_options = AudioParamDescriptor { name : String :: new () , min_value : - nyquist , max_value : nyquist , default_value : 440. , automation_rate : AutomationRate :: A , } ; let (f_param , f_proc) = context . create_audio_param (freq_param_options , & registration) ; f_param . set_value (frequency) ; let det_param_options = AudioParamDescriptor { name : String :: new () , min_value : - 153_600. , max_value : 153_600. , default_value : 0. , automation_rate : AutomationRate :: A , } ; let (det_param , det_proc) = context . create_audio_param (det_param_options , & registration) ; det_param . set_value (detune) ; let renderer = OscillatorRenderer { type_ , frequency : f_proc , detune : det_proc , phase : 0. , start_time : f64 :: MAX , stop_time : f64 :: MAX , started : false , periodic_wave : None , ended_triggered : false , sine_table : precomputed_sine_table () , } ; let node = Self { registration , channel_config : channel_config . into () , frequency : f_param , detune : det_param , type_ , start_stop_count : 0 , } ; (node , Box :: new (renderer)) }) ; if let Some (p_wave) = periodic_wave { node . set_periodic_wave (p_wave) ; } node } # [doc = \" A-rate [`AudioParam`] that defines the fundamental frequency of the\"] # [doc = \" oscillator, expressed in Hz\"] # [doc = \"\"] # [doc = \" The final frequency is calculated as follow: frequency * 2^(detune/1200)\"] # [must_use] pub fn frequency (& self) -> & AudioParam { & self . frequency } # [doc = \" A-rate [`AudioParam`] that defines a transposition according to the\"] # [doc = \" frequency, expressed in cents.\"] # [doc = \"\"] # [doc = \" see <https://en.wikipedia.org/wiki/Cent_(music)>\"] # [doc = \"\"] # [doc = \" The final frequency is calculated as follow: frequency * 2^(detune/1200)\"] # [must_use] pub fn detune (& self) -> & AudioParam { & self . detune } # [doc = \" Returns the oscillator type\"] # [must_use] pub fn type_ (& self) -> OscillatorType { self . type_ } # [doc = \" Set the oscillator type\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `type_` - oscillator type (sine, square, triangle, sawtooth)\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" if `type_` is `OscillatorType::Custom`\"] pub fn set_type (& mut self , type_ : OscillatorType) { match (& (type_) , & (OscillatorType :: Custom)) { (left_val , right_val) => { if * left_val == * right_val { let kind = :: core :: panicking :: AssertKind :: Ne ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"InvalidStateError: Custom type cannot be set manually\"))) ; } } } ; if self . type_ == OscillatorType :: Custom { return ; } self . type_ = type_ ; self . registration . post_message (type_) ; } # [doc = \" Sets a `PeriodicWave` which describes a waveform to be used by the oscillator.\"] # [doc = \"\"] # [doc = \" Calling this sets the oscillator type to `custom`, once set to `custom`\"] # [doc = \" the oscillator cannot be reverted back to a standard waveform.\"] pub fn set_periodic_wave (& mut self , periodic_wave : PeriodicWave) { self . type_ = OscillatorType :: Custom ; self . registration . post_message (periodic_wave) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for OscillatorRenderer { fn process (& mut self , _inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let output = & mut outputs [0] ; output . set_number_of_channels (1) ; let sample_rate = scope . sample_rate as f64 ; let dt = 1. / sample_rate ; let num_frames = RENDER_QUANTUM_SIZE ; let next_block_time = scope . current_time + dt * num_frames as f64 ; if self . start_time >= next_block_time { output . make_silent () ; return self . start_time != f64 :: MAX ; } else if self . stop_time < scope . current_time { output . make_silent () ; if ! self . ended_triggered { scope . send_ended_event () ; self . ended_triggered = true ; } return false ; } let channel_data = output . channel_data_mut (0) ; let frequency_values = params . get (& self . frequency) ; let detune_values = params . get (& self . detune) ; let mut current_time = scope . current_time ; if ! self . started && self . start_time < current_time { self . start_time = current_time ; } if frequency_values . len () == 1 && detune_values . len () == 1 { let phase_incr = get_phase_incr (frequency_values [0] , detune_values [0] , sample_rate) ; channel_data . iter_mut () . for_each (| output | self . generate_sample (output , phase_incr , & mut current_time , dt)) ; } else { channel_data . iter_mut () . zip (frequency_values . iter () . cycle ()) . zip (detune_values . iter () . cycle ()) . for_each (| ((output , & f) , & d) | { let phase_incr = get_phase_incr (f , d , sample_rate) ; self . generate_sample (output , phase_incr , & mut current_time , dt) }) ; } true } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (& type_) = msg . downcast_ref :: < OscillatorType > () { self . type_ = type_ ; return ; } if let Some (& schedule) = msg . downcast_ref :: < Schedule > () { match schedule { Schedule :: Start (v) => self . start_time = v , Schedule :: Stop (v) => self . stop_time = v , } return ; } if let Some (periodic_wave) = msg . downcast_mut :: < PeriodicWave > () { if let Some (current_periodic_wave) = & mut self . periodic_wave { std :: mem :: swap (current_periodic_wave , periodic_wave) } else { self . periodic_wave = Some (std :: mem :: take (periodic_wave)) ; } self . type_ = OscillatorType :: Custom ; return ; } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"OscillatorRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::oscillator\" , \"web_audio_api::node::oscillator\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/oscillator.rs\") , 458u32 , ()) ; } } ; } fn before_drop (& mut self , scope : & AudioWorkletGlobalScope) { if ! self . ended_triggered && scope . current_time >= self . start_time { scope . send_ended_event () ; self . ended_triggered = true ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::oscillator",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl OscillatorRenderer { # [inline] fn generate_sample (& mut self , output : & mut f32 , phase_incr : f64 , current_time : & mut f64 , dt : f64) { if * current_time < self . start_time || * current_time >= self . stop_time { * output = 0. ; * current_time += dt ; return ; } if ! self . started { if * current_time > self . start_time { let ratio = (* current_time - self . start_time) / dt ; self . phase = Self :: unroll_phase (phase_incr * ratio) ; } self . started = true ; } * output = match self . type_ { OscillatorType :: Sine => self . generate_sine () , OscillatorType :: Sawtooth => self . generate_sawtooth (phase_incr) , OscillatorType :: Square => self . generate_square (phase_incr) , OscillatorType :: Triangle => self . generate_triangle () , OscillatorType :: Custom => self . generate_custom () , } ; * current_time += dt ; self . phase = Self :: unroll_phase (self . phase + phase_incr) ; } # [inline] fn generate_sine (& mut self) -> f32 { let position = self . phase * TABLE_LENGTH_USIZE as f64 ; let floored = position . floor () ; let prev_index = floored as usize ; let mut next_index = prev_index + 1 ; if next_index == TABLE_LENGTH_USIZE { next_index = 0 ; } let k = (position - floored) as f32 ; self . sine_table [prev_index] . mul_add (1. - k , self . sine_table [next_index] * k) } # [inline] fn generate_sawtooth (& mut self , phase_incr : f64) -> f32 { let phase = Self :: unroll_phase (self . phase + 0.5) ; let mut sample = 2.0 * phase - 1.0 ; sample -= Self :: poly_blep (phase , phase_incr , false) ; sample as f32 } # [inline] fn generate_square (& mut self , phase_incr : f64) -> f32 { let mut sample = if self . phase < 0.5 { 1.0 } else { - 1.0 } ; sample += Self :: poly_blep (self . phase , phase_incr , false) ; let shift_phase = Self :: unroll_phase (self . phase + 0.5) ; sample -= Self :: poly_blep (shift_phase , phase_incr , false) ; sample as f32 } # [inline] fn generate_triangle (& mut self) -> f32 { let mut sample = - 4. * self . phase + 2. ; if sample > 1. { sample = 2. - sample ; } else if sample < - 1. { sample = - 2. - sample ; } sample as f32 } # [inline] fn generate_custom (& mut self) -> f32 { let periodic_wave = self . periodic_wave . as_ref () . unwrap () . as_slice () ; let position = self . phase * TABLE_LENGTH_USIZE as f64 ; let floored = position . floor () ; let prev_index = floored as usize ; let mut next_index = prev_index + 1 ; if next_index == TABLE_LENGTH_USIZE { next_index = 0 ; } let k = (position - floored) as f32 ; periodic_wave [prev_index] . mul_add (1. - k , periodic_wave [next_index] * k) } # [inline] fn poly_blep (mut t : f64 , dt : f64 , is_test : bool) -> f64 { if is_test { 0. } else if t < dt { t /= dt ; t + t - t * t - 1.0 } else if t > 1.0 - dt { t = (t - 1.0) / dt ; t . mul_add (t , t) + t + 1.0 } else { 0.0 } } # [inline] fn unroll_phase (mut phase : f64) -> f64 { if phase >= 1. { phase -= 1. } phase } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: collections :: HashMap ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: f32 :: consts :: PI ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Mutex , OnceLock } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use float_eq :: float_eq ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use hrtf :: { HrirSphere , HrtfContext , HrtfProcessor , Vec3 } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PanningModelType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { PanningModelType :: EqualPower => \"EqualPower\" , PanningModelType :: HRTF => \"HRTF\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for PanningModelType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for PanningModelType { # [inline] fn clone (& self) -> PanningModelType { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for PanningModelType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for PanningModelType { # [inline] fn eq (& self , other : & PanningModelType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for PanningModelType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for PanningModelType { # [inline] fn default () -> PanningModelType { Self :: EqualPower } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u8 > for PanningModelType { fn from (i : u8) -> Self { match i { 0 => PanningModelType :: EqualPower , 1 => PanningModelType :: HRTF , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for DistanceModelType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { DistanceModelType :: Linear => \"Linear\" , DistanceModelType :: Inverse => \"Inverse\" , DistanceModelType :: Exponential => \"Exponential\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for DistanceModelType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for DistanceModelType { # [inline] fn clone (& self) -> DistanceModelType { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for DistanceModelType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for DistanceModelType { # [inline] fn eq (& self , other : & DistanceModelType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for DistanceModelType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for DistanceModelType { # [inline] fn default () -> DistanceModelType { Self :: Inverse } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u8 > for DistanceModelType { fn from (i : u8) -> Self { match i { 0 => DistanceModelType :: Linear , 1 => DistanceModelType :: Inverse , 2 => DistanceModelType :: Exponential , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for PannerOptions { # [inline] fn clone (& self) -> PannerOptions { PannerOptions { panning_model : :: core :: clone :: Clone :: clone (& self . panning_model) , distance_model : :: core :: clone :: Clone :: clone (& self . distance_model) , position_x : :: core :: clone :: Clone :: clone (& self . position_x) , position_y : :: core :: clone :: Clone :: clone (& self . position_y) , position_z : :: core :: clone :: Clone :: clone (& self . position_z) , orientation_x : :: core :: clone :: Clone :: clone (& self . orientation_x) , orientation_y : :: core :: clone :: Clone :: clone (& self . orientation_y) , orientation_z : :: core :: clone :: Clone :: clone (& self . orientation_z) , ref_distance : :: core :: clone :: Clone :: clone (& self . ref_distance) , max_distance : :: core :: clone :: Clone :: clone (& self . max_distance) , rolloff_factor : :: core :: clone :: Clone :: clone (& self . rolloff_factor) , cone_inner_angle : :: core :: clone :: Clone :: clone (& self . cone_inner_angle) , cone_outer_angle : :: core :: clone :: Clone :: clone (& self . cone_outer_angle) , cone_outer_gain : :: core :: clone :: Clone :: clone (& self . cone_outer_gain) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PannerOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"panning_model\" , \"distance_model\" , \"position_x\" , \"position_y\" , \"position_z\" , \"orientation_x\" , \"orientation_y\" , \"orientation_z\" , \"ref_distance\" , \"max_distance\" , \"rolloff_factor\" , \"cone_inner_angle\" , \"cone_outer_angle\" , \"cone_outer_gain\" , \"audio_node_options\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . panning_model , & self . distance_model , & self . position_x , & self . position_y , & self . position_z , & self . orientation_x , & self . orientation_y , & self . orientation_z , & self . ref_distance , & self . max_distance , & self . rolloff_factor , & self . cone_inner_angle , & self . cone_outer_angle , & self . cone_outer_gain , & & self . audio_node_options] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"PannerOptions\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for PannerOptions { fn default () -> Self { PannerOptions { panning_model : PanningModelType :: default () , distance_model : DistanceModelType :: default () , position_x : 0. , position_y : 0. , position_z : 0. , orientation_x : 1. , orientation_y : 0. , orientation_z : 0. , ref_distance : 1. , max_distance : 10000. , rolloff_factor : 1. , cone_inner_angle : 360. , cone_outer_angle : 360. , cone_outer_gain : 0. , audio_node_options : AudioNodeOptions { channel_count : 2 , channel_count_mode : ChannelCountMode :: ClampedMax , channel_interpretation : ChannelInterpretation :: Speakers , } , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl HrtfState { fn new (processor : HrtfProcessor , len : usize) -> Self { Self { len , processor , output_interleaved : :: alloc :: vec :: from_elem ((0. , 0.) , RENDER_QUANTUM_SIZE) , prev_sample_vector : Vec3 :: new (0. , 0. , 1.) , prev_left_samples : :: alloc :: vec :: Vec :: new () , prev_right_samples : :: alloc :: vec :: Vec :: new () , prev_distance_gain : 0. , } } fn process (& mut self , source : & [f32] , new_distance_gain : f32 , projected_source : [f32 ; 3]) -> & [(f32 , f32)] { self . output_interleaved . fill ((0. , 0.)) ; let new_sample_vector = Vec3 { x : projected_source [0] , z : projected_source [1] , y : projected_source [2] , } ; let context = HrtfContext { source , output : & mut self . output_interleaved , new_sample_vector , prev_sample_vector : self . prev_sample_vector , prev_left_samples : & mut self . prev_left_samples , prev_right_samples : & mut self . prev_right_samples , new_distance_gain , prev_distance_gain : self . prev_distance_gain , } ; self . processor . process_samples (context) ; self . prev_sample_vector = new_sample_vector ; self . prev_distance_gain = new_distance_gain ; & self . output_interleaved } fn tail_time_samples (& self) -> usize { self . len } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PannerNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"registration\" , \"channel_config\" , \"position_x\" , \"position_y\" , \"position_z\" , \"orientation_x\" , \"orientation_y\" , \"orientation_z\" , \"cone_inner_angle\" , \"cone_outer_angle\" , \"cone_outer_gain\" , \"distance_model\" , \"ref_distance\" , \"max_distance\" , \"rolloff_factor\" , \"panning_model\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . registration , & self . channel_config , & self . position_x , & self . position_y , & self . position_z , & self . orientation_x , & self . orientation_y , & self . orientation_z , & self . cone_inner_angle , & self . cone_outer_angle , & self . cone_outer_gain , & self . distance_model , & self . ref_distance , & self . max_distance , & self . rolloff_factor , & & self . panning_model] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"PannerNode\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for PannerNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } fn set_channel_count (& self , count : usize) { assert_valid_channel_count (count) ; self . channel_config . set_count (count , self . registration ()) ; } fn set_channel_count_mode (& self , mode : ChannelCountMode) { assert_valid_channel_count_mode (mode) ; self . channel_config . set_count_mode (mode , self . registration ()) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl PannerNode { # [doc = \" returns a `PannerNode` instance\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `context` - audio context in which the audio node will live.\"] # [doc = \" * `options` - stereo panner options\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * `options.channel_config.count` is greater than 2\"] # [doc = \" * `options.channel_config.mode` is `ChannelCountMode::Max`\"] # [doc = \"\"] # [doc = \" Can panic when loading HRIR-sphere\"] # [allow (clippy :: missing_panics_doc)] pub fn new < C : BaseAudioContext > (context : & C , options : PannerOptions) -> Self { let mut node = context . base () . register (| registration | { use crate :: spatial :: PARAM_OPTS ; let PannerOptions { position_x , position_y , position_z , orientation_x , orientation_y , orientation_z , distance_model , ref_distance , max_distance , rolloff_factor , cone_inner_angle , cone_outer_angle , cone_outer_gain , audio_node_options : channel_config , panning_model } = options ; if ! (ref_distance >= 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - refDistance cannot be negative\")) ; } } ; if ! (max_distance > 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - maxDistance must be positive\")) ; } } ; if ! (rolloff_factor >= 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - rolloffFactor cannot be negative\")) ; } } ; assert_valid_cone_outer_gain (cone_outer_gain) ; assert_valid_channel_count (channel_config . channel_count) ; assert_valid_channel_count_mode (channel_config . channel_count_mode) ; let (param_px , render_px) = context . create_audio_param (PARAM_OPTS , & registration) ; let (param_py , render_py) = context . create_audio_param (PARAM_OPTS , & registration) ; let (param_pz , render_pz) = context . create_audio_param (PARAM_OPTS , & registration) ; param_px . set_value (position_x) ; param_py . set_value (position_y) ; param_pz . set_value (position_z) ; let orientation_x_opts = AudioParamDescriptor { default_value : 1.0 , .. PARAM_OPTS } ; let (param_ox , render_ox) = context . create_audio_param (orientation_x_opts , & registration) ; let (param_oy , render_oy) = context . create_audio_param (PARAM_OPTS , & registration) ; let (param_oz , render_oz) = context . create_audio_param (PARAM_OPTS , & registration) ; param_ox . set_value (orientation_x) ; param_oy . set_value (orientation_y) ; param_oz . set_value (orientation_z) ; let render = PannerRenderer { position_x : render_px , position_y : render_py , position_z : render_pz , orientation_x : render_ox , orientation_y : render_oy , orientation_z : render_oz , distance_model , ref_distance , max_distance , rolloff_factor , cone_inner_angle , cone_outer_angle , cone_outer_gain , hrtf_state : None , tail_time_counter : 0 , } ; let node = PannerNode { registration , channel_config : channel_config . into () , position_x : param_px , position_y : param_py , position_z : param_pz , orientation_x : param_ox , orientation_y : param_oy , orientation_z : param_oz , distance_model , ref_distance , max_distance , rolloff_factor , cone_inner_angle , cone_outer_angle , cone_outer_gain , panning_model , } ; context . base () . ensure_audio_listener_present () ; (node , Box :: new (render)) }) ; context . base () . connect_listener_to_panner (node . registration () . id ()) ; node . set_panning_model (options . panning_model) ; node } pub fn position_x (& self) -> & AudioParam { & self . position_x } pub fn position_y (& self) -> & AudioParam { & self . position_y } pub fn position_z (& self) -> & AudioParam { & self . position_z } pub fn set_position (& self , x : f32 , y : f32 , z : f32) { self . position_x . set_value (x) ; self . position_y . set_value (y) ; self . position_z . set_value (z) ; } pub fn orientation_x (& self) -> & AudioParam { & self . orientation_x } pub fn orientation_y (& self) -> & AudioParam { & self . orientation_y } pub fn orientation_z (& self) -> & AudioParam { & self . orientation_z } pub fn set_orientation (& self , x : f32 , y : f32 , z : f32) { self . orientation_x . set_value (x) ; self . orientation_y . set_value (y) ; self . orientation_z . set_value (z) ; } pub fn distance_model (& self) -> DistanceModelType { self . distance_model } pub fn set_distance_model (& mut self , value : DistanceModelType) { self . distance_model = value ; self . registration . post_message (ControlMessage :: DistanceModel (value)) ; } pub fn ref_distance (& self) -> f64 { self . ref_distance } # [doc = \" Set the refDistance attribute\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the provided value is negative.\"] pub fn set_ref_distance (& mut self , value : f64) { if ! (value >= 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - refDistance cannot be negative\")) ; } } ; self . ref_distance = value ; self . registration . post_message (ControlMessage :: RefDistance (value)) ; } pub fn max_distance (& self) -> f64 { self . max_distance } # [doc = \" Set the maxDistance attribute\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the provided value is negative.\"] pub fn set_max_distance (& mut self , value : f64) { if ! (value > 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - maxDistance must be positive\")) ; } } ; self . max_distance = value ; self . registration . post_message (ControlMessage :: MaxDistance (value)) ; } pub fn rolloff_factor (& self) -> f64 { self . rolloff_factor } # [doc = \" Set the rolloffFactor attribute\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the provided value is negative.\"] pub fn set_rolloff_factor (& mut self , value : f64) { if ! (value >= 0.) { { :: core :: panicking :: panic_fmt (format_args ! (\"RangeError - rolloffFactor cannot be negative\")) ; } } ; self . rolloff_factor = value ; self . registration . post_message (ControlMessage :: RollOffFactor (value)) ; } pub fn cone_inner_angle (& self) -> f64 { self . cone_inner_angle } pub fn set_cone_inner_angle (& mut self , value : f64) { self . cone_inner_angle = value ; self . registration . post_message (ControlMessage :: ConeInnerAngle (value)) ; } pub fn cone_outer_angle (& self) -> f64 { self . cone_outer_angle } pub fn set_cone_outer_angle (& mut self , value : f64) { self . cone_outer_angle = value ; self . registration . post_message (ControlMessage :: ConeOuterAngle (value)) ; } pub fn cone_outer_gain (& self) -> f64 { self . cone_outer_gain } # [doc = \" Set the coneOuterGain attribute\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if the provided value is not in the range [0, 1]\"] pub fn set_cone_outer_gain (& mut self , value : f64) { assert_valid_cone_outer_gain (value) ; self . cone_outer_gain = value ; self . registration . post_message (ControlMessage :: ConeOuterGain (value)) ; } pub fn panning_model (& self) -> PanningModelType { self . panning_model } # [allow (clippy :: missing_panics_doc)] pub fn set_panning_model (& mut self , value : PanningModelType) { let hrtf_option = match value { PanningModelType :: EqualPower => None , PanningModelType :: HRTF => { let sample_rate = self . context () . sample_rate () as u32 ; let (processor , len) = load_hrtf_processor (sample_rate) ; Some (HrtfState :: new (processor , len)) } } ; self . panning_model = value ; self . registration . post_message (ControlMessage :: PanningModel (Box :: new (hrtf_option))) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for SpatialParams { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for SpatialParams { # [inline] fn clone (& self) -> SpatialParams { let _ : :: core :: clone :: AssertParamIsClone < f32 > ; * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for PannerRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; if input . is_silent () { let tail_time = match & self . hrtf_state { None => false , Some (hrtf_state) => hrtf_state . tail_time_samples () > self . tail_time_counter , } ; if ! tail_time { output . make_silent () ; return false ; } self . tail_time_counter += RENDER_QUANTUM_SIZE ; } let mut hrtf_state = self . hrtf_state . take () ; let source_position_x = params . get (& self . position_x) ; let source_position_y = params . get (& self . position_y) ; let source_position_z = params . get (& self . position_z) ; let source_orientation_x = params . get (& self . orientation_x) ; let source_orientation_y = params . get (& self . orientation_y) ; let source_orientation_z = params . get (& self . orientation_z) ; let [listener_position_x , listener_position_y , listener_position_z , listener_forward_x , listener_forward_y , listener_forward_z , listener_up_x , listener_up_y , listener_up_z] = params . listener_params () ; let mut a_rate_params = source_position_x . iter () . cycle () . zip (source_position_y . iter () . cycle ()) . zip (source_position_z . iter () . cycle ()) . zip (source_orientation_x . iter () . cycle ()) . zip (source_orientation_y . iter () . cycle ()) . zip (source_orientation_z . iter () . cycle ()) . zip (listener_position_x . iter () . cycle ()) . zip (listener_position_y . iter () . cycle ()) . zip (listener_position_z . iter () . cycle ()) . zip (listener_forward_x . iter () . cycle ()) . zip (listener_forward_y . iter () . cycle ()) . zip (listener_forward_z . iter () . cycle ()) . zip (listener_up_x . iter () . cycle ()) . zip (listener_up_y . iter () . cycle ()) . zip (listener_up_z . iter () . cycle ()) . map (| tuple | { let ((((((sp_so_lp , lfx) , lfy) , lfz) , lux) , luy) , luz) = tuple ; let (((sp_so , lpx) , lpy) , lpz) = sp_so_lp ; let (((sp , sox) , soy) , soz) = sp_so ; let ((spx , spy) , spz) = sp ; let source_position = [* spx , * spy , * spz] ; let source_orientation = [* sox , * soy , * soz] ; let listener_position = [* lpx , * lpy , * lpz] ; let listener_forward = [* lfx , * lfy , * lfz] ; let listener_up = [* lux , * luy , * luz] ; let dist_gain = self . dist_gain (source_position , listener_position) ; let cone_gain = self . cone_gain (source_position , source_orientation , listener_position) ; let (azimuth , elevation) = crate :: spatial :: azimuth_and_elevation (source_position , listener_position , listener_forward , listener_up) ; SpatialParams { dist_gain , cone_gain , azimuth , elevation } }) ; if let Some (hrtf_state) = & mut hrtf_state { let SpatialParams { dist_gain , cone_gain , azimuth , elevation } = a_rate_params . next () . unwrap () ; let new_distance_gain = cone_gain * dist_gain ; let az_rad = azimuth * PI / 180. ; let el_rad = elevation * PI / 180. ; let x = az_rad . sin () * el_rad . cos () ; let z = az_rad . cos () * el_rad . cos () ; let y = el_rad . sin () ; let mut projected_source = [x , y , z] ; if { match (& & projected_source [..] , & & [0. ; 3] [..]) { (a_val , b_val) => { false || :: float_eq :: FloatEqCmp :: abs_all (a_val , b_val , & 1E-6) } } } { projected_source = [0. , 0. , 1.] ; } * output = input . clone () ; let mut overall_gain_correction = 1. ; if output . number_of_channels () == 2 { overall_gain_correction *= 2. ; output . mix (1 , ChannelInterpretation :: Speakers) ; } let output_interleaved = hrtf_state . process (output . channel_data (0) , new_distance_gain , projected_source) ; output . set_number_of_channels (2) ; let [left , right] = output . stereo_mut () ; output_interleaved . iter () . zip (& mut left [..]) . zip (& mut right [..]) . for_each (| ((p , l) , r) | { * l = overall_gain_correction * p . 0 ; * r = overall_gain_correction * p . 1 ; }) ; } else { let single_valued = listener_position_x . len () == 1 && listener_position_y . len () == 1 && listener_position_z . len () == 1 && listener_forward_x . len () == 1 && listener_forward_y . len () == 1 && listener_forward_z . len () == 1 && listener_up_x . len () == 1 && listener_up_y . len () == 1 && listener_up_z . len () == 1 ; if single_valued { let param_value = a_rate_params . next () . unwrap () ; match input . number_of_channels () { 1 => { * output = input . clone () ; output . mix (2 , ChannelInterpretation :: Speakers) ; let [left , right] = output . stereo_mut () ; left . iter_mut () . zip (& mut right [..]) . for_each (| (l , r) | apply_mono_to_stereo_gain (param_value , l , r)) ; } 2 => { output . set_number_of_channels (2) ; let [left , right] = output . stereo_mut () ; input . channel_data (0) . iter () . copied () . zip (input . channel_data (1) . iter () . copied ()) . zip (& mut left [..]) . zip (& mut right [..]) . for_each (| (((il , ir) , ol) , or) | { apply_stereo_to_stereo_gain (param_value , il , ir , ol , or) }) ; } _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } else { match input . number_of_channels () { 1 => { * output = input . clone () ; output . mix (2 , ChannelInterpretation :: Speakers) ; let [left , right] = output . stereo_mut () ; a_rate_params . zip (& mut left [..]) . zip (& mut right [..]) . for_each (| ((p , l) , r) | apply_mono_to_stereo_gain (p , l , r)) ; } 2 => { output . set_number_of_channels (2) ; let [left , right] = output . stereo_mut () ; a_rate_params . zip (input . channel_data (0) . iter () . copied ()) . zip (input . channel_data (1) . iter () . copied ()) . zip (& mut left [..]) . zip (& mut right [..]) . for_each (| ((((p , il) , ir) , ol) , or) | { apply_stereo_to_stereo_gain (p , il , ir , ol , or) }) ; } _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } } self . hrtf_state = hrtf_state ; self . hrtf_state . is_some () } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (control) = msg . downcast_mut :: < ControlMessage > () { match control { ControlMessage :: DistanceModel (value) => self . distance_model = * value , ControlMessage :: RefDistance (value) => self . ref_distance = * value , ControlMessage :: MaxDistance (value) => self . max_distance = * value , ControlMessage :: RollOffFactor (value) => self . rolloff_factor = * value , ControlMessage :: ConeInnerAngle (value) => self . cone_inner_angle = * value , ControlMessage :: ConeOuterAngle (value) => self . cone_outer_angle = * value , ControlMessage :: ConeOuterGain (value) => self . cone_outer_gain = * value , ControlMessage :: PanningModel (value) => self . hrtf_state = value . take () , } return ; } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"PannerRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::panner\" , \"web_audio_api::node::panner\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/panner.rs\") , 919u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl PannerRenderer { fn cone_gain (& self , source_position : [f32 ; 3] , source_orientation : [f32 ; 3] , listener_position : [f32 ; 3]) -> f32 { let abs_inner_angle = self . cone_inner_angle . abs () as f32 / 2. ; let abs_outer_angle = self . cone_outer_angle . abs () as f32 / 2. ; if abs_inner_angle >= 180. && abs_outer_angle >= 180. { 1. } else { let cone_outer_gain = self . cone_outer_gain as f32 ; let abs_angle = crate :: spatial :: angle (source_position , source_orientation , listener_position) ; if abs_angle < abs_inner_angle { 1. } else if abs_angle >= abs_outer_angle { cone_outer_gain } else { let x = (abs_angle - abs_inner_angle) / (abs_outer_angle - abs_inner_angle) ; (1. - x) + cone_outer_gain * x } } } fn dist_gain (& self , source_position : [f32 ; 3] , listener_position : [f32 ; 3]) -> f32 { let distance_model = self . distance_model ; let ref_distance = self . ref_distance ; let distance = crate :: spatial :: distance (source_position , listener_position) as f64 ; let dist_gain = match distance_model { DistanceModelType :: Linear => { let rolloff_factor = self . rolloff_factor . clamp (0. , 1.) ; let max_distance = self . max_distance ; let d2ref = ref_distance . min (max_distance) ; let d2max = ref_distance . max (max_distance) ; let d_clamped = distance . clamp (d2ref , d2max) ; 1. - rolloff_factor * (d_clamped - d2ref) / (d2max - d2ref) } DistanceModelType :: Inverse => { let rolloff_factor = self . rolloff_factor . max (0.) ; if distance > 0. { ref_distance / (ref_distance + rolloff_factor * (ref_distance . max (distance) - ref_distance)) } else { 1. } } DistanceModelType :: Exponential => { let rolloff_factor = self . rolloff_factor . max (0.) ; (distance . max (ref_distance) / ref_distance) . powf (- rolloff_factor) } } ; dist_gain as f32 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { AudioProcessingEvent , EventHandler , EventPayload , EventType , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AudioBuffer , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ScriptProcessorOptions { # [inline] fn clone (& self) -> ScriptProcessorOptions { ScriptProcessorOptions { buffer_size : :: core :: clone :: Clone :: clone (& self . buffer_size) , number_of_input_channels : :: core :: clone :: Clone :: clone (& self . number_of_input_channels) , number_of_output_channels : :: core :: clone :: Clone :: clone (& self . number_of_output_channels) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ScriptProcessorOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ScriptProcessorOptions\" , \"buffer_size\" , & self . buffer_size , \"number_of_input_channels\" , & self . number_of_input_channels , \"number_of_output_channels\" , & & self . number_of_output_channels) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ScriptProcessorNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ScriptProcessorNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"buffer_size\" , & & self . buffer_size) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for ScriptProcessorNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } fn set_channel_count_mode (& self , mode : ChannelCountMode) { match (& mode , & ChannelCountMode :: Explicit) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"NotSupportedError - ScriptProcessorNode channel count mode must be \\'explicit\\'\"))) ; } } } ; self . channel_config . set_count_mode (mode , self . registration ()) ; } fn set_channel_count (& self , count : usize) { match (& count , & self . channel_config . count ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"NotSupportedError - ScriptProcessorNode channel count must equal numberOfInputChannels\"))) ; } } } ; self . channel_config . set_count (count , self . registration ()) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ScriptProcessorNode { # [doc = \" Creates a `ScriptProcessorNode`\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" - `context` - Audio context in which the node will live\"] # [doc = \" - `options` - node options\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics if:\"] # [doc = \" - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\"] # [doc = \" - the number of input and output channels are both zero\"] # [doc = \" - either of the channel counts exceed [`crate::MAX_CHANNELS`]\"] pub fn new < C : BaseAudioContext > (context : & C , options : ScriptProcessorOptions) -> Self { let ScriptProcessorOptions { buffer_size , number_of_input_channels , number_of_output_channels } = options ; if ! ((buffer_size / 256) . is_power_of_two () && buffer_size <= 16384) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - bufferSize must be one of: 256, 512, 1024, 2048, 4096, 8192, 16384\")) ; } } ; match (number_of_input_channels , number_of_output_channels) { (0 , 0) => { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - numberOfInputChannels and numberOfOutputChannels cannot both be zero\")) ; } (0 , c) | (c , 0) => crate :: assert_valid_number_of_channels (c) , (c , d) => { crate :: assert_valid_number_of_channels (c) ; crate :: assert_valid_number_of_channels (d) ; } } ; context . base () . register (move | registration | { let number_of_quanta = buffer_size / RENDER_QUANTUM_SIZE ; let render = ScriptProcessorRenderer { input_buffer : Vec :: with_capacity (number_of_quanta) , output_buffer : Vec :: with_capacity (number_of_quanta) , next_output_buffer : Vec :: with_capacity (number_of_quanta) , buffer_size , number_of_output_channels , } ; let upmix_input_channels = if number_of_input_channels == 0 { 1 } else { number_of_input_channels } ; let audio_node_options = AudioNodeOptions { channel_count : upmix_input_channels , channel_count_mode : ChannelCountMode :: Explicit , channel_interpretation : ChannelInterpretation :: Speakers , } ; let node = ScriptProcessorNode { registration , channel_config : audio_node_options . into () , buffer_size , } ; (node , Box :: new (render)) }) } pub fn buffer_size (& self) -> usize { self . buffer_size } # [doc = \" Register callback to run when the AudioProcessingEvent is dispatched\"] # [doc = \"\"] # [doc = \" The event handler processes audio from the input (if any) by accessing the audio data from\"] # [doc = \" the inputBuffer attribute. The audio data which is the result of the processing (or the\"] # [doc = \" synthesized data if there are no inputs) is then placed into the outputBuffer.\"] # [doc = \"\"] # [doc = \" The output buffer is shipped back to the render thread when the AudioProcessingEvent goes\"] # [doc = \" out of scope, so be sure not to store it somewhere.\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] pub fn set_onaudioprocess < F : FnMut (AudioProcessingEvent) + Send + 'static > (& self , mut callback : F) { let base = self . registration () . context () . clone () ; let id = self . registration () . id () ; let callback = move | v | { let mut payload = match v { EventPayload :: AudioProcessing (v) => v , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } ; payload . registration = Some ((base . clone () , id)) ; callback (payload) ; } ; self . context () . set_event_handler (EventType :: AudioProcessing (self . registration () . id ()) , EventHandler :: Multiple (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when the AudioProcessingEvent is dispatched\"] pub fn clear_onaudioprocess (& self) { self . context () . clear_event_handler (EventType :: AudioProcessing (self . registration () . id ())) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [allow (clippy :: non_send_fields_in_send_ty)] unsafe impl Send for ScriptProcessorRenderer { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::script_processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for ScriptProcessorRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; output . make_silent () ; let silence = output . clone () ; if ! self . output_buffer . is_empty () { * output = self . output_buffer . remove (0) ; } let number_of_quanta = self . input_buffer . capacity () ; self . input_buffer . push (input . clone ()) ; if self . input_buffer . len () == number_of_quanta { let number_of_input_channels = self . input_buffer . iter () . map (| i | i . number_of_channels ()) . max () . unwrap () ; let mut input_samples = :: alloc :: vec :: from_elem (:: alloc :: vec :: from_elem (0. , self . buffer_size) , number_of_input_channels) ; self . input_buffer . iter () . enumerate () . for_each (| (i , b) | { let offset = RENDER_QUANTUM_SIZE * i ; b . channels () . iter () . zip (input_samples . iter_mut ()) . for_each (| (c , o) | { o [offset .. (offset + RENDER_QUANTUM_SIZE)] . copy_from_slice (c) ; }) ; }) ; let input_buffer = AudioBuffer :: from (input_samples , scope . sample_rate) ; let output_samples = :: alloc :: vec :: from_elem (:: alloc :: vec :: from_elem (0. , self . buffer_size) , self . number_of_output_channels) ; let output_buffer = AudioBuffer :: from (output_samples , scope . sample_rate) ; let playback_time = scope . current_time + self . buffer_size as f64 / scope . sample_rate as f64 ; scope . send_audio_processing_event (input_buffer , output_buffer , playback_time) ; self . input_buffer . clear () ; std :: mem :: swap (& mut self . output_buffer , & mut self . next_output_buffer) ; let mut silent_quantum = silence ; silent_quantum . set_number_of_channels (self . number_of_output_channels) ; self . next_output_buffer . clear () ; self . next_output_buffer . resize (number_of_quanta , silent_quantum) ; } false } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (buffer) = msg . downcast_mut :: < AudioBuffer > () { buffer . channels () . iter () . enumerate () . for_each (| (i , c) | { c . as_slice () . chunks (RENDER_QUANTUM_SIZE) . zip (self . next_output_buffer . iter_mut ()) . for_each (| (s , o) | o . channel_data_mut (i) . copy_from_slice (s)) }) ; return ; } ; { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"ScriptProcessorRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::script_processor\" , \"web_audio_api::node::script_processor\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/script_processor.rs\") , 272u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { precomputed_sine_table , AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , TABLE_LENGTH_BY_4_F32 , TABLE_LENGTH_BY_4_USIZE , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for StereoPannerOptions { # [inline] fn clone (& self) -> StereoPannerOptions { StereoPannerOptions { pan : :: core :: clone :: Clone :: clone (& self . pan) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for StereoPannerOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"StereoPannerOptions\" , \"pan\" , & self . pan , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for StereoPannerOptions { fn default () -> Self { Self { pan : 0. , audio_node_options : AudioNodeOptions { channel_count : 2 , channel_count_mode : ChannelCountMode :: ClampedMax , channel_interpretation : ChannelInterpretation :: Speakers , } , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for StereoPannerNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"StereoPannerNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"pan\" , & & self . pan) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for StereoPannerNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } fn set_channel_count_mode (& self , mode : ChannelCountMode) { assert_valid_channel_count_mode (mode) ; self . channel_config . set_count_mode (mode , self . registration ()) ; } fn set_channel_count (& self , count : usize) { assert_valid_channel_count (count) ; self . channel_config . set_count (count , self . registration ()) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl StereoPannerNode { # [doc = \" returns a `StereoPannerNode` instance\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `context` - audio context in which the audio node will live.\"] # [doc = \" * `options` - stereo panner options\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * `options.channel_config.count` is greater than 2\"] # [doc = \" * `options.channel_config.mode` is `ChannelCountMode::Max`\"] # [doc = \"\"] pub fn new < C : BaseAudioContext > (context : & C , options : StereoPannerOptions) -> Self { context . base () . register (move | registration | { assert_valid_channel_count_mode (options . audio_node_options . channel_count_mode) ; assert_valid_channel_count (options . audio_node_options . channel_count) ; let pan_options = AudioParamDescriptor { name : String :: new () , min_value : - 1. , max_value : 1. , default_value : 0. , automation_rate : crate :: param :: AutomationRate :: A , } ; let (pan_param , pan_proc) = context . create_audio_param (pan_options , & registration) ; pan_param . set_value (options . pan) ; let renderer = StereoPannerRenderer :: new (pan_proc) ; let node = Self { registration , channel_config : options . audio_node_options . into () , pan : pan_param , } ; (node , Box :: new (renderer)) }) } # [doc = \" Returns the pan audio parameter\"] # [must_use] pub fn pan (& self) -> & AudioParam { & self . pan } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl StereoPannerRenderer { fn new (pan : AudioParamId) -> Self { Self { pan , sine_table : precomputed_sine_table () } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::stereo_panner",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for StereoPannerRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; if input . is_silent () { output . make_silent () ; return false ; } output . set_number_of_channels (2) ; let pan_values = params . get (& self . pan) ; let [left , right] = output . stereo_mut () ; match input . number_of_channels () { 0 => () , 1 => { if pan_values . len () == 1 { let pan = pan_values [0] ; let x = (pan + 1.) * 0.5 ; let [gain_left , gain_right] = get_stereo_gains (self . sine_table , x) ; left . iter_mut () . zip (right . iter_mut ()) . zip (input . channel_data (0) . iter ()) . for_each (| ((l , r) , input) | { * l = input * gain_left ; * r = input * gain_right ; }) ; } else { left . iter_mut () . zip (right . iter_mut ()) . zip (pan_values . iter ()) . zip (input . channel_data (0) . iter ()) . for_each (| (((l , r) , pan) , input) | { let x = (pan + 1.) * 0.5 ; let [gain_left , gain_right] = get_stereo_gains (self . sine_table , x) ; * l = input * gain_left ; * r = input * gain_right ; }) ; } } 2 => { if pan_values . len () == 1 { let pan = pan_values [0] ; let x = if pan <= 0. { pan + 1. } else { pan } ; let [gain_left , gain_right] = get_stereo_gains (self . sine_table , x) ; left . iter_mut () . zip (right . iter_mut ()) . zip (input . channel_data (0) . iter ()) . zip (input . channel_data (1) . iter ()) . for_each (| (((l , r) , & input_left) , & input_right) | { if pan <= 0. { * l = input_right . mul_add (gain_left , input_left) ; * r = input_right * gain_right ; } else { * l = input_left * gain_left ; * r = input_left . mul_add (gain_right , input_right) ; } }) ; } else { left . iter_mut () . zip (right . iter_mut ()) . zip (pan_values . iter ()) . zip (input . channel_data (0) . iter ()) . zip (input . channel_data (1) . iter ()) . for_each (| ((((l , r) , & pan) , & input_left) , & input_right) | { if pan <= 0. { let x = pan + 1. ; let [gain_left , gain_right] = get_stereo_gains (self . sine_table , x) ; * l = input_right . mul_add (gain_left , input_left) ; * r = input_right * gain_right ; } else { let x = pan ; let [gain_left , gain_right] = get_stereo_gains (self . sine_table , x) ; * l = input_left * gain_left ; * r = input_left . mul_add (gain_right , input_right) ; } }) ; } } _ => { :: core :: panicking :: panic_fmt (format_args ! (\"StereoPannerNode should not have more than 2 channels to process\")) ; } } false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use rubato :: { FftFixedInOut , Resampler as _ } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { context :: { AudioContextRegistration , BaseAudioContext } , render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } , RENDER_QUANTUM_SIZE , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioNode , AudioNodeOptions , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for OverSampleType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { OverSampleType :: None => \"None\" , OverSampleType :: X2 => \"X2\" , OverSampleType :: X4 => \"X4\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for OverSampleType { # [inline] fn clone (& self) -> OverSampleType { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for OverSampleType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for OverSampleType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for OverSampleType { # [inline] fn eq (& self , other : & OverSampleType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for OverSampleType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for OverSampleType { fn default () -> Self { Self :: None } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl From < u32 > for OverSampleType { fn from (i : u32) -> Self { match i { 0 => OverSampleType :: None , 1 => OverSampleType :: X2 , 2 => OverSampleType :: X4 , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for WaveShaperOptions { # [inline] fn clone (& self) -> WaveShaperOptions { WaveShaperOptions { curve : :: core :: clone :: Clone :: clone (& self . curve) , oversample : :: core :: clone :: Clone :: clone (& self . oversample) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for WaveShaperOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"WaveShaperOptions\" , \"curve\" , & self . curve , \"oversample\" , & self . oversample , \"audio_node_options\" , & & self . audio_node_options) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Default for WaveShaperOptions { fn default () -> Self { Self { oversample : OverSampleType :: None , curve : None , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for WaveShaperNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"WaveShaperNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"curve\" , & self . curve , \"oversample\" , & & self . oversample) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for WaveShaperNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl WaveShaperNode { # [doc = \" returns a `WaveShaperNode` instance\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `context` - audio context in which the audio node will live.\"] # [doc = \" * `options` - waveshaper options\"] pub fn new < C : BaseAudioContext > (context : & C , options : WaveShaperOptions) -> Self { let WaveShaperOptions { oversample , curve , audio_node_options : channel_config } = options ; let mut node = context . base () . register (move | registration | { let sample_rate = context . sample_rate () as usize ; let renderer = WaveShaperRenderer :: new (RendererConfig { oversample , sample_rate , }) ; let node = Self { registration , channel_config : channel_config . into () , curve : None , oversample , } ; (node , Box :: new (renderer)) }) ; if let Some (curve) = curve { node . set_curve (curve) ; } node } # [doc = \" Returns the distortion curve\"] # [must_use] pub fn curve (& self) -> Option < & [f32] > { self . curve . as_deref () } # [doc = \" Set the distortion `curve` of this node\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `curve` - the desired distortion `curve`\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Panics if a curve has already been given to the source (though `new` or through\"] # [doc = \" `set_curve`)\"] pub fn set_curve (& mut self , curve : Vec < f32 >) { if ! self . curve . is_none () { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError - cannot assign curve twice\")) ; } } ; let clone = curve . clone () ; self . curve = Some (curve) ; self . registration . post_message (Some (clone)) ; } # [doc = \" Returns the `oversample` faactor of this node\"] # [must_use] pub fn oversample (& self) -> OverSampleType { self . oversample } # [doc = \" set the `oversample` factor of this node\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `oversample` - the desired `OversampleType` variant\"] pub fn set_oversample (& mut self , oversample : OverSampleType) { self . oversample = oversample ; self . registration . post_message (oversample) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ResamplerConfig { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"ResamplerConfig\" , \"channels\" , & self . channels , \"chunk_size_in\" , & self . chunk_size_in , \"sample_rate_in\" , & self . sample_rate_in , \"sample_rate_out\" , & & self . sample_rate_out) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ResamplerConfig { # [inline] fn clone (& self) -> ResamplerConfig { ResamplerConfig { channels : :: core :: clone :: Clone :: clone (& self . channels) , chunk_size_in : :: core :: clone :: Clone :: clone (& self . chunk_size_in) , sample_rate_in : :: core :: clone :: Clone :: clone (& self . sample_rate_in) , sample_rate_out : :: core :: clone :: Clone :: clone (& self . sample_rate_out) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for ResamplerConfig { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for ResamplerConfig { # [inline] fn eq (& self , other : & ResamplerConfig) -> bool { self . channels == other . channels && self . chunk_size_in == other . chunk_size_in && self . sample_rate_in == other . sample_rate_in && self . sample_rate_out == other . sample_rate_out } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for ResamplerConfig { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < usize > ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ResamplerConfig { fn upsample_x2 (channels : usize , sample_rate : usize) -> Self { let chunk_size_in = RENDER_QUANTUM_SIZE * 2 ; let sample_rate_in = sample_rate ; let sample_rate_out = sample_rate * 2 ; Self { channels , chunk_size_in , sample_rate_in , sample_rate_out , } } fn upsample_x4 (channels : usize , sample_rate : usize) -> Self { let chunk_size_in = RENDER_QUANTUM_SIZE * 4 ; let sample_rate_in = sample_rate ; let sample_rate_out = sample_rate * 4 ; Self { channels , chunk_size_in , sample_rate_in , sample_rate_out , } } fn downsample_x2 (channels : usize , sample_rate : usize) -> Self { let chunk_size_in = RENDER_QUANTUM_SIZE ; let sample_rate_in = sample_rate * 2 ; let sample_rate_out = sample_rate ; Self { channels , chunk_size_in , sample_rate_in , sample_rate_out , } } fn downsample_x4 (channels : usize , sample_rate : usize) -> Self { let chunk_size_in = RENDER_QUANTUM_SIZE ; let sample_rate_in = sample_rate * 4 ; let sample_rate_out = sample_rate ; Self { channels , chunk_size_in , sample_rate_in , sample_rate_out , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Resampler { fn new (config : ResamplerConfig) -> Self { let ResamplerConfig { channels , chunk_size_in , sample_rate_in , sample_rate_out } = & config ; let processor = FftFixedInOut :: new (* sample_rate_in , * sample_rate_out , * chunk_size_in , * channels) . unwrap () ; let samples_out = processor . output_buffer_allocate (true) ; Self { config , processor , samples_out } } fn process < T > (& mut self , samples_in : & [T]) where T : AsRef < [f32] > { if true { match (& self . config . channels , & samples_in . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; } ; if true { if ! samples_in . iter () . all (| channel | channel . as_ref () . len () == self . processor . input_frames_next ()) { :: core :: panicking :: panic (\"assertion failed: samples_in.iter().all(|channel|\\n        channel.as_ref().len() == self.processor.input_frames_next())\") } ; } ; let (in_len , out_len) = self . processor . process_into_buffer (samples_in , & mut self . samples_out [..] , None) . unwrap () ; if true { match (& in_len , & samples_in [0] . as_ref () . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; } ; if true { if ! self . samples_out . iter () . all (| channel | channel . len () == out_len) { :: core :: panicking :: panic (\"assertion failed: self.samples_out.iter().all(|channel| channel.len() == out_len)\") } ; } ; } fn samples_out (& self) -> & [Vec < f32 >] { & self . samples_out [..] } fn samples_out_mut (& mut self) -> & mut [Vec < f32 >] { & mut self . samples_out [..] } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for WaveShaperRenderer { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { let input = & inputs [0] ; let output = & mut outputs [0] ; if input . is_silent () && self . can_propagate_silence { output . make_silent () ; return false ; } * output = input . clone () ; if let Some (curve) = & self . curve { match self . oversample { OverSampleType :: None => { output . modify_channels (| channel | { channel . iter_mut () . for_each (| o | * o = apply_curve (curve , * o)) ; }) ; } OverSampleType :: X2 => { let channels = output . channels () ; if channels . len () != self . channels_x2 { self . channels_x2 = channels . len () ; self . upsampler_x2 = Resampler :: new (ResamplerConfig :: upsample_x2 (self . channels_x2 , self . sample_rate)) ; self . downsampler_x2 = Resampler :: new (ResamplerConfig :: downsample_x2 (self . channels_x2 , self . sample_rate)) ; } self . upsampler_x2 . process (channels) ; for channel in self . upsampler_x2 . samples_out_mut () . iter_mut () { for s in channel . iter_mut () { * s = apply_curve (curve , * s) ; } } self . downsampler_x2 . process (self . upsampler_x2 . samples_out ()) ; for (processed , output) in self . downsampler_x2 . samples_out () . iter () . zip (output . channels_mut ()) { output . copy_from_slice (& processed [..]) ; } } OverSampleType :: X4 => { let channels = output . channels () ; if channels . len () != self . channels_x4 { self . channels_x4 = channels . len () ; self . upsampler_x4 = Resampler :: new (ResamplerConfig :: upsample_x4 (self . channels_x4 , self . sample_rate)) ; self . downsampler_x4 = Resampler :: new (ResamplerConfig :: downsample_x4 (self . channels_x4 , self . sample_rate)) ; } self . upsampler_x4 . process (channels) ; for channel in self . upsampler_x4 . samples_out_mut () . iter_mut () { for s in channel . iter_mut () { * s = apply_curve (curve , * s) ; } } self . downsampler_x4 . process (self . upsampler_x4 . samples_out ()) ; for (processed , output) in self . downsampler_x4 . samples_out () . iter () . zip (output . channels_mut ()) { output . copy_from_slice (& processed [..]) ; } } } } false } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (& oversample) = msg . downcast_ref :: < OverSampleType > () { self . oversample = oversample ; return ; } if let Some (curve) = msg . downcast_mut :: < Option < Vec < f32 > > > () { std :: mem :: swap (& mut self . curve , curve) ; self . can_propagate_silence = if let Some (curve) = & self . curve { if curve . len () % 2 == 1 { curve [curve . len () / 2] . abs () < 1e-9 } else { let a = curve [curve . len () / 2 - 1] ; let b = curve [curve . len () / 2] ; ((a + b) / 2.) . abs () < 1e-9 } } else { true } ; return ; } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"WaveShaperRenderer: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::node::waveshaper\" , \"web_audio_api::node::waveshaper\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/node/waveshaper.rs\") , 517u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::node::waveshaper",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl WaveShaperRenderer { # [doc = \" returns an `WaveShaperRenderer` instance\"] # [allow (clippy :: missing_const_for_fn)] fn new (config : RendererConfig) -> Self { let RendererConfig { sample_rate , oversample } = config ; let channels_x2 = 1 ; let channels_x4 = 1 ; let upsampler_x2 = Resampler :: new (ResamplerConfig :: upsample_x2 (channels_x2 , sample_rate)) ; let downsampler_x2 = Resampler :: new (ResamplerConfig :: downsample_x2 (channels_x2 , sample_rate)) ; let upsampler_x4 = Resampler :: new (ResamplerConfig :: upsample_x4 (channels_x2 , sample_rate)) ; let downsampler_x4 = Resampler :: new (ResamplerConfig :: downsample_x4 (channels_x2 , sample_rate)) ; Self { oversample , curve : None , sample_rate , channels_x2 , channels_x4 , upsampler_x2 , upsampler_x4 , downsampler_x2 , downsampler_x4 , can_propagate_silence : true , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: ConcreteBaseAudioContext ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextState , AudioNodeId } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AudioBuffer , AudioRenderCapacityEvent } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: collections :: HashMap ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: hash :: Hash ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: ops :: ControlFlow ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: Receiver ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for Event { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"Event\" , \"type_\" , & & self . type_) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for Event { # [inline] fn clone (& self) -> Event { Event { type_ : :: core :: clone :: Clone :: clone (& self . type_) } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: hash :: Hash for EventType { # [inline] fn hash < __H : :: core :: hash :: Hasher > (& self , state : & mut __H) -> () { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; :: core :: hash :: Hash :: hash (& __self_tag , state) ; match self { EventType :: Ended (__self_0) => :: core :: hash :: Hash :: hash (__self_0 , state) , EventType :: ProcessorError (__self_0) => :: core :: hash :: Hash :: hash (__self_0 , state) , EventType :: Message (__self_0) => :: core :: hash :: Hash :: hash (__self_0 , state) , EventType :: AudioProcessing (__self_0) => :: core :: hash :: Hash :: hash (__self_0 , state) , _ => { } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for EventType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { let _ : :: core :: cmp :: AssertParamIsEq < AudioNodeId > ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for EventType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for EventType { # [inline] fn eq (& self , other : & EventType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag && match (self , other) { (EventType :: Ended (__self_0) , EventType :: Ended (__arg1_0)) => * __self_0 == * __arg1_0 , (EventType :: ProcessorError (__self_0) , EventType :: ProcessorError (__arg1_0)) => * __self_0 == * __arg1_0 , (EventType :: Message (__self_0) , EventType :: Message (__arg1_0)) => * __self_0 == * __arg1_0 , (EventType :: AudioProcessing (__self_0) , EventType :: AudioProcessing (__arg1_0)) => * __self_0 == * __arg1_0 , _ => true , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for EventType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { EventType :: Ended (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Ended\" , & __self_0) , EventType :: SinkChange => :: core :: fmt :: Formatter :: write_str (f , \"SinkChange\") , EventType :: StateChange => :: core :: fmt :: Formatter :: write_str (f , \"StateChange\") , EventType :: RenderCapacity => :: core :: fmt :: Formatter :: write_str (f , \"RenderCapacity\") , EventType :: ProcessorError (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"ProcessorError\" , & __self_0) , EventType :: Diagnostics => :: core :: fmt :: Formatter :: write_str (f , \"Diagnostics\") , EventType :: Message (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Message\" , & __self_0) , EventType :: Complete => :: core :: fmt :: Formatter :: write_str (f , \"Complete\") , EventType :: AudioProcessing (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"AudioProcessing\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ErrorEvent { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"ErrorEvent\" , \"message\" , & self . message , \"error\" , & self . error , \"event\" , & & self . event) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioProcessingEvent { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field4_finish (f , \"AudioProcessingEvent\" , \"input_buffer\" , & self . input_buffer , \"output_buffer\" , & self . output_buffer , \"playback_time\" , & self . playback_time , \"registration\" , & & self . registration) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Drop for AudioProcessingEvent { fn drop (& mut self) { if let Some ((context , id)) = self . registration . take () { let wrapped = crate :: message :: ControlMessage :: NodeMessage { id , msg : llq :: Node :: new (Box :: new (self . output_buffer . clone ())) , } ; context . send_control_msg (wrapped) ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for OfflineAudioCompletionEvent { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"OfflineAudioCompletionEvent\" , \"rendered_buffer\" , & self . rendered_buffer , \"event\" , & & self . event) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for EventPayload { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { match self { EventPayload :: None => :: core :: fmt :: Formatter :: write_str (f , \"None\") , EventPayload :: RenderCapacity (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"RenderCapacity\" , & __self_0) , EventPayload :: ProcessorError (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"ProcessorError\" , & __self_0) , EventPayload :: Diagnostics (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Diagnostics\" , & __self_0) , EventPayload :: Message (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Message\" , & __self_0) , EventPayload :: AudioContextState (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"AudioContextState\" , & __self_0) , EventPayload :: Complete (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"Complete\" , & __self_0) , EventPayload :: AudioProcessing (__self_0) => :: core :: fmt :: Formatter :: debug_tuple_field1_finish (f , \"AudioProcessing\" , & __self_0) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for EventDispatch { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"EventDispatch\" , \"type_\" , & self . type_ , \"payload\" , & & self . payload) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl EventDispatch { pub fn ended (id : AudioNodeId) -> Self { EventDispatch { type_ : EventType :: Ended (id) , payload : EventPayload :: None , } } pub fn sink_change () -> Self { EventDispatch { type_ : EventType :: SinkChange , payload : EventPayload :: None , } } pub fn state_change (state : AudioContextState) -> Self { EventDispatch { type_ : EventType :: StateChange , payload : EventPayload :: AudioContextState (state) , } } pub fn render_capacity (value : AudioRenderCapacityEvent) -> Self { EventDispatch { type_ : EventType :: RenderCapacity , payload : EventPayload :: RenderCapacity (value) , } } pub fn processor_error (id : AudioNodeId , value : ErrorEvent) -> Self { EventDispatch { type_ : EventType :: ProcessorError (id) , payload : EventPayload :: ProcessorError (value) , } } pub fn diagnostics (value : Vec < u8 >) -> Self { EventDispatch { type_ : EventType :: Diagnostics , payload : EventPayload :: Diagnostics (value) , } } pub fn message (id : AudioNodeId , value : Box < dyn Any + Send + 'static >) -> Self { EventDispatch { type_ : EventType :: Message (id) , payload : EventPayload :: Message (value) , } } pub fn complete (buffer : AudioBuffer) -> Self { EventDispatch { type_ : EventType :: Complete , payload : EventPayload :: Complete (buffer) , } } pub fn audio_processing (id : AudioNodeId , value : AudioProcessingEvent) -> Self { EventDispatch { type_ : EventType :: AudioProcessing (id) , payload : EventPayload :: AudioProcessing (value) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for EventLoop { # [inline] fn clone (& self) -> EventLoop { EventLoop { event_recv : :: core :: clone :: Clone :: clone (& self . event_recv) , event_handlers : :: core :: clone :: Clone :: clone (& self . event_handlers) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::events",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl EventLoop { pub fn new (event_recv : Receiver < EventDispatch >) -> Self { Self { event_recv , event_handlers : Default :: default () } } fn handle_event (& self , mut event : EventDispatch) -> ControlFlow < () > { let mut result = ControlFlow :: Continue (()) ; if match event . payload { EventPayload :: AudioContextState (AudioContextState :: Closed) => true , _ => false , } { event . payload = EventPayload :: None ; result = ControlFlow :: Break (()) ; } let mut event_handler_lock = self . event_handlers . lock () . unwrap () ; let callback_option = event_handler_lock . remove (& event . type_) ; drop (event_handler_lock) ; if let Some (callback) = callback_option { match callback { EventHandler :: Once (f) => (f) (event . payload) , EventHandler :: Multiple (mut f) => { (f) (event . payload) ; self . event_handlers . lock () . unwrap () . insert (event . type_ , EventHandler :: Multiple (f)) ; } } ; } result } # [inline (always)] pub fn handle_pending_events (& self) -> bool { let mut events_were_handled = false ; for event in self . event_recv . try_iter () { self . handle_event (event) ; events_were_handled = true ; } events_were_handled } pub fn run_in_thread (& self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Entering event thread\") , lvl , & (\"web_audio_api::events\" , \"web_audio_api::events\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/events.rs\") , 226u32 , ()) ; } } ; let self_clone = self . clone () ; std :: thread :: spawn (move | | { for event in self_clone . event_recv . iter () { let result = self_clone . handle_event (event) ; if result . is_break () { break ; } } { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Event loop has terminated\") , lvl , & (\"web_audio_api::events\" , \"web_audio_api::events\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/events.rs\") , 240u32 , ()) ; } } ; }) ; } pub fn set_handler (& self , event : EventType , callback : EventHandler) { self . event_handlers . lock () . unwrap () . insert (event , callback) ; } pub fn clear_handler (& self , event : EventType) { self . event_handlers . lock () . unwrap () . remove (& event) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message_port",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message_port",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: AudioContextRegistration ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message_port",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: AudioNode ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message_port",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { EventHandler , EventPayload , EventType } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message_port",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < 'a > std :: fmt :: Debug for MessagePort < 'a > { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"MessagePort\") . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message_port",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < 'a > MessagePort < 'a > { pub (crate) fn from_node (node : & 'a dyn AudioNode) -> Self { Self (node . registration ()) } # [doc = \" Send a message from the port.\"] pub fn post_message < M : Any + Send + 'static > (& self , msg : M) { self . 0 . post_message (msg) ; } # [doc = \" Register callback to run when a message arrives on the channel.\"] # [doc = \"\"] # [doc = \" Only a single event handler is active at any time. Calling this method multiple times will\"] # [doc = \" override the previous event handler.\"] pub fn set_onmessage < F : FnMut (Box < dyn Any + Send + 'static >) + Send + 'static > (& self , mut callback : F) { let callback = move | v | match v { EventPayload :: Message (v) => callback (v) , _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } ; self . 0 . context () . set_event_handler (EventType :: Message (self . 0 . id ()) , EventHandler :: Multiple (Box :: new (callback))) ; } # [doc = \" Unset the callback to run when a message arrives on the channel.\"] pub fn clear_onmessage (& self) { self . 0 . context () . clear_event_handler (EventType :: Message (self . 0 . id ())) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: slice :: { Iter , IterMut } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: Ordering ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex , OnceLock } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use arrayvec :: ArrayVec ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: AudioContextRegistration ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { assert_valid_time_value , AtomicF32 , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [doc = \" For SetTargetAtTime event, that theoretically cannot end, if the diff between\"] # [doc = \" the current value and the target is below this threshold, the value is set\"] # [doc = \" to target value and the event is considered ended.\"] const SNAP_TO_TARGET : f32 = 1e-10 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AutomationRate { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AutomationRate { # [inline] fn clone (& self) -> AutomationRate { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for AutomationRate { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for AutomationRate { # [inline] fn eq (& self , other : & AutomationRate) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for AutomationRate { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AutomationRate { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { AutomationRate :: A => \"A\" , AutomationRate :: K => \"K\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AutomationRate { fn is_a_rate (self) -> bool { match self { AutomationRate :: A => true , AutomationRate :: K => false , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioParamDescriptor { # [inline] fn clone (& self) -> AudioParamDescriptor { AudioParamDescriptor { name : :: core :: clone :: Clone :: clone (& self . name) , automation_rate : :: core :: clone :: Clone :: clone (& self . automation_rate) , default_value : :: core :: clone :: Clone :: clone (& self . default_value) , min_value : :: core :: clone :: Clone :: clone (& self . min_value) , max_value : :: core :: clone :: Clone :: clone (& self . max_value) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamDescriptor { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"AudioParamDescriptor\" , \"name\" , & self . name , \"automation_rate\" , & self . automation_rate , \"default_value\" , & self . default_value , \"min_value\" , & self . min_value , \"max_value\" , & & self . max_value) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: StructuralPartialEq for AudioParamEventType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: PartialEq for AudioParamEventType { # [inline] fn eq (& self , other : & AudioParamEventType) -> bool { let __self_tag = :: core :: intrinsics :: discriminant_value (self) ; let __arg1_tag = :: core :: intrinsics :: discriminant_value (other) ; __self_tag == __arg1_tag } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: cmp :: Eq for AudioParamEventType { # [inline] # [doc (hidden)] # [coverage (off)] fn assert_receiver_is_total_eq (& self) -> () { } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamEventType { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , match self { AudioParamEventType :: SetValue => \"SetValue\" , AudioParamEventType :: SetValueAtTime => \"SetValueAtTime\" , AudioParamEventType :: LinearRampToValueAtTime => \"LinearRampToValueAtTime\" , AudioParamEventType :: ExponentialRampToValueAtTime => \"ExponentialRampToValueAtTime\" , AudioParamEventType :: CancelScheduledValues => \"CancelScheduledValues\" , AudioParamEventType :: SetTargetAtTime => \"SetTargetAtTime\" , AudioParamEventType :: CancelAndHoldAtTime => \"CancelAndHoldAtTime\" , AudioParamEventType :: SetValueCurveAtTime => \"SetValueCurveAtTime\" , }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: marker :: Copy for AudioParamEventType { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioParamEventType { # [inline] fn clone (& self) -> AudioParamEventType { * self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamEvent { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"event_type\" , \"value\" , \"time\" , \"time_constant\" , \"cancel_time\" , \"duration\" , \"values\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . event_type , & self . value , & self . time , & self . time_constant , & self . cancel_time , & self . duration , & & self . values] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioParamEvent\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamEventTimeline { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AudioParamEventTimeline\" , \"inner\" , & self . inner , \"dirty\" , & & self . dirty) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for AudioParamEventTimeline { # [inline] fn default () -> AudioParamEventTimeline { AudioParamEventTimeline { inner : :: core :: default :: Default :: default () , dirty : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioParamEventTimeline { fn new () -> Self { Self { inner : Vec :: with_capacity (32) , dirty : false } } fn push (& mut self , item : AudioParamEvent) { self . dirty = true ; self . inner . push (item) ; } fn pop (& mut self) -> Option < AudioParamEvent > { if ! self . inner . is_empty () { Some (self . inner . remove (0)) } else { None } } fn retain < F > (& mut self , func : F) where F : Fn (& AudioParamEvent) -> bool { self . inner . retain (func) ; } fn replace_peek (& mut self , item : AudioParamEvent) { self . inner [0] = item ; } fn is_empty (& self) -> bool { self . inner . is_empty () } fn unsorted_peek (& self) -> Option < & AudioParamEvent > { self . inner . first () } fn peek (& self) -> Option < & AudioParamEvent > { if ! ! self . dirty { { :: core :: panicking :: panic_fmt (format_args ! (\"`AudioParamEventTimeline`: Invalid `.peek()` call, the queue is dirty\")) ; } } ; self . inner . first () } fn next (& self) -> Option < & AudioParamEvent > { if ! ! self . dirty { { :: core :: panicking :: panic_fmt (format_args ! (\"`AudioParamEventTimeline`: Invalid `.next()` call, the queue is dirty\")) ; } } ; self . inner . get (1) } fn sort (& mut self) { self . inner . sort_by (| a , b | a . time . partial_cmp (& b . time) . unwrap ()) ; self . dirty = false ; } fn iter (& mut self) -> Iter < '_ , AudioParamEvent > { self . inner . iter () } fn iter_mut (& mut self) -> IterMut < '_ , AudioParamEvent > { self . inner . iter_mut () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioParam { # [inline] fn clone (& self) -> AudioParam { AudioParam { registration : :: core :: clone :: Clone :: clone (& self . registration) , raw_parts : :: core :: clone :: Clone :: clone (& self . raw_parts) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for AudioParam { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"AudioParam\") . field (\"registration\" , & self . registration ()) . field (\"automation_rate\" , & self . automation_rate ()) . field (\"automation_rate_constrained\" , & self . raw_parts . automation_rate_constrained) . field (\"default_value\" , & self . default_value ()) . field (\"min_value\" , & self . min_value ()) . field (\"max_value\" , & self . max_value ()) . finish () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamInner { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"default_value\" , \"min_value\" , \"max_value\" , \"automation_rate_constrained\" , \"automation_rate\" , \"current_value\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . default_value , & self . min_value , & self . max_value , & self . automation_rate_constrained , & self . automation_rate , & & self . current_value] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioParamInner\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioParamInner { # [inline] fn clone (& self) -> AudioParamInner { AudioParamInner { default_value : :: core :: clone :: Clone :: clone (& self . default_value) , min_value : :: core :: clone :: Clone :: clone (& self . min_value) , max_value : :: core :: clone :: Clone :: clone (& self . max_value) , automation_rate_constrained : :: core :: clone :: Clone :: clone (& self . automation_rate_constrained) , automation_rate : :: core :: clone :: Clone :: clone (& self . automation_rate) , current_value : :: core :: clone :: Clone :: clone (& self . current_value) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for AudioParam { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & 'static ChannelConfig { static INSTANCE : OnceLock < ChannelConfig > = OnceLock :: new () ; INSTANCE . get_or_init (| | { AudioNodeOptions { channel_count : 1 , channel_count_mode : ChannelCountMode :: Explicit , channel_interpretation : ChannelInterpretation :: Discrete , } . into () }) } fn number_of_inputs (& self) -> usize { 1 } fn number_of_outputs (& self) -> usize { 1 } fn set_channel_count (& self , _v : usize) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - AudioParam has channel count constraints\")) ; } ; } fn set_channel_count_mode (& self , _v : ChannelCountMode) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - AudioParam has channel count mode constraints\")) ; } ; } fn set_channel_interpretation (& self , _v : ChannelInterpretation) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - AudioParam has channel interpretation constraints\")) ; } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioParam { # [doc = \" Current value of the automation rate of the AudioParam\"] # [allow (clippy :: missing_panics_doc)] pub fn automation_rate (& self) -> AutomationRate { * self . raw_parts . automation_rate . lock () . unwrap () } # [doc = \" Update the current value of the automation rate of the AudioParam\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Some nodes have automation rate constraints and may panic when updating the value.\"] pub fn set_automation_rate (& self , value : AutomationRate) { if ! (! self . raw_parts . automation_rate_constrained || value == self . automation_rate ()) { { :: core :: panicking :: panic_fmt (format_args ! (\"InvalidStateError - automation rate cannot be changed for this param\")) ; } } ; let mut guard = self . raw_parts . automation_rate . lock () . unwrap () ; * guard = value ; self . registration () . post_message (value) ; drop (guard) ; } pub (crate) fn set_automation_rate_constrained (& mut self , value : bool) { self . raw_parts . automation_rate_constrained = value ; } pub fn default_value (& self) -> f32 { self . raw_parts . default_value } pub fn min_value (& self) -> f32 { self . raw_parts . min_value } pub fn max_value (& self) -> f32 { self . raw_parts . max_value } # [doc = \" Retrieve the current value of the `AudioParam`.\"] pub fn value (& self) -> f32 { self . raw_parts . current_value . load (Ordering :: Acquire) } # [doc = \" Set the value of the `AudioParam`.\"] # [doc = \"\"] # [doc = \" Is equivalent to calling the `set_value_at_time` method with the current\"] # [doc = \" AudioContext's currentTime\"] pub fn set_value (& self , value : f32) -> & Self { self . send_event (self . set_value_raw (value)) } fn set_value_raw (& self , value : f32) -> AudioParamEvent { assert_is_finite (value) ; let clamped = value . clamp (self . raw_parts . min_value , self . raw_parts . max_value) ; self . raw_parts . current_value . store (clamped , Ordering :: Release) ; AudioParamEvent { event_type : AudioParamEventType :: SetValue , value , time : 0. , time_constant : None , cancel_time : None , duration : None , values : None , } } # [doc = \" Schedules a parameter value change at the given time.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if `start_time` is negative\"] pub fn set_value_at_time (& self , value : f32 , start_time : f64) -> & Self { self . send_event (self . set_value_at_time_raw (value , start_time)) } fn set_value_at_time_raw (& self , value : f32 , start_time : f64) -> AudioParamEvent { assert_is_finite (value) ; assert_valid_time_value (start_time) ; AudioParamEvent { event_type : AudioParamEventType :: SetValueAtTime , value , time : start_time , time_constant : None , cancel_time : None , duration : None , values : None , } } # [doc = \" Schedules a linear continuous change in parameter value from the\"] # [doc = \" previous scheduled parameter value to the given value.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if `end_time` is negative\"] pub fn linear_ramp_to_value_at_time (& self , value : f32 , end_time : f64) -> & Self { self . send_event (self . linear_ramp_to_value_at_time_raw (value , end_time)) } fn linear_ramp_to_value_at_time_raw (& self , value : f32 , end_time : f64) -> AudioParamEvent { assert_is_finite (value) ; assert_valid_time_value (end_time) ; AudioParamEvent { event_type : AudioParamEventType :: LinearRampToValueAtTime , value , time : end_time , time_constant : None , cancel_time : None , duration : None , values : None , } } # [doc = \" Schedules an exponential continuous change in parameter value from the\"] # [doc = \" previous scheduled parameter value to the given value.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \" - `value` is zero\"] # [doc = \" - `end_time` is negative\"] pub fn exponential_ramp_to_value_at_time (& self , value : f32 , end_time : f64) -> & Self { self . send_event (self . exponential_ramp_to_value_at_time_raw (value , end_time)) } fn exponential_ramp_to_value_at_time_raw (& self , value : f32 , end_time : f64) -> AudioParamEvent { assert_not_zero (value) ; assert_valid_time_value (end_time) ; AudioParamEvent { event_type : AudioParamEventType :: ExponentialRampToValueAtTime , value , time : end_time , time_constant : None , cancel_time : None , duration : None , values : None , } } # [doc = \" Start exponentially approaching the target value at the given time with\"] # [doc = \" a rate having the given time constant.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \" - `start_time` is negative\"] # [doc = \" - `time_constant` is negative\"] pub fn set_target_at_time (& self , value : f32 , start_time : f64 , time_constant : f64) -> & Self { self . send_event (self . set_target_at_time_raw (value , start_time , time_constant)) } fn set_target_at_time_raw (& self , value : f32 , start_time : f64 , time_constant : f64) -> AudioParamEvent { assert_is_finite (value) ; assert_valid_time_value (start_time) ; assert_valid_time_value (time_constant) ; if time_constant == 0. { AudioParamEvent { event_type : AudioParamEventType :: SetValueAtTime , value , time : start_time , time_constant : None , cancel_time : None , duration : None , values : None , } } else { AudioParamEvent { event_type : AudioParamEventType :: SetTargetAtTime , value , time : start_time , time_constant : Some (time_constant) , cancel_time : None , duration : None , values : None , } } } # [doc = \" Cancels all scheduled parameter changes with times greater than or equal\"] # [doc = \" to `cancel_time`.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if `cancel_time` is negative\"] pub fn cancel_scheduled_values (& self , cancel_time : f64) -> & Self { self . send_event (self . cancel_scheduled_values_raw (cancel_time)) } fn cancel_scheduled_values_raw (& self , cancel_time : f64) -> AudioParamEvent { assert_valid_time_value (cancel_time) ; AudioParamEvent { event_type : AudioParamEventType :: CancelScheduledValues , value : 0. , time : cancel_time , time_constant : None , cancel_time : None , duration : None , values : None , } } # [doc = \" Cancels all scheduled parameter changes with times greater than or equal\"] # [doc = \" to `cancel_time` and the automation value that would have happened at\"] # [doc = \" that time is then propagated for all future time.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if `cancel_time` is negative\"] pub fn cancel_and_hold_at_time (& self , cancel_time : f64) -> & Self { self . send_event (self . cancel_and_hold_at_time_raw (cancel_time)) } fn cancel_and_hold_at_time_raw (& self , cancel_time : f64) -> AudioParamEvent { assert_valid_time_value (cancel_time) ; AudioParamEvent { event_type : AudioParamEventType :: CancelAndHoldAtTime , value : 0. , time : cancel_time , time_constant : None , cancel_time : None , duration : None , values : None , } } # [doc = \" Sets an array of arbitrary parameter values starting at the given time\"] # [doc = \" for the given duration.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \" - `value` length is less than 2\"] # [doc = \" - `start_time` is negative\"] # [doc = \" - `duration` is negative or equal to zero\"] pub fn set_value_curve_at_time (& self , values : & [f32] , start_time : f64 , duration : f64) -> & Self { self . send_event (self . set_value_curve_at_time_raw (values , start_time , duration)) } fn set_value_curve_at_time_raw (& self , values : & [f32] , start_time : f64 , duration : f64) -> AudioParamEvent { assert_sequence_length (values) ; assert_valid_time_value (start_time) ; assert_strictly_positive (duration) ; let copy = values . to_vec () ; let boxed_copy = copy . into_boxed_slice () ; AudioParamEvent { event_type : AudioParamEventType :: SetValueCurveAtTime , value : 0. , time : start_time , time_constant : None , cancel_time : None , duration : Some (duration) , values : Some (boxed_copy) , } } pub (crate) fn into_raw_parts (self) -> AudioParamInner { let Self { registration : _ , raw_parts } = self ; raw_parts } pub (crate) fn from_raw_parts (registration : AudioContextRegistration , raw_parts : AudioParamInner) -> Self { Self { registration : registration . into () , raw_parts } } fn send_event (& self , event : AudioParamEvent) -> & Self { self . registration () . post_message (event) ; self } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioParamProcessor { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"default_value\" , \"min_value\" , \"max_value\" , \"intrinsic_value\" , \"automation_rate\" , \"current_value\" , \"event_timeline\" , \"last_event\" , \"buffer\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . default_value , & self . min_value , & self . max_value , & self . intrinsic_value , & self . automation_rate , & self . current_value , & self . event_timeline , & self . last_event , & & self . buffer] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioParamProcessor\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for AudioParamProcessor { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let period = 1. / scope . sample_rate as f64 ; let input = & inputs [0] ; let output = & mut outputs [0] ; self . compute_intrinsic_values (scope . current_time , period , RENDER_QUANTUM_SIZE) ; self . mix_to_output (input , output) ; true } fn onmessage (& mut self , msg : & mut dyn Any) { if let Some (automation_rate) = msg . downcast_ref :: < AutomationRate > () { self . automation_rate = * automation_rate ; return ; } if let Some (event) = msg . downcast_mut :: < AudioParamEvent > () { let tombstone_event = AudioParamEvent { event_type : AudioParamEventType :: SetValue , value : Default :: default () , time : Default :: default () , time_constant : None , cancel_time : None , duration : None , values : None , } ; let event = std :: mem :: replace (event , tombstone_event) ; self . handle_incoming_event (event) ; return ; } ; { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"AudioParamProcessor: Dropping incoming message {0:?}\" , msg) , lvl , & (\"web_audio_api::param\" , \"web_audio_api::param\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/param.rs\") , 726u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::param",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioParamProcessor { fn compute_intrinsic_values (& mut self , block_time : f64 , dt : f64 , count : usize) -> & [f32] { self . compute_buffer (block_time , dt , count) ; self . buffer . as_slice () } fn mix_to_output (& mut self , input : & AudioRenderQuantum , output : & mut AudioRenderQuantum) { if self . buffer . len () == 1 || ! self . automation_rate . is_a_rate () { let mut value = self . buffer [0] ; if input . is_silent () || ! self . automation_rate . is_a_rate () { output . set_single_valued (true) ; value += input . channel_data (0) [0] ; if value . is_nan () { value = self . default_value ; } else { value = value . max (self . min_value) . min (self . max_value) ; } output . channel_data_mut (0) [0] = value ; } else { output . set_single_valued (false) ; * output = input . clone () ; output . channel_data_mut (0) . iter_mut () . for_each (| o | { * o += value ; if o . is_nan () { * o = self . default_value ; } else { * o = o . max (self . min_value) . min (self . max_value) ; } }) ; } } else { * output = input . clone () ; output . set_single_valued (false) ; output . channel_data_mut (0) . iter_mut () . zip (self . buffer . iter ()) . for_each (| (o , p) | { * o += p ; if o . is_nan () { * o = self . default_value ; } else { * o = o . max (self . min_value) . min (self . max_value) ; } }) ; } } fn handle_incoming_event (& mut self , event : AudioParamEvent) { if event . event_type == AudioParamEventType :: CancelScheduledValues { let some_current_event = self . event_timeline . unsorted_peek () ; match some_current_event { None => () , Some (current_event) => { match current_event . event_type { AudioParamEventType :: LinearRampToValueAtTime | AudioParamEventType :: ExponentialRampToValueAtTime => { if current_event . time >= event . time { let last_event = self . last_event . as_ref () . unwrap () ; self . intrinsic_value = last_event . value ; } } _ => () , } } } self . event_timeline . retain (| queued | queued . time < event . time) ; return ; } if event . event_type == AudioParamEventType :: CancelAndHoldAtTime { let mut e1 : Option < & mut AudioParamEvent > = None ; let mut e2 : Option < & mut AudioParamEvent > = None ; let mut t1 = f64 :: MIN ; let mut t2 = f64 :: MAX ; self . event_timeline . sort () ; for queued in self . event_timeline . iter_mut () { if queued . time >= t1 && queued . time <= event . time { t1 = queued . time ; e1 = Some (queued) ; } else if queued . time < t2 && queued . time > event . time { t2 = queued . time ; e2 = Some (queued) ; } } if let Some (matched) = e2 { if matched . event_type == AudioParamEventType :: LinearRampToValueAtTime || matched . event_type == AudioParamEventType :: ExponentialRampToValueAtTime { matched . cancel_time = Some (event . time) ; } } else if let Some (matched) = e1 { if matched . event_type == AudioParamEventType :: SetTargetAtTime { matched . cancel_time = Some (event . time) ; } else if matched . event_type == AudioParamEventType :: SetValueCurveAtTime { let start_time = matched . time ; let duration = matched . duration . unwrap () ; if event . time <= start_time + duration { matched . cancel_time = Some (event . time) ; } } } self . event_timeline . retain (| queued | { let mut time = queued . time ; if let Some (cancel_time) = queued . cancel_time { time = cancel_time ; } time <= event . time }) ; return ; } if event . event_type == AudioParamEventType :: SetValueCurveAtTime { let start_time = event . time ; let end_time = start_time + event . duration . unwrap () ; for queued in self . event_timeline . iter () { if ! (queued . time <= start_time || queued . time >= end_time) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - scheduling SetValueCurveAtTime ({0:?}) at time of another automation event ({1:?})\" , event , queued)) ; } } ; } } if event . event_type == AudioParamEventType :: SetValueAtTime || event . event_type == AudioParamEventType :: SetValue || event . event_type == AudioParamEventType :: LinearRampToValueAtTime || event . event_type == AudioParamEventType :: ExponentialRampToValueAtTime || event . event_type == AudioParamEventType :: SetTargetAtTime { for queued in self . event_timeline . iter () { if queued . event_type == AudioParamEventType :: SetValueCurveAtTime { let start_time = queued . time ; let end_time = start_time + queued . duration . unwrap () ; if ! (event . time <= start_time || event . time >= end_time) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - scheduling automation event ({0:?}) during SetValueCurveAtTime ({1:?})\" , event , queued)) ; } } ; } } } if event . event_type == AudioParamEventType :: SetValue { self . intrinsic_value = event . value ; } if self . event_timeline . is_empty () && self . last_event . is_none () && (event . event_type == AudioParamEventType :: LinearRampToValueAtTime || event . event_type == AudioParamEventType :: ExponentialRampToValueAtTime) { let set_value_event = AudioParamEvent { event_type : AudioParamEventType :: SetValue , value : self . intrinsic_value , time : 0. , time_constant : None , cancel_time : None , duration : None , values : None , } ; self . event_timeline . push (set_value_event) ; } if self . event_timeline . is_empty () && event . event_type == AudioParamEventType :: SetTargetAtTime { let set_value_event = AudioParamEvent { event_type : AudioParamEventType :: SetValue , value : self . intrinsic_value , time : 0. , time_constant : None , cancel_time : None , duration : None , values : None , } ; self . event_timeline . push (set_value_event) ; } self . event_timeline . push (event) ; self . event_timeline . sort () ; } fn compute_set_value_automation (& mut self , infos : & BlockInfos) -> bool { let event = self . event_timeline . peek () . unwrap () ; let mut time = event . time ; if time == 0. { time = infos . block_time ; } if infos . is_a_rate { let end_index = ((time - infos . block_time) . max (0.) / infos . dt) . round () as usize ; let end_index_clipped = end_index . min (infos . count) ; for _ in self . buffer . len () .. end_index_clipped { self . buffer . push (self . intrinsic_value) ; } } if time > infos . next_block_time { return true ; } self . intrinsic_value = event . value ; # [allow (clippy :: float_cmp)] if time != event . time { let mut event = self . event_timeline . pop () . unwrap () ; event . time = time ; self . last_event = Some (event) ; } else { self . last_event = self . event_timeline . pop () ; } false } fn compute_linear_ramp_automation (& mut self , infos : & BlockInfos) -> bool { let event = self . event_timeline . peek () . unwrap () ; let last_event = self . last_event . as_ref () . unwrap () ; let start_time = last_event . time ; let mut end_time = event . time ; let duration = end_time - start_time ; if let Some (cancel_time) = event . cancel_time { end_time = cancel_time ; } let start_value = last_event . value ; let end_value = event . value ; let diff = end_value - start_value ; if infos . is_a_rate { let start_index = self . buffer . len () ; let end_index = ((end_time - infos . block_time) . max (0.) / infos . dt) . round () as usize ; let end_index_clipped = end_index . min (infos . count) ; if end_index_clipped > start_index { let mut time = (start_index as f64) . mul_add (infos . dt , infos . block_time) ; let mut value = 0. ; for _ in start_index .. end_index_clipped { value = compute_linear_ramp_sample (start_time , duration , start_value , diff , time) ; self . buffer . push (value) ; time += infos . dt ; } self . intrinsic_value = value ; } } if end_time >= infos . next_block_time { let value = compute_linear_ramp_sample (start_time , duration , start_value , diff , infos . next_block_time) ; self . intrinsic_value = value ; return true ; } if event . cancel_time . is_some () { let value = compute_linear_ramp_sample (start_time , duration , start_value , diff , end_time) ; self . intrinsic_value = value ; let mut last_event = self . event_timeline . pop () . unwrap () ; last_event . time = end_time ; last_event . value = value ; self . last_event = Some (last_event) ; } else { self . intrinsic_value = end_value ; self . last_event = self . event_timeline . pop () ; } false } fn compute_exponential_ramp_automation (& mut self , infos : & BlockInfos) -> bool { let event = self . event_timeline . peek () . unwrap () ; let last_event = self . last_event . as_ref () . unwrap () ; let start_time = last_event . time ; let mut end_time = event . time ; let duration = end_time - start_time ; if let Some (cancel_time) = event . cancel_time { end_time = cancel_time ; } let start_value = last_event . value ; let end_value = event . value ; let ratio = end_value / start_value ; if start_value == 0. || start_value * end_value < 0. { let event = AudioParamEvent { event_type : AudioParamEventType :: SetValueAtTime , time : end_time , value : end_value , time_constant : None , cancel_time : None , duration : None , values : None , } ; self . event_timeline . replace_peek (event) ; return false ; } if infos . is_a_rate { let start_index = self . buffer . len () ; let end_index = ((end_time - infos . block_time) . max (0.) / infos . dt) . round () as usize ; let end_index_clipped = end_index . min (infos . count) ; if end_index_clipped > start_index { let mut time = (start_index as f64) . mul_add (infos . dt , infos . block_time) ; let mut value = 0. ; for _ in start_index .. end_index_clipped { value = compute_exponential_ramp_sample (start_time , duration , start_value , ratio , time) ; self . buffer . push (value) ; time += infos . dt ; } self . intrinsic_value = value ; } } if end_time >= infos . next_block_time { let value = compute_exponential_ramp_sample (start_time , duration , start_value , ratio , infos . next_block_time) ; self . intrinsic_value = value ; return true ; } if event . cancel_time . is_some () { let value = compute_exponential_ramp_sample (start_time , duration , start_value , ratio , end_time) ; self . intrinsic_value = value ; let mut last_event = self . event_timeline . pop () . unwrap () ; last_event . time = end_time ; last_event . value = value ; self . last_event = Some (last_event) ; } else { self . intrinsic_value = end_value ; self . last_event = self . event_timeline . pop () ; } false } fn compute_set_target_automation (& mut self , infos : & BlockInfos) -> bool { let event = self . event_timeline . peek () . unwrap () ; let mut end_time = infos . next_block_time ; let mut ended = false ; let some_next_event = self . event_timeline . next () ; if let Some (next_event) = some_next_event { match next_event . event_type { AudioParamEventType :: LinearRampToValueAtTime | AudioParamEventType :: ExponentialRampToValueAtTime => { end_time = infos . block_time ; ended = true ; } _ => { if next_event . time < infos . next_block_time { end_time = next_event . time ; ended = true ; } } } } if let Some (cancel_time) = event . cancel_time { if cancel_time < infos . next_block_time { end_time = cancel_time ; ended = true ; } } let start_time = event . time ; let start_value = self . last_event . as_ref () . unwrap () . value ; let end_value = event . value ; let diff = start_value - end_value ; let time_constant = event . time_constant . unwrap () ; if infos . is_a_rate { let start_index = self . buffer . len () ; let end_index = ((end_time - infos . block_time) . max (0.) / infos . dt) . round () as usize ; let end_index_clipped = end_index . min (infos . count) ; if end_index_clipped > start_index { let mut time = (start_index as f64) . mul_add (infos . dt , infos . block_time) ; let mut value = 0. ; for _ in start_index .. end_index_clipped { value = if time - start_time < 0. { self . intrinsic_value } else { compute_set_target_sample (start_time , time_constant , end_value , diff , time) } ; self . buffer . push (value) ; time += infos . dt ; } self . intrinsic_value = value ; } } if ! ended { let value = compute_set_target_sample (start_time , time_constant , end_value , diff , infos . next_block_time) ; let diff = (end_value - value) . abs () ; if diff < SNAP_TO_TARGET { self . intrinsic_value = end_value ; if end_value == 0. { for v in self . buffer . iter_mut () { if v . is_subnormal () { * v = 0. ; } } } let event = AudioParamEvent { event_type : AudioParamEventType :: SetValueAtTime , time : infos . next_block_time , value : end_value , time_constant : None , cancel_time : None , duration : None , values : None , } ; self . event_timeline . replace_peek (event) ; } else { self . intrinsic_value = value ; } return true ; } let value = compute_set_target_sample (start_time , time_constant , end_value , diff , end_time) ; self . intrinsic_value = value ; let mut event = self . event_timeline . pop () . unwrap () ; event . time = end_time ; event . value = value ; self . last_event = Some (event) ; false } fn compute_set_value_curve_automation (& mut self , infos : & BlockInfos) -> bool { let event = self . event_timeline . peek () . unwrap () ; let start_time = event . time ; let duration = event . duration . unwrap () ; let values = event . values . as_ref () . unwrap () ; let mut end_time = start_time + duration ; if let Some (cancel_time) = event . cancel_time { end_time = cancel_time ; } if infos . is_a_rate { let start_index = self . buffer . len () ; let end_index = ((end_time - infos . block_time) . max (0.) / infos . dt) . round () as usize ; let end_index_clipped = end_index . min (infos . count) ; if end_index_clipped > start_index { let mut time = (start_index as f64) . mul_add (infos . dt , infos . block_time) ; let mut value = 0. ; for _ in start_index .. end_index_clipped { value = if time < start_time { self . intrinsic_value } else { compute_set_value_curve_sample (start_time , duration , values , time) } ; self . buffer . push (value) ; time += infos . dt ; } self . intrinsic_value = value ; } } if end_time >= infos . next_block_time { let value = compute_set_value_curve_sample (start_time , duration , values , infos . next_block_time) ; self . intrinsic_value = value ; return true ; } if event . cancel_time . is_some () { let value = compute_set_value_curve_sample (start_time , duration , values , end_time) ; self . intrinsic_value = value ; let mut last_event = self . event_timeline . pop () . unwrap () ; last_event . time = end_time ; last_event . value = value ; self . last_event = Some (last_event) ; } else { let value = values [values . len () - 1] ; let mut last_event = self . event_timeline . pop () . unwrap () ; last_event . time = end_time ; last_event . value = value ; self . intrinsic_value = value ; self . last_event = Some (last_event) ; } false } fn compute_buffer (& mut self , block_time : f64 , dt : f64 , count : usize) { let clamped = self . intrinsic_value . clamp (self . min_value , self . max_value) ; self . current_value . store (clamped , Ordering :: Release) ; self . buffer . clear () ; let is_a_rate = self . automation_rate . is_a_rate () ; let next_block_time = dt . mul_add (count as f64 , block_time) ; let is_constant_block = match self . event_timeline . peek () { None => true , Some (event) => { if event . event_type != AudioParamEventType :: LinearRampToValueAtTime && event . event_type != AudioParamEventType :: ExponentialRampToValueAtTime { event . time >= next_block_time } else { false } } } ; if ! is_a_rate || is_constant_block { self . buffer . push (self . intrinsic_value) ; if is_constant_block { return ; } } let block_infos = BlockInfos { block_time , dt , count , is_a_rate , next_block_time , } ; loop { let next_event_type = self . event_timeline . peek () . map (| e | e . event_type) ; let exit_loop = match next_event_type { None => { if is_a_rate { for _ in self . buffer . len () .. count { self . buffer . push (self . intrinsic_value) ; } } true } Some (AudioParamEventType :: SetValue) | Some (AudioParamEventType :: SetValueAtTime) => { self . compute_set_value_automation (& block_infos) } Some (AudioParamEventType :: LinearRampToValueAtTime) => { self . compute_linear_ramp_automation (& block_infos) } Some (AudioParamEventType :: ExponentialRampToValueAtTime) => { self . compute_exponential_ramp_automation (& block_infos) } Some (AudioParamEventType :: SetTargetAtTime) => { self . compute_set_target_automation (& block_infos) } Some (AudioParamEventType :: SetValueCurveAtTime) => { self . compute_set_value_curve_automation (& block_infos) } _ => { :: core :: panicking :: panic_fmt (format_args ! (\"AudioParamEvent {0:?} should not appear in AudioParamEventTimeline\" , next_event_type . unwrap ())) ; } } ; if exit_loop { break ; } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: f32 :: consts :: PI ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: BaseAudioContext ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: TABLE_LENGTH_USIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PeriodicWaveOptions { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field3_finish (f , \"PeriodicWaveOptions\" , \"real\" , & self . real , \"imag\" , & self . imag , \"disable_normalization\" , & & self . disable_normalization) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for PeriodicWaveOptions { # [inline] fn default () -> PeriodicWaveOptions { PeriodicWaveOptions { real : :: core :: default :: Default :: default () , imag : :: core :: default :: Default :: default () , disable_normalization : :: core :: default :: Default :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for PeriodicWaveOptions { # [inline] fn clone (& self) -> PeriodicWaveOptions { PeriodicWaveOptions { real : :: core :: clone :: Clone :: clone (& self . real) , imag : :: core :: clone :: Clone :: clone (& self . imag) , disable_normalization : :: core :: clone :: Clone :: clone (& self . disable_normalization) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for PeriodicWave { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"PeriodicWave\" , \"wavetable\" , & & self . wavetable) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for PeriodicWave { # [inline] fn clone (& self) -> PeriodicWave { PeriodicWave { wavetable : :: core :: clone :: Clone :: clone (& self . wavetable) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: default :: Default for PeriodicWave { # [inline] fn default () -> PeriodicWave { PeriodicWave { wavetable : :: core :: default :: Default :: default () } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::periodic_wave",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl PeriodicWave { # [doc = \" Returns a `PeriodicWave`\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" * `real` - The real parameter represents an array of cosine terms of Fourier series.\"] # [doc = \" * `imag` - The imag parameter represents an array of sine terms of Fourier series.\"] # [doc = \" * `constraints` - The constraints parameter specifies the normalization mode of the `PeriodicWave`\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" Will panic if:\"] # [doc = \"\"] # [doc = \" * `real` is defined and its length is less than 2\"] # [doc = \" * `imag` is defined and its length is less than 2\"] # [doc = \" * `real` and `imag` are defined and theirs lengths are not equal\"] # [doc = \" * `PeriodicWave` is more than 8192 components\"] pub fn new < C : BaseAudioContext > (_context : & C , options : PeriodicWaveOptions) -> Self { let PeriodicWaveOptions { real , imag , disable_normalization } = options ; let (real , imag) = match (real , imag) { (Some (r) , Some (i)) => { match (& r . len () , & i . len ()) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"IndexSizeError - `real` and `imag` length should be equal\"))) ; } } } ; if ! (r . len () >= 2) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - `real` and `imag` length should at least 2\")) ; } } ; (r , i) } (Some (r) , None) => { if ! (r . len () >= 2) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - `real` and `imag` length should at least 2\")) ; } } ; let len = r . len () ; (r , :: alloc :: vec :: from_elem (0. , len)) } (None , Some (i)) => { if ! (i . len () >= 2) { { :: core :: panicking :: panic_fmt (format_args ! (\"IndexSizeError - `real` and `imag` length should at least 2\")) ; } } ; let len = i . len () ; (:: alloc :: vec :: from_elem (0. , len) , i) } _ => (< [_] > :: into_vec (# [rustc_box] :: alloc :: boxed :: Box :: new ([0. , 0.])) , < [_] > :: into_vec (# [rustc_box] :: alloc :: boxed :: Box :: new ([0. , 1.]))) , } ; let normalize = ! disable_normalization ; let wavetable = Self :: generate_wavetable (& real , & imag , normalize , TABLE_LENGTH_USIZE) ; Self { wavetable : Arc :: new (wavetable) } } pub (crate) fn as_slice (& self) -> & [f32] { & self . wavetable [..] } fn generate_wavetable (reals : & [f32] , imags : & [f32] , normalize : bool , size : usize) -> Vec < f32 > { let mut wavetable = Vec :: with_capacity (size) ; let pi_2 = 2. * PI ; for i in 0 .. size { let mut sample = 0. ; let phase = pi_2 * i as f32 / size as f32 ; for j in 1 .. reals . len () { let freq = j as f32 ; let real = reals [j] ; let imag = imags [j] ; let rad = phase * freq ; let contrib = real * rad . cos () + imag * rad . sin () ; sample += contrib ; } wavetable . push (sample) ; } if normalize { Self :: normalize (& mut wavetable) ; } wavetable } fn normalize (wavetable : & mut [f32]) { let mut max = 0. ; for sample in wavetable . iter () { let abs = sample . abs () ; if abs > max { max = abs ; } } if max > 0. { let norm_factor = 1. / max ; for sample in wavetable . iter_mut () { * sample *= norm_factor ; } } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) use thread :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub use processor :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) use node_collection :: NodeCollection ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub use quantum :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: cell :: RefCell ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: panic :: { self , AssertUnwindSafe } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: AudioNodeId ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use smallvec :: { smallvec , SmallVec } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { Alloc , AudioParamValues , AudioProcessor , AudioRenderQuantum , NodeCollection , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { ChannelConfigInner , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: AudioWorkletGlobalScope ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for OutgoingEdge { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { let mut format = f . debug_struct (\"OutgoingEdge\") ; format . field (\"self_index\" , & self . self_index) . field (\"other_id\" , & self . other_id) ; if self . other_index == usize :: MAX { format . field (\"other_index\" , & \"HIDDEN\") ; } else { format . field (\"other_index\" , & self . other_index) ; } format . finish () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for Node { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"Node\") . field (\"id\" , & self . reclaim_id . as_deref ()) . field (\"processor\" , & self . processor) . field (\"channel_config\" , & self . channel_config) . field (\"outgoing_edges\" , & self . outgoing_edges) . field (\"control_handle_dropped\" , & self . control_handle_dropped) . field (\"cycle_breaker\" , & self . cycle_breaker) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Node { # [doc = \" Render an audio quantum\"] fn process (& mut self , params : AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { self . processor . process (& self . inputs [..] , & mut self . outputs [..] , params , scope) } # [doc = \" Determine if this node is done playing and can be removed from the audio graph\"] fn can_free (& self , tail_time : bool) -> bool { if ! self . control_handle_dropped { return false ; } if ! self . has_inputs_connected { if ! tail_time { return true ; } if self . outgoing_edges . is_empty () { return true ; } } if ! self . processor . has_side_effects () && self . outgoing_edges . is_empty () { return true ; } false } # [doc = \" Get the current buffer for AudioParam values\"] pub fn get_buffer (& self) -> & AudioRenderQuantum { self . outputs . first () . unwrap () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for Graph { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"Graph\") . field (\"nodes\" , & self . nodes) . field (\"ordered\" , & self . ordered) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::graph",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Graph { pub fn new (reclaim_id_channel : llq :: Producer < AudioNodeId >) -> Self { Graph { nodes : NodeCollection :: new () , alloc : Alloc :: with_capacity (64) , reclaim_id_channel , ordered : :: alloc :: vec :: Vec :: new () , marked : :: alloc :: vec :: Vec :: new () , marked_temp : :: alloc :: vec :: Vec :: new () , in_cycle : :: alloc :: vec :: Vec :: new () , cycle_breakers : :: alloc :: vec :: Vec :: new () , } } # [doc = \" Check if the graph is fully initialized and can start rendering\"] pub fn is_active (& self) -> bool { ! self . nodes . is_empty () } pub fn add_node (& mut self , index : AudioNodeId , reclaim_id : llq :: Node < AudioNodeId > , processor : Box < dyn AudioProcessor > , number_of_inputs : usize , number_of_outputs : usize , channel_config : ChannelConfigInner) { let inputs = :: alloc :: vec :: from_elem (AudioRenderQuantum :: from (self . alloc . silence ()) , number_of_inputs) ; let outputs = :: alloc :: vec :: from_elem (AudioRenderQuantum :: from (self . alloc . silence ()) , number_of_outputs) ; self . nodes . insert (index , RefCell :: new (Node { reclaim_id : Some (reclaim_id) , processor , inputs , outputs , channel_config , outgoing_edges : { let count = 0usize ; # [allow (unused_mut)] let mut vec = :: smallvec :: SmallVec :: new () ; if count <= vec . inline_size () { vec } else { :: smallvec :: SmallVec :: from_vec (:: alloc :: vec :: Vec :: new ()) } } , control_handle_dropped : false , has_inputs_connected : false , cycle_breaker : false , })) ; } pub fn add_edge (& mut self , source : (AudioNodeId , usize) , dest : (AudioNodeId , usize)) { self . nodes . get_unchecked_mut (source . 0) . outgoing_edges . push (OutgoingEdge { self_index : source . 1 , other_id : dest . 0 , other_index : dest . 1 , }) ; self . ordered . clear () ; } pub fn remove_edge (& mut self , source : (AudioNodeId , usize) , dest : (AudioNodeId , usize)) { self . nodes . get_unchecked_mut (source . 0) . outgoing_edges . retain (| edge | { edge . other_id != dest . 0 || edge . self_index != source . 1 || edge . other_index != dest . 1 }) ; self . ordered . clear () ; } pub fn mark_control_handle_dropped (& mut self , index : AudioNodeId) { if let Some (node) = self . nodes . get_mut (index) { node . get_mut () . control_handle_dropped = true ; } } pub fn mark_cycle_breaker (& mut self , index : AudioNodeId) { self . nodes . get_unchecked_mut (index) . cycle_breaker = true ; } pub fn set_channel_count (& mut self , index : AudioNodeId , v : usize) { self . nodes . get_unchecked_mut (index) . channel_config . count = v ; } pub fn set_channel_count_mode (& mut self , index : AudioNodeId , v : ChannelCountMode) { self . nodes . get_unchecked_mut (index) . channel_config . count_mode = v ; } pub fn set_channel_interpretation (& mut self , index : AudioNodeId , v : ChannelInterpretation) { self . nodes . get_unchecked_mut (index) . channel_config . interpretation = v ; } pub fn route_message (& mut self , index : AudioNodeId , msg : & mut dyn Any) { self . nodes . get_unchecked_mut (index) . processor . onmessage (msg) ; } # [doc = \" Helper function for `order_nodes` - traverse node and outgoing edges\"] # [doc = \"\"] # [doc = \" The return value indicates `cycle_breaker_applied`:\"] # [doc = \" - true: a cycle was found and a cycle breaker was applied, current ordering is invalidated\"] # [doc = \" - false: visiting this leg was successful and no topological changes were applied\"] fn visit (& self , node_id : AudioNodeId , marked : & mut Vec < AudioNodeId > , marked_temp : & mut Vec < AudioNodeId > , ordered : & mut Vec < AudioNodeId > , in_cycle : & mut Vec < AudioNodeId > , cycle_breakers : & mut Vec < AudioNodeId >) -> bool { if let Some (pos) = marked_temp . iter () . position (| & m | m == node_id) { let cycle_breaker_node = marked_temp . iter () . skip (pos) . find (| & & node_id | self . nodes . get_unchecked (node_id) . borrow () . cycle_breaker) ; match cycle_breaker_node { Some (& node_id) => { cycle_breakers . push (node_id) ; return true ; } None => { in_cycle . extend_from_slice (& marked_temp [pos ..]) ; return false ; } } } if marked . contains (& node_id) { return false ; } marked . push (node_id) ; marked_temp . push (node_id) ; for edge in self . nodes . get_unchecked (node_id) . borrow () . outgoing_edges . iter () { let cycle_breaker_applied = self . visit (edge . other_id , marked , marked_temp , ordered , in_cycle , cycle_breakers) ; if cycle_breaker_applied { return true ; } } ordered . push (node_id) ; marked_temp . retain (| marked | * marked != node_id) ; false } # [doc = \" Determine the order of the audio nodes for rendering\"] # [doc = \"\"] # [doc = \" By inspecting the audio node connections, we can determine which nodes should render before\"] # [doc = \" other nodes. For example, in a graph with an audio source, a gain node and the destination\"] # [doc = \" node, at every render quantum the source should render first and after that the gain node.\"] # [doc = \"\"] # [doc = \" Inspired by the spec recommendation at\"] # [doc = \" <https://webaudio.github.io/web-audio-api/#rendering-loop>\"] # [doc = \"\"] # [doc = \" The goals are:\"] # [doc = \" - Perform a topological sort of the graph\"] # [doc = \" - Break cycles when possible (if there is a DelayNode present)\"] # [doc = \" - Mute nodes that are still in a cycle\"] # [doc = \" - For performance: no new allocations (reuse Vecs)\"] fn order_nodes (& mut self) { let mut ordered = std :: mem :: take (& mut self . ordered) ; let mut marked = std :: mem :: take (& mut self . marked) ; let mut marked_temp = std :: mem :: take (& mut self . marked_temp) ; let mut in_cycle = std :: mem :: take (& mut self . in_cycle) ; let mut cycle_breakers = std :: mem :: take (& mut self . cycle_breakers) ; loop { ordered . clear () ; marked . clear () ; marked_temp . clear () ; in_cycle . clear () ; cycle_breakers . clear () ; let mut cycle_breaker_applied = false ; for node_id in self . nodes . keys () { cycle_breaker_applied = self . visit (node_id , & mut marked , & mut marked_temp , & mut ordered , & mut in_cycle , & mut cycle_breakers) ; if cycle_breaker_applied { break ; } } if cycle_breaker_applied { cycle_breakers . iter () . for_each (| node_id | { self . nodes . get_unchecked_mut (* node_id) . outgoing_edges . clear () ; }) ; continue ; } break ; } ordered . retain (| o | ! in_cycle . contains (o)) ; ordered . reverse () ; self . ordered = ordered ; self . marked = marked ; self . marked_temp = marked_temp ; self . in_cycle = in_cycle ; self . cycle_breakers = cycle_breakers ; } # [doc = \" Render a single audio quantum by traversing the node list\"] pub fn render (& mut self , scope : & AudioWorkletGlobalScope) -> & AudioRenderQuantum { if self . ordered . is_empty () { self . order_nodes () ; } let mut nodes_dropped = false ; self . ordered . iter () . for_each (| index | { let mut node = self . nodes . get_unchecked (* index) . borrow_mut () ; let params = AudioParamValues :: from (& self . nodes) ; scope . node_id . set (* index) ; let (success , tail_time) = { let catch_me = AssertUnwindSafe (| | node . process (params , scope)) ; match panic :: catch_unwind (catch_me) { Ok (tail_time) => (true , tail_time) , Err (e) => { node . outgoing_edges . clear () ; scope . report_error (e) ; (false , false) } } } ; node . outgoing_edges . iter () . filter (| edge | edge . other_index != usize :: MAX) . for_each (| edge | { let mut output_node = self . nodes . get_unchecked (edge . other_id) . borrow_mut () ; output_node . has_inputs_connected = true ; let signal = & node . outputs [edge . self_index] ; let channel_config = & output_node . channel_config . clone () ; output_node . inputs [edge . other_index] . add (signal , channel_config) ; }) ; let can_free = ! success || node . can_free (tail_time) ; if ! can_free { node . inputs . iter_mut () . for_each (AudioRenderQuantum :: make_silent) ; node . has_inputs_connected = false ; } drop (node) ; if can_free { let mut node = self . nodes . remove (* index) . into_inner () ; self . reclaim_id_channel . push (node . reclaim_id . take () . unwrap ()) ; node . processor . before_drop (scope) ; drop (node) ; nodes_dropped = true ; self . nodes . values_mut () . for_each (| node | { node . get_mut () . outgoing_edges . retain (| e | e . other_id != * index) ; }) ; } }) ; if nodes_dropped { let mut i = 0 ; while i < self . ordered . len () { if ! self . nodes . contains (self . ordered [i]) { self . ordered . remove (i) ; } else { i += 1 ; } } } & self . nodes . get_unchecked_mut (AudioNodeId (0)) . outputs [0] } pub fn before_drop (& mut self , scope : & AudioWorkletGlobalScope) { self . nodes . iter_mut () . for_each (| (id , node) | { scope . node_id . set (id) ; node . get_mut () . processor . before_drop (scope) ; }) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: cell :: Cell ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: ops :: ControlFlow ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: { AtomicU64 , AtomicU8 , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: time :: { Duration , Instant } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { Receiver , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use dasp_sample :: FromSample ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use futures_channel :: { mpsc , oneshot } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use futures_util :: StreamExt as _ ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: AudioRenderQuantum ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextState , AudioNodeId , OfflineAudioContext , OfflineAudioContextCallback , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { EventDispatch , EventLoop } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: message :: ControlMessage ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: ChannelInterpretation ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: AudioWorkletGlobalScope ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AudioRenderCapacityLoad , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: graph :: Graph ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [allow (clippy :: non_send_fields_in_send_ty)] unsafe impl Send for Graph { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "unsafe impl Sync for Graph { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "unsafe impl Send for RenderThread { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "unsafe impl Sync for RenderThread { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for RenderThread { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"RenderThread\") . field (\"sample_rate\" , & self . sample_rate) . field (\"buffer_size\" , & self . buffer_size) . field (\"frames_played\" , & self . frames_played . load (Ordering :: Relaxed)) . field (\"number_of_channels\" , & self . number_of_channels) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl RenderThread { pub fn new (sample_rate : f32 , number_of_channels : usize , receiver : Receiver < ControlMessage > , state : Arc < AtomicU8 > , frames_played : Arc < AtomicU64 > , event_sender : Sender < EventDispatch >) -> Self { Self { graph : None , sample_rate , buffer_size : 0 , number_of_channels , suspended : false , state , frames_played , receiver : Some (receiver) , buffer_offset : None , load_value_sender : None , event_sender , garbage_collector : None , } } pub (crate) fn set_load_value_sender (& mut self , load_value_sender : Sender < AudioRenderCapacityLoad >) { self . load_value_sender = Some (load_value_sender) ; } pub (crate) fn spawn_garbage_collector_thread (& mut self) { if self . garbage_collector . is_none () { let (gc_producer , gc_consumer) = llq :: Queue :: new () . split () ; spawn_garbage_collector_thread (gc_consumer) ; self . garbage_collector = Some (gc_producer) ; } } # [inline (always)] fn handle_control_messages (& mut self) { if self . receiver . is_none () { return ; } while let Ok (msg) = self . receiver . as_ref () . unwrap () . try_recv () { let result = self . handle_control_message (msg) ; if result . is_break () { return ; } } } fn handle_control_message (& mut self , msg : ControlMessage) -> ControlFlow < () > { use ControlMessage :: * ; match msg { RegisterNode { id : node_id , reclaim_id , node , inputs , outputs , channel_config } => { self . graph . as_mut () . unwrap () . add_node (node_id , reclaim_id , node , inputs , outputs , channel_config) ; } ConnectNode { from , to , output , input } => { self . graph . as_mut () . unwrap () . add_edge ((from , output) , (to , input)) ; } DisconnectNode { from , output , to , input } => { self . graph . as_mut () . unwrap () . remove_edge ((from , output) , (to , input)) ; } ControlHandleDropped { id } => { self . graph . as_mut () . unwrap () . mark_control_handle_dropped (id) ; } MarkCycleBreaker { id } => { self . graph . as_mut () . unwrap () . mark_cycle_breaker (id) ; } CloseAndRecycle { sender } => { self . set_state (AudioContextState :: Suspended) ; let _ = sender . send (self . graph . take () . unwrap ()) ; self . receiver = None ; return ControlFlow :: Break (()) ; } Startup { graph } => { if true { if ! self . graph . is_none () { :: core :: panicking :: panic (\"assertion failed: self.graph.is_none()\") } ; } ; self . graph = Some (graph) ; self . set_state (AudioContextState :: Running) ; } NodeMessage { id , mut msg } => { self . graph . as_mut () . unwrap () . route_message (id , msg . as_mut ()) ; if let Some (gc) = self . garbage_collector . as_mut () { gc . push (msg) } } RunDiagnostics { mut buffer } => { use std :: io :: Write ; (& mut buffer) . write_fmt (format_args ! (\"{0:#?}\\n\" , & self)) . ok () ; (& mut buffer) . write_fmt (format_args ! (\"{0:?}\\n\" , & self . graph)) . ok () ; self . event_sender . try_send (EventDispatch :: diagnostics (buffer)) . expect (\"Unable to send diagnostics - channel is full\") ; } Suspend { notify } => { self . suspended = true ; self . set_state (AudioContextState :: Suspended) ; notify . send () ; } Resume { notify } => { self . suspended = false ; self . set_state (AudioContextState :: Running) ; notify . send () ; } Close { notify } => { self . suspended = true ; self . set_state (AudioContextState :: Closed) ; notify . send () ; } SetChannelCount { id , count } => { self . graph . as_mut () . unwrap () . set_channel_count (id , count) ; } SetChannelCountMode { id , mode } => { self . graph . as_mut () . unwrap () . set_channel_count_mode (id , mode) ; } SetChannelInterpretation { id , interpretation } => { self . graph . as_mut () . unwrap () . set_channel_interpretation (id , interpretation) ; } } ControlFlow :: Continue (()) } pub fn render_audiobuffer_sync (mut self , context : & mut OfflineAudioContext , mut suspend_callbacks : Vec < (usize , Box < OfflineAudioContextCallback >) > , event_loop : & EventLoop) -> AudioBuffer { let length = context . length () ; let sample_rate = self . sample_rate ; let mut buffer = Vec :: with_capacity (self . number_of_channels) ; buffer . resize_with (buffer . capacity () , | | Vec :: with_capacity (length)) ; let num_frames = (length + RENDER_QUANTUM_SIZE - 1) / RENDER_QUANTUM_SIZE ; self . handle_control_messages () ; for quantum in 0 .. num_frames { if suspend_callbacks . first () . map (| & (q , _) | q) == Some (quantum) { let callback = suspend_callbacks . remove (0) . 1 ; (callback) (context) ; self . handle_control_messages () ; } self . render_offline_quantum (& mut buffer) ; let events_were_handled = event_loop . handle_pending_events () ; if events_were_handled { self . handle_control_messages () ; } } self . unload_graph () ; event_loop . handle_pending_events () ; AudioBuffer :: from (buffer , sample_rate) } pub async fn render_audiobuffer (mut self , length : usize , mut suspend_callbacks : Vec < (usize , oneshot :: Sender < () >) > , mut resume_receiver : mpsc :: Receiver < () > , event_loop : & EventLoop) -> AudioBuffer { let sample_rate = self . sample_rate ; let mut buffer = Vec :: with_capacity (self . number_of_channels) ; buffer . resize_with (buffer . capacity () , | | Vec :: with_capacity (length)) ; let num_frames = (length + RENDER_QUANTUM_SIZE - 1) / RENDER_QUANTUM_SIZE ; self . handle_control_messages () ; for quantum in 0 .. num_frames { if suspend_callbacks . first () . map (| & (q , _) | q) == Some (quantum) { let sender = suspend_callbacks . remove (0) . 1 ; sender . send (()) . unwrap () ; resume_receiver . next () . await ; self . handle_control_messages () ; } self . render_offline_quantum (& mut buffer) ; let events_were_handled = event_loop . handle_pending_events () ; if events_were_handled { self . handle_control_messages () ; } } self . unload_graph () ; event_loop . handle_pending_events () ; AudioBuffer :: from (buffer , sample_rate) } # [doc = \" Render a single quantum into an AudioBuffer\"] fn render_offline_quantum (& mut self , buffer : & mut [Vec < f32 >]) { let current_frame = self . frames_played . fetch_add (RENDER_QUANTUM_SIZE as u64 , Ordering :: Relaxed) ; let current_time = current_frame as f64 / self . sample_rate as f64 ; let scope = AudioWorkletGlobalScope { current_frame , current_time , sample_rate : self . sample_rate , event_sender : self . event_sender . clone () , node_id : Cell :: new (AudioNodeId (0)) , } ; let graph = self . graph . as_mut () . unwrap () ; # [cfg (any (target_arch = \"x86\" , target_arch = \"x86_64\" , target_arch = \"aarch64\"))] let rendered = no_denormals :: no_denormals (| | graph . render (& scope)) ; let remaining = (buffer [0] . capacity () - buffer [0] . len ()) . min (RENDER_QUANTUM_SIZE) ; let channels = rendered . channels () ; buffer . iter_mut () . enumerate () . for_each (| (i , b) | { let c = channels . get (i) . map (AsRef :: as_ref) . unwrap_or (& [0. ; RENDER_QUANTUM_SIZE]) ; b . extend_from_slice (& c [.. remaining]) ; }) ; } # [doc = \" Run destructors of all alive nodes in the audio graph\"] fn unload_graph (mut self) { let current_frame = self . frames_played . load (Ordering :: Relaxed) ; let current_time = current_frame as f64 / self . sample_rate as f64 ; let scope = AudioWorkletGlobalScope { current_frame , current_time , sample_rate : self . sample_rate , event_sender : self . event_sender . clone () , node_id : Cell :: new (AudioNodeId (0)) , } ; self . graph . take () . unwrap () . before_drop (& scope) ; } pub fn render < S : FromSample < f32 > + Clone > (& mut self , output_buffer : & mut [S]) { let render_start = Instant :: now () ; # [cfg (any (target_arch = \"x86\" , target_arch = \"x86_64\" , target_arch = \"aarch64\"))] no_denormals :: no_denormals (| | self . render_inner (output_buffer)) ; if let Some (load_value_sender) = & self . load_value_sender { let duration = render_start . elapsed () . as_micros () as f64 / 1E6 ; let max_duration = RENDER_QUANTUM_SIZE as f64 / self . sample_rate as f64 ; let load_value = duration / max_duration ; let render_timestamp = self . frames_played . load (Ordering :: Relaxed) as f64 / self . sample_rate as f64 ; let load_value_data = AudioRenderCapacityLoad { render_timestamp , load_value } ; let _ = load_value_sender . try_send (load_value_data) ; } } fn render_inner < S : FromSample < f32 > + Clone > (& mut self , mut output_buffer : & mut [S]) { self . buffer_size = output_buffer . len () ; if let Some ((offset , prev_rendered)) = self . buffer_offset . take () { let leftover_len = (RENDER_QUANTUM_SIZE - offset) * self . number_of_channels ; let (first , next) = output_buffer . split_at_mut (leftover_len . min (output_buffer . len ())) ; for i in 0 .. self . number_of_channels { let output = first . iter_mut () . skip (i) . step_by (self . number_of_channels) ; let channel = prev_rendered . channel_data (i) [offset ..] . iter () ; for (sample , input) in output . zip (channel) { let value = S :: from_sample_ (* input) ; * sample = value ; } } if next . is_empty () { self . buffer_offset = Some ((offset + first . len () / self . number_of_channels , prev_rendered)) ; return ; } output_buffer = next ; } self . handle_control_messages () ; if self . suspended || ! self . graph . as_ref () . is_some_and (Graph :: is_active) { output_buffer . fill (S :: from_sample_ (0.)) ; return ; } let chunk_size = RENDER_QUANTUM_SIZE * self . number_of_channels ; for data in output_buffer . chunks_mut (chunk_size) { let current_frame = self . frames_played . fetch_add (RENDER_QUANTUM_SIZE as u64 , Ordering :: Relaxed) ; let current_time = current_frame as f64 / self . sample_rate as f64 ; let scope = AudioWorkletGlobalScope { current_frame , current_time , sample_rate : self . sample_rate , event_sender : self . event_sender . clone () , node_id : Cell :: new (AudioNodeId (0)) , } ; let mut destination_buffer = self . graph . as_mut () . unwrap () . render (& scope) . clone () ; if destination_buffer . number_of_channels () < self . number_of_channels { destination_buffer . mix (self . number_of_channels , ChannelInterpretation :: Discrete) ; } for i in 0 .. self . number_of_channels { let output = data . iter_mut () . skip (i) . step_by (self . number_of_channels) ; let channel = destination_buffer . channel_data (i) . iter () ; for (sample , input) in output . zip (channel) { let value = S :: from_sample_ (* input) ; * sample = value ; } } if data . len () != chunk_size { let channel_offset = data . len () / self . number_of_channels ; if true { if ! (channel_offset < RENDER_QUANTUM_SIZE) { :: core :: panicking :: panic (\"assertion failed: channel_offset < RENDER_QUANTUM_SIZE\") } ; } ; self . buffer_offset = Some ((channel_offset , destination_buffer)) ; } self . handle_control_messages () ; } } fn set_state (& self , state : AudioContextState) { self . state . store (state as u8 , Ordering :: Relaxed) ; self . event_sender . try_send (EventDispatch :: state_change (state)) . ok () ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Drop for RenderThread { fn drop (& mut self) { if let Some (gc) = self . garbage_collector . as_mut () { gc . push (llq :: Node :: new (Box :: new (TerminateGarbageCollectorThread))) } { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Audio render thread has been dropped\") , lvl , & (\"web_audio_api::render::thread\" , \"web_audio_api::render::thread\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/render/thread.rs\") , 521u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "const GARBAGE_COLLECTOR_THREAD_TIMEOUT : Duration = Duration :: from_millis (100) ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::thread",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for TerminateGarbageCollectorThread { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: write_str (f , \"TerminateGarbageCollectorThread\") } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioNodeId , AudioParamId } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: { AudioProcessingEvent , ErrorEvent , EventDispatch } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AudioBuffer , Event , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { graph :: Node , AudioRenderQuantum , NodeCollection } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: Sender ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: cell :: Cell ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: ops :: Deref ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for AudioWorkletGlobalScope { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { let mut format = f . debug_struct (\"RenderScope\") ; format . field (\"current_frame\" , & self . current_frame) . field (\"current_time\" , & self . current_time) . field (\"sample_rate\" , & self . sample_rate) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioWorkletGlobalScope { # [doc = \" Send a message to the corresponding AudioWorkletNode of this processor\"] # [doc = \"\"] # [doc = \" This method is just a shim of the full\"] # [doc = \" [`MessagePort`](https://webaudio.github.io/web-audio-api/#dom-audioworkletprocessor-port)\"] # [doc = \" `postMessage` functionality of the AudioWorkletProcessor.\"] pub fn post_message (& self , msg : Box < dyn Any + Send + 'static >) { let _ = self . event_sender . try_send (EventDispatch :: message (self . node_id . get () , msg)) ; } pub (crate) fn send_ended_event (& self) { let _ = self . event_sender . try_send (EventDispatch :: ended (self . node_id . get ())) ; } pub (crate) fn send_audio_processing_event (& self , input_buffer : AudioBuffer , output_buffer : AudioBuffer , playback_time : f64) { let event = AudioProcessingEvent { input_buffer , output_buffer , playback_time , registration : None , } ; let dispatch = EventDispatch :: audio_processing (self . node_id . get () , event) ; let _ = self . event_sender . try_send (dispatch) ; } pub (crate) fn report_error (& self , error : Box < dyn Any + Send >) { pub fn type_name_of_val < T : ? Sized > (_val : & T) -> & 'static str { std :: any :: type_name :: < T > () } let message = if let Some (v) = error . downcast_ref :: < String > () { v . to_string () } else if let Some (v) = error . downcast_ref :: < & str > () { v . to_string () } else { type_name_of_val (& error) . to_string () } ; { :: std :: io :: _eprint (format_args ! (\"Panic occurred in Audio Processor: \\'{0}\\'. Removing node from graph.\\n\" , & message)) ; } ; let event = ErrorEvent { message , error , event : Event { type_ : \"ErrorEvent\" } , } ; let _ = self . event_sender . try_send (EventDispatch :: processor_error (self . node_id . get () , event)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for dyn AudioProcessor { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (self . name ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Deref for DerefAudioRenderQuantumChannel < '_ > { type Target = [f32] ; fn deref (& self) -> & Self :: Target { let buffer = self . 0 . get_buffer () ; let len = if buffer . single_valued () { 1 } else { RENDER_QUANTUM_SIZE } ; & buffer . channel_data (0) [.. len] } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < 'a > std :: fmt :: Debug for AudioParamValues < 'a > { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"AudioParamValues\") . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::processor",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < 'a > AudioParamValues < 'a > { pub (crate) fn from (nodes : & 'a NodeCollection) -> Self { Self { nodes } } # [doc = \" Get the computed values for the given [`crate::param::AudioParam`]\"] # [doc = \"\"] # [doc = \" For k-rate params or if the (a-rate) parameter is constant for this block, it will provide\"] # [doc = \" a slice of length 1. In other cases, i.e. a-rate param with scheduled automations it will\"] # [doc = \" provide a slice of length equal to the render quantum size (default: 128)\"] # [allow (clippy :: missing_panics_doc)] pub fn get (& self , index : & AudioParamId) -> impl Deref < Target = [f32] > + '_ { DerefAudioRenderQuantumChannel (self . nodes . get_unchecked (index . into ()) . borrow ()) } pub (crate) fn listener_params (& self) -> [impl Deref < Target = [f32] > + '_ ; 9] { crate :: context :: LISTENER_AUDIO_PARAM_IDS . map (| p | self . get (& p)) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use arrayvec :: ArrayVec ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: cell :: RefCell ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: rc :: Rc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { ChannelConfigInner , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: assert_valid_number_of_channels ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { MAX_CHANNELS , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AllocInner { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AllocInner\" , \"pool\" , & self . pool , \"zeroes\" , & & self . zeroes) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Alloc { pub fn with_capacity (n : usize) -> Self { let pool : Vec < _ > = (0 .. n) . map (| _ | Rc :: new ([0. ; RENDER_QUANTUM_SIZE])) . collect () ; let zeroes = Rc :: new ([0. ; RENDER_QUANTUM_SIZE]) ; let inner = AllocInner { pool : RefCell :: new (pool) , zeroes } ; Self { inner : Rc :: new (inner) } } pub fn silence (& self) -> AudioRenderQuantumChannel { AudioRenderQuantumChannel { data : Rc :: clone (& self . inner . zeroes) , alloc : Rc :: clone (& self . inner) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AllocInner { fn allocate (& self) -> Rc < [f32 ; RENDER_QUANTUM_SIZE] > { if let Some (rc) = self . pool . borrow_mut () . pop () { rc } else { Rc :: new ([0. ; RENDER_QUANTUM_SIZE]) } } fn push (& self , data : Rc < [f32 ; RENDER_QUANTUM_SIZE] >) { self . pool . borrow_mut () . push (data) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioRenderQuantumChannel { # [inline] fn clone (& self) -> AudioRenderQuantumChannel { AudioRenderQuantumChannel { data : :: core :: clone :: Clone :: clone (& self . data) , alloc : :: core :: clone :: Clone :: clone (& self . alloc) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioRenderQuantumChannel { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AudioRenderQuantumChannel\" , \"data\" , & self . data , \"alloc\" , & & self . alloc) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioRenderQuantumChannel { fn make_mut (& mut self) -> & mut [f32 ; RENDER_QUANTUM_SIZE] { if Rc :: strong_count (& self . data) != 1 { let mut new = self . alloc . allocate () ; Rc :: make_mut (& mut new) . copy_from_slice (self . data . deref ()) ; self . data = new ; } Rc :: make_mut (& mut self . data) } # [doc = \" `O(1)` check if this buffer is equal to the 'silence buffer'\"] # [doc = \"\"] # [doc = \" If this function returns false, it is still possible for all samples to be zero.\"] pub (crate) fn is_silent (& self) -> bool { Rc :: ptr_eq (& self . data , & self . alloc . zeroes) } # [doc = \" Sum two channels\"] pub (crate) fn add (& mut self , other : & Self) { if self . is_silent () { * self = other . clone () ; } else if ! other . is_silent () { self . iter_mut () . zip (other . iter ()) . for_each (| (a , b) | * a += b) } } pub (crate) fn silence (& self) -> Self { Self { data : Rc :: clone (& self . alloc . zeroes) , alloc : Rc :: clone (& self . alloc) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: ops :: { Deref , DerefMut } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Deref for AudioRenderQuantumChannel { type Target = [f32] ; fn deref (& self) -> & Self :: Target { self . data . as_slice () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl DerefMut for AudioRenderQuantumChannel { fn deref_mut (& mut self) -> & mut Self :: Target { self . make_mut () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AsRef < [f32] > for AudioRenderQuantumChannel { fn as_ref (& self) -> & [f32] { & self . data [..] } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: ops :: Drop for AudioRenderQuantumChannel { fn drop (& mut self) { if Rc :: strong_count (& self . data) == 1 { let zeroes = Rc :: clone (& self . alloc . zeroes) ; let rc = std :: mem :: replace (& mut self . data , zeroes) ; self . alloc . push (rc) ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AudioRenderQuantum { # [inline] fn clone (& self) -> AudioRenderQuantum { AudioRenderQuantum { channels : :: core :: clone :: Clone :: clone (& self . channels) , single_valued : :: core :: clone :: Clone :: clone (& self . single_valued) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioRenderQuantum { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field2_finish (f , \"AudioRenderQuantum\" , \"channels\" , & self . channels , \"single_valued\" , & & self . single_valued) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::quantum",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioRenderQuantum { # [doc = \" Create a new `AudioRenderQuantum` from a single channel buffer\"] pub (crate) fn from (channel : AudioRenderQuantumChannel) -> Self { let mut channels = ArrayVec :: new () ; channels . push (channel) ; Self { channels , single_valued : false } } pub (crate) fn single_valued (& self) -> bool { self . single_valued } pub (crate) fn set_single_valued (& mut self , value : bool) { self . single_valued = value ; } # [doc = \" Number of channels in this AudioRenderQuantum\"] pub fn number_of_channels (& self) -> usize { self . channels . len () } # [doc = \" Set number of channels in this AudioRenderQuantum\"] # [doc = \"\"] # [doc = \" Note: if the new number is higher than the previous, the new channels will be filled with\"] # [doc = \" garbage.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if the given number of channels is outside the [1, 32] range, 32\"] # [doc = \" being defined by the MAX_CHANNELS constant.\"] pub fn set_number_of_channels (& mut self , n : usize) { assert_valid_number_of_channels (n) ; for _ in self . number_of_channels () .. n { self . channels . push (self . channels [0] . clone ()) ; } self . channels . truncate (n) ; } # [doc = \" Get the samples from this specific channel.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \" Panics if the index is greater than the available number of channels\"] pub fn channel_data (& self , index : usize) -> & AudioRenderQuantumChannel { & self . channels [index] } # [doc = \" Get the samples (mutable) from this specific channel.\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \" Panics if the index is greater than the available number of channels\"] pub fn channel_data_mut (& mut self , index : usize) -> & mut AudioRenderQuantumChannel { & mut self . channels [index] } # [doc = \" Channel data as slice\"] pub fn channels (& self) -> & [AudioRenderQuantumChannel] { & self . channels [..] } # [doc = \" Channel data as slice (mutable)\"] pub fn channels_mut (& mut self) -> & mut [AudioRenderQuantumChannel] { & mut self . channels [..] } # [doc = \" `O(1)` check if this buffer is equal to the 'silence buffer'\"] # [doc = \"\"] # [doc = \" If this function returns false, it is still possible for all samples to be zero.\"] pub fn is_silent (& self) -> bool { ! self . channels . iter () . any (| channel | ! channel . is_silent ()) } pub (crate) fn stereo_mut (& mut self) -> [& mut AudioRenderQuantumChannel ; 2] { match (& self . number_of_channels () , & 2) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; let (ls , rs) = self . channels_mut () . split_at_mut (1) ; [& mut ls [0] , & mut rs [0]] } # [doc = \" Up/Down-mix to the desired number of channels\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function will panic if the given number of channels is outside the [1, 32] range, 32\"] # [doc = \" being defined by the MAX_CHANNELS constant.\"] # [inline (always)] pub (crate) fn mix (& mut self , computed_number_of_channels : usize , interpretation : ChannelInterpretation) { if self . number_of_channels () == computed_number_of_channels { return ; } self . mix_inner (computed_number_of_channels , interpretation) } fn mix_inner (& mut self , computed_number_of_channels : usize , interpretation : ChannelInterpretation) { assert_valid_number_of_channels (computed_number_of_channels) ; let silence = self . channels [0] . silence () ; if interpretation == ChannelInterpretation :: Discrete || self . number_of_channels () > 6 || computed_number_of_channels > 6 { for _ in self . number_of_channels () .. computed_number_of_channels { self . channels . push (silence . clone ()) ; } self . channels . truncate (computed_number_of_channels) ; } else { match (self . number_of_channels () , computed_number_of_channels) { (1 , 2) => { self . channels . push (self . channels [0] . clone ()) ; } (1 , 3) => { self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (1 , 4) => { self . channels . push (self . channels [0] . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (1 , 5) => { self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (1 , 6) => { let main = std :: mem :: replace (& mut self . channels [0] , silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (main) ; self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (2 , 3) => { let left = std :: mem :: replace (& mut self . channels [0] , silence) ; let right = std :: mem :: replace (& mut self . channels [1] , left) ; self . channels . push (right) ; } (2 , 4) => { self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (2 , 5) => { self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (2 , 6) => { self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (3 , 4) => { self . channels . push (silence) ; } (3 , 5) => { self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (3 , 6) => { self . channels . push (silence . clone ()) ; self . channels . push (silence . clone ()) ; self . channels . push (silence) ; } (4 , 5) => { let sl = std :: mem :: replace (& mut self . channels [2] , silence . clone ()) ; let sr = std :: mem :: replace (& mut self . channels [3] , sl) ; self . channels . push (sr) ; } (4 , 6) => { let sl = std :: mem :: replace (& mut self . channels [2] , silence . clone ()) ; let sr = std :: mem :: replace (& mut self . channels [3] , silence) ; self . channels . push (sl) ; self . channels . push (sr) ; } (5 , 6) => { self . channels . push (silence) ; } (2 , 1) => { let right = self . channels [1] . clone () ; self . channels [0] . iter_mut () . zip (right . iter ()) . for_each (| (l , r) | * l = 0.5 * (* l + * r)) ; self . channels . truncate (1) ; } (3 , 1) => { self . channels . truncate (1) ; } (4 , 1) => { let right = self . channels [1] . clone () ; let s_left = self . channels [2] . clone () ; let s_right = self . channels [3] . clone () ; self . channels [0] . iter_mut () . zip (right . iter ()) . zip (s_left . iter ()) . zip (s_right . iter ()) . for_each (| (((l , r) , sl) , sr) | * l = 0.25 * (* l + * r + * sl + * sr)) ; self . channels . truncate (1) ; } (5 , 1) => { let c = std :: mem :: replace (& mut self . channels [2] , silence) ; self . channels [0] = c ; self . channels . truncate (1) ; } (6 , 1) => { let right = self . channels [1] . clone () ; let center = self . channels [2] . clone () ; let s_left = self . channels [4] . clone () ; let s_right = self . channels [5] . clone () ; let sqrt05 = (0.5_f32) . sqrt () ; self . channels [0] . iter_mut () . zip (right . iter ()) . zip (center . iter ()) . zip (s_left . iter ()) . zip (s_right . iter ()) . for_each (| ((((l , r) , c) , sl) , sr) | { * l = sqrt05 . mul_add (* l + * r , 0.5f32 . mul_add (* sl + * sr , * c)) }) ; self . channels . truncate (1) ; } (3 , 2) => { self . channels . truncate (2) ; } (4 , 2) => { let s_left = self . channels [2] . clone () ; let s_right = self . channels [3] . clone () ; self . channels [0] . iter_mut () . zip (s_left . iter ()) . for_each (| (l , sl) | * l = 0.5 * (* l + * sl)) ; self . channels [1] . iter_mut () . zip (s_right . iter ()) . for_each (| (r , sr) | * r = 0.5 * (* r + * sr)) ; self . channels . truncate (2) ; } (5 , 2) => { self . channels . truncate (2) ; } (6 , 2) => { let center = self . channels [2] . clone () ; let s_left = self . channels [4] . clone () ; let s_right = self . channels [5] . clone () ; let sqrt05 = (0.5_f32) . sqrt () ; self . channels [0] . iter_mut () . zip (center . iter ()) . zip (s_left . iter ()) . for_each (| ((l , c) , sl) | * l += sqrt05 * (* c + * sl)) ; self . channels [1] . iter_mut () . zip (center . iter ()) . zip (s_right . iter ()) . for_each (| ((r , c) , sr) | * r += sqrt05 * (* c + * sr)) ; self . channels . truncate (2) } (4 , 3) => { self . channels . truncate (3) ; } (5 , 3) => { self . channels . truncate (3) ; } (6 , 3) => { self . channels . truncate (3) ; } (5 , 4) => { self . channels . truncate (4) ; } (6 , 4) => { let _low_f = self . channels . swap_remove (3) ; let center = self . channels . swap_remove (2) ; let sqrt05 = (0.5_f32) . sqrt () ; self . channels [0] . iter_mut () . zip (center . iter ()) . for_each (| (l , c) | * l += sqrt05 * c) ; self . channels [1] . iter_mut () . zip (center . iter ()) . for_each (| (r , c) | * r += sqrt05 * c) ; } (6 , 5) => { self . channels . truncate (5) ; } _ => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } if true { match (& self . number_of_channels () , & computed_number_of_channels) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: None) ; } } } ; } ; } # [doc = \" Convert this buffer to silence\"] # [doc = \"\"] # [doc = \" `O(1)` operation to convert this buffer to the 'silence buffer' which will enable some\"] # [doc = \" optimizations in the graph rendering.\"] pub fn make_silent (& mut self) { let silence = self . channels [0] . silence () ; self . channels [0] = silence ; self . channels . truncate (1) ; } # [doc = \" Convert to a single channel buffer, dropping excess channels\"] pub (crate) fn force_mono (& mut self) { self . channels . truncate (1) ; } # [doc = \" Modify every channel in the same way\"] pub (crate) fn modify_channels < F : Fn (& mut AudioRenderQuantumChannel) > (& mut self , fun : F) { self . channels . iter_mut () . for_each (fun) } # [doc = \" Sum two `AudioRenderQuantum`s\"] # [doc = \"\"] # [doc = \" Both buffers will be mixed up front according to the supplied `channel_config`\"] pub (crate) fn add (& mut self , other : & Self , channel_config : & ChannelConfigInner) { let channels_self = self . number_of_channels () ; let channels_other = other . number_of_channels () ; let max_channels = channels_self . max (channels_other) ; let interpretation = channel_config . interpretation ; let mode = channel_config . count_mode ; let count = channel_config . count ; let new_channels = match mode { ChannelCountMode :: Max => max_channels , ChannelCountMode :: Explicit => count , ChannelCountMode :: ClampedMax => max_channels . min (count) , } ; if interpretation == ChannelInterpretation :: Speakers && self . all_channels_identical () && other . all_channels_identical () { self . channels . truncate (1) ; self . channels [0] . add (& other . channels [0]) ; self . mix (new_channels , interpretation) ; return ; } self . mix (new_channels , interpretation) ; let mut other_mixed = other . clone () ; other_mixed . mix (new_channels , interpretation) ; self . channels . iter_mut () . zip (other_mixed . channels . iter ()) . for_each (| (s , o) | s . add (o)) ; } # [doc = \" Determine if all channels are identical (by pointer)\"] # [doc = \"\"] # [doc = \" This is often the case for upmixed buffers. When all channels are identical, modifications\"] # [doc = \" only need to be applied once.\"] fn all_channels_identical (& self) -> bool { let mut channels = self . channels . iter () ; let first = channels . next () . unwrap () ; for c in channels { if ! Rc :: ptr_eq (& first . data , & c . data) { return false ; } } true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::node_collection",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioNodeId , DESTINATION_NODE_ID } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::node_collection",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: graph :: Node ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::node_collection",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: cell :: RefCell ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::node_collection",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for NodeCollection { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field1_finish (f , \"NodeCollection\" , \"nodes\" , & & self . nodes) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::render::node_collection",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl NodeCollection { pub fn new () -> Self { let mut instance = Self { nodes : Vec :: with_capacity (64) } ; instance . ensure_capacity (64) ; instance } # [inline (always)] pub fn is_empty (& self) -> bool { let destination_id = DESTINATION_NODE_ID . 0 as usize ; self . nodes [destination_id] . is_none () } # [inline (always)] fn ensure_capacity (& mut self , new_len : usize) { self . nodes . resize_with (new_len . max (self . nodes . len ()) , | | None) ; } # [inline (always)] pub fn insert (& mut self , index : AudioNodeId , value : RefCell < Node >) { let index = index . 0 as usize ; self . ensure_capacity (index + 1) ; self . nodes [index] = Some (value) ; } # [inline (always)] pub fn remove (& mut self , index : AudioNodeId) -> RefCell < Node > { self . nodes [index . 0 as usize] . take () . expect (\"Unable to remove non-existing Node in NodeCollection\") } # [inline (always)] pub fn keys (& self) -> impl Iterator < Item = AudioNodeId > + '_ { self . nodes . iter () . enumerate () . filter_map (| (i , v) | v . as_ref () . and (Some (AudioNodeId (i as u64)))) } # [inline (always)] pub fn values_mut (& mut self) -> impl Iterator < Item = & mut RefCell < Node > > { self . nodes . iter_mut () . filter_map (Option :: as_mut) } # [inline (always)] pub fn iter_mut (& mut self) -> impl Iterator < Item = (AudioNodeId , & mut RefCell < Node >) > { self . nodes . iter_mut () . enumerate () . filter_map (| (i , v) | v . as_mut () . map (| m | (AudioNodeId (i as u64) , m))) } # [inline (always)] pub fn contains (& self , index : AudioNodeId) -> bool { self . nodes [index . 0 as usize] . is_some () } # [inline (always)] pub fn get_mut (& mut self , index : AudioNodeId) -> Option < & mut RefCell < Node > > { self . nodes [index . 0 as usize] . as_mut () } # [track_caller] # [inline (always)] pub fn get_unchecked (& self , index : AudioNodeId) -> & RefCell < Node > { self . nodes [index . 0 as usize] . as_ref () . unwrap () } # [track_caller] # [inline (always)] pub fn get_unchecked_mut (& mut self , index : AudioNodeId) -> & mut Node { self . nodes [index . 0 as usize] . as_mut () . unwrap () . get_mut () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextRegistration , BaseAudioContext } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { AudioNode , AudioNodeOptions , ChannelConfig , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor , AudioParamInner , AutomationRate , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: { AudioParamValues , AudioProcessor , AudioRenderQuantum , AudioWorkletGlobalScope , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: f32 :: consts :: PI ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: OnceLock ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [doc = \" AudioParam settings for the cartesian coordinates\"] pub (crate) const PARAM_OPTS : AudioParamDescriptor = AudioParamDescriptor { name : String :: new () , min_value : f32 :: MIN , max_value : f32 :: MAX , default_value : 0. , automation_rate : AutomationRate :: A , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioListener { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"position_x\" , \"position_y\" , \"position_z\" , \"forward_x\" , \"forward_y\" , \"forward_z\" , \"up_x\" , \"up_y\" , \"up_z\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . position_x , & self . position_y , & self . position_z , & self . forward_x , & self . forward_y , & self . forward_z , & self . up_x , & self . up_y , & & self . up_z] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioListener\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioListener { pub fn position_x (& self) -> & AudioParam { & self . position_x } pub fn position_y (& self) -> & AudioParam { & self . position_y } pub fn position_z (& self) -> & AudioParam { & self . position_z } pub fn forward_x (& self) -> & AudioParam { & self . forward_x } pub fn forward_y (& self) -> & AudioParam { & self . forward_y } pub fn forward_z (& self) -> & AudioParam { & self . forward_z } pub fn up_x (& self) -> & AudioParam { & self . up_x } pub fn up_y (& self) -> & AudioParam { & self . up_y } pub fn up_z (& self) -> & AudioParam { & self . up_z } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioNode for AudioListenerNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { static INSTANCE : OnceLock < ChannelConfig > = OnceLock :: new () ; INSTANCE . get_or_init (| | { AudioNodeOptions { channel_count : 1 , channel_count_mode : ChannelCountMode :: Explicit , channel_interpretation : ChannelInterpretation :: Discrete , } . into () }) } fn number_of_inputs (& self) -> usize { 0 } fn number_of_outputs (& self) -> usize { 9 } fn set_channel_count (& self , _v : usize) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - AudioListenerNode has channel count constraints\")) ; } ; } fn set_channel_count_mode (& self , _v : ChannelCountMode) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - AudioListenerNode has channel count mode constraints\")) ; } ; } fn set_channel_interpretation (& self , _v : ChannelInterpretation) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - AudioListenerNode has channel interpretation constraints\")) ; } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioListenerNode { pub fn new < C : BaseAudioContext > (context : & C) -> Self { context . base () . register (move | registration | { let forward_z_opts = AudioParamDescriptor { default_value : - 1. , .. PARAM_OPTS } ; let up_y_opts = AudioParamDescriptor { default_value : 1. , .. PARAM_OPTS } ; let (p1 , _v1) = context . create_audio_param (PARAM_OPTS , & registration) ; let (p2 , _v2) = context . create_audio_param (PARAM_OPTS , & registration) ; let (p3 , _v3) = context . create_audio_param (PARAM_OPTS , & registration) ; let (p4 , _v4) = context . create_audio_param (PARAM_OPTS , & registration) ; let (p5 , _v5) = context . create_audio_param (PARAM_OPTS , & registration) ; let (p6 , _v6) = context . create_audio_param (forward_z_opts , & registration) ; let (p7 , _v7) = context . create_audio_param (PARAM_OPTS , & registration) ; let (p8 , _v8) = context . create_audio_param (up_y_opts , & registration) ; let (p9 , _v9) = context . create_audio_param (PARAM_OPTS , & registration) ; let node = Self { registration , fields : AudioListener { position_x : p1 , position_y : p2 , position_z : p3 , forward_x : p4 , forward_y : p5 , forward_z : p6 , up_x : p7 , up_y : p8 , up_z : p9 , } , } ; let proc = ListenerRenderer { } ; (node , Box :: new (proc)) }) } pub fn into_fields (self) -> AudioListener { self . fields } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioProcessor for ListenerRenderer { fn process (& mut self , _inputs : & [AudioRenderQuantum] , _outputs : & mut [AudioRenderQuantum] , _params : AudioParamValues < '_ > , _scope : & AudioWorkletGlobalScope) -> bool { true } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::spatial",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use vecmath :: { vec3_cross , vec3_dot , vec3_len , vec3_normalized , vec3_scale , vec3_square_len , vec3_sub , Vector3 , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: { AtomicU64 , AtomicU8 } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { Receiver , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: { AudioContextLatencyCategory , AudioContextOptions , AudioContextState , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: events :: EventDispatch ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_devices :: MediaDeviceInfo ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_streams :: { MediaStream , MediaStreamTrack } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: message :: ControlMessage ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AudioRenderCapacityLoad , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) use none :: NoneBackend ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for ControlThreadInit { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"state\" , \"frames_played\" , \"ctrl_msg_send\" , \"load_value_recv\" , \"event_send\" , \"event_recv\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . state , & self . frames_played , & self . ctrl_msg_send , & self . load_value_recv , & self . event_send , & & self . event_recv] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"ControlThreadInit\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for RenderThreadInit { # [inline] fn clone (& self) -> RenderThreadInit { RenderThreadInit { state : :: core :: clone :: Clone :: clone (& self . state) , frames_played : :: core :: clone :: Clone :: clone (& self . frames_played) , ctrl_msg_recv : :: core :: clone :: Clone :: clone (& self . ctrl_msg_recv) , load_value_send : :: core :: clone :: Clone :: clone (& self . load_value_send) , event_send : :: core :: clone :: Clone :: clone (& self . event_send) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for RenderThreadInit { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"RenderThreadInit\" , \"state\" , & self . state , \"frames_played\" , & self . frames_played , \"ctrl_msg_recv\" , & self . ctrl_msg_recv , \"load_value_send\" , & self . load_value_send , \"event_send\" , & & self . event_send) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: thread ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: time :: { Duration , Instant } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioBackendManager , RenderThreadInit } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: AudioContextOptions ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_devices :: MediaDeviceInfo ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: RenderThread ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { MAX_CHANNELS , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { Receiver , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for NoneBackend { # [inline] fn clone (& self) -> NoneBackend { NoneBackend { sender : :: core :: clone :: Clone :: clone (& self . sender) , sample_rate : :: core :: clone :: Clone :: clone (& self . sample_rate) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl NoneBackend { # [doc = \" Creates a mock backend to be used as tombstones\"] pub (crate) fn void () -> Self { Self { sample_rate : 0. , sender : crossbeam_channel :: bounded (0) . 0 , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Callback { fn run (mut self) { let buffer_size = RENDER_QUANTUM_SIZE ; let mut buffer = :: alloc :: vec :: from_elem (0. , buffer_size * MAX_CHANNELS) ; let interval = Duration :: from_secs_f32 (buffer_size as f32 / self . sample_rate) ; let mut deadline = Instant :: now () . checked_add (interval) . unwrap () ; loop { while let Ok (msg) = self . receiver . recv_deadline (deadline) { match msg { NoneBackendMessage :: Close => return , NoneBackendMessage :: Resume => { self . running = true ; deadline = Instant :: now () . checked_add (interval) . unwrap () ; break ; } NoneBackendMessage :: Suspend => self . running = false , } } if self . running { self . render_thread . render (& mut buffer [..]) ; } deadline = deadline . checked_add (interval) . unwrap () ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::none",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioBackendManager for NoneBackend { # [doc = \" Setup a new output stream (speakers)\"] fn build_output (options : AudioContextOptions , render_thread_init : RenderThreadInit) -> Self where Self : Sized { let sample_rate = options . sample_rate . unwrap_or (48000.) ; let RenderThreadInit { state , frames_played , ctrl_msg_recv , load_value_send , event_send } = render_thread_init ; let mut render_thread = RenderThread :: new (sample_rate , MAX_CHANNELS , ctrl_msg_recv , state , frames_played , event_send) ; render_thread . set_load_value_sender (load_value_send) ; render_thread . spawn_garbage_collector_thread () ; let (sender , receiver) = crossbeam_channel :: bounded (32) ; let callback = Callback { render_thread , receiver , sample_rate , running : true , } ; thread :: spawn (move | | callback . run ()) ; Self { sender , sample_rate } } # [doc = \" Setup a new input stream (microphone capture)\"] fn build_input (_options : AudioContextOptions , _number_of_channels : Option < u32 >) -> (Self , Receiver < AudioBuffer >) where Self : Sized { :: core :: panicking :: panic (\"not implemented\") } # [doc = \" Resume or start the stream\"] fn resume (& self) -> bool { self . sender . send (NoneBackendMessage :: Resume) . unwrap () ; true } # [doc = \" Suspend the stream\"] fn suspend (& self) -> bool { self . sender . send (NoneBackendMessage :: Suspend) . unwrap () ; true } # [doc = \" Close the stream, freeing all resources. It cannot be started again after closing.\"] fn close (& self) { self . sender . send (NoneBackendMessage :: Close) . unwrap () } # [doc = \" Sample rate of the stream\"] fn sample_rate (& self) -> f32 { self . sample_rate } # [doc = \" Number of channels of the stream\"] fn number_of_channels (& self) -> usize { MAX_CHANNELS } # [doc = \" Output latency of the stream in seconds\"] # [doc = \"\"] # [doc = \" This is the difference between the time the backend acquires the data in the callback and\"] # [doc = \" the listener can hear the sound.\"] fn output_latency (& self) -> f64 { 0. } # [doc = \" The audio output device\"] fn sink_id (& self) -> & str { \"none\" } fn enumerate_devices_sync () -> Vec < MediaDeviceInfo > where Self : Sized { :: core :: panicking :: panic (\"not implemented\") } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: Ordering ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Mutex ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use cpal :: { traits :: { DeviceTrait , HostTrait , StreamTrait } , BuildStreamError , Device , OutputCallbackInfo , SampleFormat , Stream , StreamConfig , SupportedBufferSize , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: Receiver ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: { AudioBackendManager , RenderThreadInit } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: AudioBuffer ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: AudioContextOptions ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: io :: microphone :: MicrophoneRender ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: media_devices :: { MediaDeviceInfo , MediaDeviceInfoKind } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: RenderThread ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AtomicF64 , MAX_CHANNELS } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use private :: ThreadSafeClosableStream ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for CpalBackend { # [inline] fn clone (& self) -> CpalBackend { CpalBackend { stream : :: core :: clone :: Clone :: clone (& self . stream) , output_latency : :: core :: clone :: Clone :: clone (& self . output_latency) , sample_rate : :: core :: clone :: Clone :: clone (& self . sample_rate) , number_of_channels : :: core :: clone :: Clone :: clone (& self . number_of_channels) , sink_id : :: core :: clone :: Clone :: clone (& self . sink_id) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AudioBackendManager for CpalBackend { fn build_output (options : AudioContextOptions , render_thread_init : RenderThreadInit) -> Self where Self : Sized { let host = get_host () ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Audio Output Host: cpal {0:?}\" , host . id ()) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 123u32 , ()) ; } } ; let RenderThreadInit { state , frames_played , ctrl_msg_recv , load_value_send , event_send } = render_thread_init ; let device = if options . sink_id . is_empty () { host . default_output_device () . expect (\"InvalidStateError - no output device available\") } else { Self :: enumerate_devices_sync () . into_iter () . find (| e | e . device_id () == options . sink_id) . map (| e | * e . device () . downcast :: < cpal :: Device > () . unwrap ()) . unwrap_or_else (| | { host . default_output_device () . expect (\"InvalidStateError - no output device available\") }) } ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Output device: {0:?}\" , device . name ()) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 147u32 , ()) ; } } ; let default_device_config = device . default_output_config () . expect (\"InvalidStateError - error while querying device output config\") ; let number_of_channels = usize :: from (default_device_config . channels ()) . min (MAX_CHANNELS) ; let mut preferred_config : StreamConfig = default_device_config . clone () . into () ; preferred_config . channels = number_of_channels as u16 ; if let Some (sample_rate) = options . sample_rate { crate :: assert_valid_sample_rate (sample_rate) ; preferred_config . sample_rate . 0 = sample_rate as u32 ; } let buffer_size = super :: buffer_size_for_latency_category (options . latency_hint , preferred_config . sample_rate . 0 as f32) as u32 ; let clamped_buffer_size : u32 = match default_device_config . buffer_size () { SupportedBufferSize :: Unknown => buffer_size , SupportedBufferSize :: Range { min , max } => buffer_size . clamp (* min , * max) , } ; preferred_config . buffer_size = cpal :: BufferSize :: Fixed (clamped_buffer_size) ; let mut sample_rate = preferred_config . sample_rate . 0 as f32 ; let output_latency = Arc :: new (AtomicF64 :: new (0.)) ; let mut renderer = RenderThread :: new (sample_rate , preferred_config . channels as usize , ctrl_msg_recv . clone () , Arc :: clone (& state) , Arc :: clone (& frames_played) , event_send . clone ()) ; renderer . set_load_value_sender (load_value_send . clone ()) ; renderer . spawn_garbage_collector_thread () ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Attempt output stream with preferred config: {0:?}\" , & preferred_config) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 201u32 , ()) ; } } ; let spawned = spawn_output_stream (& device , default_device_config . sample_format () , & preferred_config , renderer , Arc :: clone (& output_latency)) ; let stream = match spawned { Ok (stream) => { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Output stream set up successfully\") , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 216u32 , ()) ; } } ; stream } Err (e) => { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Output stream build failed with preferred config: {0}\" , e) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 220u32 , ()) ; } } ; let mut supported_config : StreamConfig = default_device_config . clone () . into () ; supported_config . channels = number_of_channels as u16 ; sample_rate = supported_config . sample_rate . 0 as f32 ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Attempt output stream with fallback config: {0:?}\" , & supported_config) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 228u32 , ()) ; } } ; let mut renderer = RenderThread :: new (sample_rate , supported_config . channels as usize , ctrl_msg_recv , state , frames_played , event_send) ; renderer . set_load_value_sender (load_value_send) ; renderer . spawn_garbage_collector_thread () ; let spawned = spawn_output_stream (& device , default_device_config . sample_format () , & supported_config , renderer , Arc :: clone (& output_latency)) ; spawned . expect (\"InvalidStateError - Unable to spawn output stream with default config\") } } ; stream . play () . expect (\"InvalidStateError - Output stream refused to play\") ; CpalBackend { stream : ThreadSafeClosableStream :: new (stream) , output_latency , sample_rate , number_of_channels , sink_id : options . sink_id , } } fn build_input (options : AudioContextOptions , number_of_channels : Option < u32 >) -> (Self , Receiver < AudioBuffer >) where Self : Sized { let host = get_host () ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Audio Input Host: cpal {0:?}\" , host . id ()) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 280u32 , ()) ; } } ; let device = if options . sink_id . is_empty () { host . default_input_device () . expect (\"InvalidStateError - no input device available\") } else { Self :: enumerate_devices_sync () . into_iter () . find (| e | e . device_id () == options . sink_id) . map (| e | * e . device () . downcast :: < cpal :: Device > () . unwrap ()) . unwrap_or_else (| | { host . default_input_device () . expect (\"InvalidStateError - no input device available\") }) } ; { let lvl = :: log :: Level :: Info ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Input device: {0:?}\" , device . name ()) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 296u32 , ()) ; } } ; let supported = device . default_input_config () . expect (\"InvalidStateError - error while querying device input config\") ; let mut preferred : StreamConfig = supported . clone () . into () ; if let Some (number_of_channels) = number_of_channels { preferred . channels = number_of_channels as u16 ; } if let Some (sample_rate) = options . sample_rate { crate :: assert_valid_sample_rate (sample_rate) ; preferred . sample_rate . 0 = sample_rate as u32 ; } let buffer_size = super :: buffer_size_for_latency_category (options . latency_hint , preferred . sample_rate . 0 as f32) as u32 ; let clamped_buffer_size : u32 = match supported . buffer_size () { SupportedBufferSize :: Unknown => buffer_size , SupportedBufferSize :: Range { min , max } => buffer_size . clamp (* min , * max) , } ; preferred . buffer_size = cpal :: BufferSize :: Fixed (clamped_buffer_size) ; let mut sample_rate = preferred . sample_rate . 0 as f32 ; let mut number_of_channels = preferred . channels as usize ; let smoothing = 3 ; let (sender , mut receiver) = crossbeam_channel :: bounded (smoothing) ; let renderer = MicrophoneRender :: new (number_of_channels , sample_rate , sender) ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Attempt input stream with preferred config: {0:?}\" , & preferred) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 334u32 , ()) ; } } ; let spawned = spawn_input_stream (& device , supported . sample_format () , & preferred , renderer) ; let stream = match spawned { Ok (stream) => { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Input stream set up successfully\") , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 345u32 , ()) ; } } ; stream } Err (e) => { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Output stream build failed with preferred config: {0}\" , e) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 349u32 , ()) ; } } ; let supported_config : StreamConfig = supported . clone () . into () ; number_of_channels = usize :: from (supported_config . channels) ; sample_rate = supported_config . sample_rate . 0 as f32 ; { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Attempt output stream with fallback config: {0:?}\" , & supported_config) , lvl , & (\"web_audio_api::io::cpal\" , \"web_audio_api::io::cpal\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/cpal.rs\") , 356u32 , ()) ; } } ; let (sender , receiver2) = crossbeam_channel :: bounded (smoothing) ; receiver = receiver2 ; let renderer = MicrophoneRender :: new (number_of_channels , sample_rate , sender) ; let spawned = spawn_input_stream (& device , supported . sample_format () , & supported_config , renderer) ; spawned . expect (\"InvalidStateError - Unable to spawn input stream with default config\") } } ; stream . play () . expect (\"InvalidStateError - Input stream refused to play\") ; let backend = CpalBackend { stream : ThreadSafeClosableStream :: new (stream) , output_latency : Arc :: new (AtomicF64 :: new (0.)) , sample_rate , number_of_channels , sink_id : options . sink_id , } ; (backend , receiver) } fn resume (& self) -> bool { self . stream . resume () } fn suspend (& self) -> bool { self . stream . suspend () } fn close (& self) { self . stream . close () } fn sample_rate (& self) -> f32 { self . sample_rate } fn number_of_channels (& self) -> usize { self . number_of_channels } fn output_latency (& self) -> f64 { self . output_latency . load (Ordering :: Relaxed) } fn sink_id (& self) -> & str { self . sink_id . as_str () } fn enumerate_devices_sync () -> Vec < MediaDeviceInfo > where Self : Sized { let host = get_host () ; let input_devices = host . input_devices () . unwrap () . map (| d | { let num_channels = d . default_input_config () . unwrap () . channels () ; (d , MediaDeviceInfoKind :: AudioInput , num_channels) }) ; let output_devices = host . output_devices () . unwrap () . map (| d | { let num_channels = d . default_output_config () . unwrap () . channels () ; (d , MediaDeviceInfoKind :: AudioOutput , num_channels) }) ; let mut list = Vec :: < MediaDeviceInfo > :: new () ; for (device , kind , num_channels) in input_devices . chain (output_devices) { let mut index = 0 ; loop { let device_id = crate :: media_devices :: DeviceId :: as_string (kind , \"cpal\" . to_string () , device . name () . unwrap () , num_channels , index) ; if ! list . iter () . any (| d | d . device_id () == device_id) { let device = MediaDeviceInfo :: new (device_id , None , kind , device . name () . unwrap () , Box :: new (device)) ; list . push (device) ; break ; } else { index += 1 ; } } } list } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal::private",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use super :: * ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal::private",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for ThreadSafeClosableStream { # [inline] fn clone (& self) -> ThreadSafeClosableStream { ThreadSafeClosableStream (:: core :: clone :: Clone :: clone (& self . 0)) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal::private",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl ThreadSafeClosableStream { pub fn new (stream : Stream) -> Self { # [allow (clippy :: arc_with_non_send_sync)] Self (Arc :: new (Mutex :: new (Some (stream)))) } pub fn close (& self) { self . 0 . lock () . unwrap () . take () ; } pub fn resume (& self) -> bool { if let Some (s) = self . 0 . lock () . unwrap () . as_ref () { if let Err (e) = s . play () { { :: core :: panicking :: panic_fmt (format_args ! (\"Error resuming cpal stream: {0:?}\" , e)) ; } ; } return true ; } false } pub fn suspend (& self) -> bool { if let Some (s) = self . 0 . lock () . unwrap () . as_ref () { if let Err (e) = s . pause () { { :: core :: panicking :: panic_fmt (format_args ! (\"Error suspending cpal stream: {0:?}\" , e)) ; } ; } return true ; } false } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal::private",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "unsafe impl Sync for ThreadSafeClosableStream { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::cpal::private",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "unsafe impl Send for ThreadSafeClosableStream { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: { AudioBuffer , AudioBufferOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: io :: AudioBackendManager ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { Receiver , Sender , TryRecvError } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MicrophoneStream { pub (crate) fn new (receiver : Receiver < AudioBuffer > , backend : Box < dyn AudioBackendManager >) -> Self { Self { receiver , number_of_channels : backend . number_of_channels () , sample_rate : backend . sample_rate () , stream : backend , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Drop for MicrophoneStream { fn drop (& mut self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Microphone stream has been dropped\") , lvl , & (\"web_audio_api::io::microphone\" , \"web_audio_api::io::microphone\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/microphone.rs\") , 32u32 , ()) ; } } ; self . stream . close () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Iterator for MicrophoneStream { type Item = Result < AudioBuffer , Box < dyn Error + Send + Sync > > ; fn next (& mut self) -> Option < Self :: Item > { let next = match self . receiver . try_recv () { Ok (buffer) => { buffer } Err (TryRecvError :: Empty) => { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"empty channel: input frame delayed\") , lvl , & (\"web_audio_api::io::microphone\" , \"web_audio_api::io::microphone\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/microphone.rs\") , 48u32 , ()) ; } } ; let options = AudioBufferOptions { number_of_channels : self . number_of_channels , length : RENDER_QUANTUM_SIZE , sample_rate : self . sample_rate , } ; AudioBuffer :: new (options) } Err (TryRecvError :: Disconnected) => { return None ; } } ; Some (Ok (next)) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MicrophoneRender { pub fn new (number_of_channels : usize , sample_rate : f32 , sender : Sender < AudioBuffer >) -> Self { Self { number_of_channels , sample_rate , sender } } pub fn render < S : dasp_sample :: ToSample < f32 > + Copy > (& self , data : & [S]) { let mut channels = Vec :: with_capacity (self . number_of_channels) ; for i in 0 .. self . number_of_channels { channels . push (data . iter () . skip (i) . step_by (self . number_of_channels) . map (| v | v . to_sample_ ()) . collect ()) ; } let buffer = AudioBuffer :: from (channels , self . sample_rate) ; let result = self . sender . try_send (buffer) ; if result . is_err () { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"input frame dropped\") , lvl , & (\"web_audio_api::io::microphone\" , \"web_audio_api::io::microphone\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/microphone.rs\") , 101u32 , ()) ; } } ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::io::microphone",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Drop for MicrophoneRender { fn drop (& mut self) { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Microphone input has been dropped\") , lvl , & (\"web_audio_api::io::microphone\" , \"web_audio_api::io::microphone\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/io/microphone.rs\") , 108u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: f32 :: consts :: PI ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: { AtomicUsize , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: { Arc , Mutex } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use realfft :: { num_complex :: Complex , RealFftPlanner } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AtomicF32 , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) const DEFAULT_SMOOTHING_TIME_CONSTANT : f64 = 0.8 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) const DEFAULT_MIN_DECIBELS : f64 = - 100. ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) const DEFAULT_MAX_DECIBELS : f64 = - 30. ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "pub (crate) const DEFAULT_FFT_SIZE : usize = 2048 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "const MIN_FFT_SIZE : usize = 32 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "const MAX_FFT_SIZE : usize = 32768 ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "const RING_BUFFER_SIZE : usize = MAX_FFT_SIZE + RENDER_QUANTUM_SIZE ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "# [automatically_derived] impl :: core :: clone :: Clone for AnalyserRingBuffer { # [inline] fn clone (& self) -> AnalyserRingBuffer { AnalyserRingBuffer { buffer : :: core :: clone :: Clone :: clone (& self . buffer) , write_index : :: core :: clone :: Clone :: clone (& self . write_index) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl AnalyserRingBuffer { pub fn new () -> Self { let mut buffer = Vec :: with_capacity (RING_BUFFER_SIZE) ; buffer . resize_with (RING_BUFFER_SIZE , | | AtomicF32 :: new (0.)) ; Self { buffer : buffer . into () , write_index : Arc :: new (AtomicUsize :: new (0)) , } } pub fn write (& self , src : & [f32]) { let mut write_index = self . write_index . load (Ordering :: SeqCst) ; let len = src . len () ; src . iter () . enumerate () . for_each (| (index , value) | { let position = (write_index + index) % RING_BUFFER_SIZE ; self . buffer [position] . store (* value , Ordering :: Relaxed) ; }) ; write_index += len ; if write_index >= RING_BUFFER_SIZE { write_index -= RING_BUFFER_SIZE ; } self . write_index . store (write_index , Ordering :: SeqCst) ; } pub fn read (& self , dst : & mut [f32] , max_len : usize) { let write_index = self . write_index . load (Ordering :: SeqCst) ; let len = dst . len () . min (max_len) ; dst . iter_mut () . take (len) . enumerate () . for_each (| (index , value) | { let position = (RING_BUFFER_SIZE + write_index - len + index) % RING_BUFFER_SIZE ; * value = self . buffer [position] . load (Ordering :: Relaxed) ; }) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for Analyser { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"Analyser\") . field (\"fft_size\" , & self . fft_size ()) . field (\"smoothing_time_constant\" , & self . smoothing_time_constant ()) . field (\"min_decibels\" , & self . min_decibels ()) . field (\"max_decibels\" , & self . max_decibels ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::analysis",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Analyser { pub fn new () -> Self { let ring_buffer = AnalyserRingBuffer :: new () ; let mut fft_planner = RealFftPlanner :: < f32 > :: new () ; let max_fft = fft_planner . plan_fft_forward (MAX_FFT_SIZE) ; let fft_input = max_fft . make_input_vec () ; let fft_scratch = max_fft . make_scratch_vec () ; let fft_output = max_fft . make_output_vec () ; let mut last_fft_output = Vec :: with_capacity (fft_output . len ()) ; last_fft_output . resize_with (fft_output . len () , | | 0.) ; let mut blackman = Vec :: with_capacity (fft_input . len ()) ; generate_blackman (DEFAULT_FFT_SIZE) . for_each (| v | blackman . push (v)) ; Self { ring_buffer , fft_size : DEFAULT_FFT_SIZE , smoothing_time_constant : DEFAULT_SMOOTHING_TIME_CONSTANT , min_decibels : DEFAULT_MIN_DECIBELS , max_decibels : DEFAULT_MAX_DECIBELS , fft_planner : Mutex :: new (fft_planner) , fft_input , fft_scratch , fft_output , last_fft_output , last_fft_time : f64 :: NEG_INFINITY , blackman , } } pub fn get_ring_buffer_clone (& self) -> AnalyserRingBuffer { self . ring_buffer . clone () } pub fn fft_size (& self) -> usize { self . fft_size } pub fn set_fft_size (& mut self , fft_size : usize) { assert_valid_fft_size (fft_size) ; let current_fft_size = self . fft_size ; if current_fft_size != fft_size { self . last_fft_output . iter_mut () . for_each (| v | * v = 0.) ; self . blackman . clear () ; generate_blackman (fft_size) . for_each (| v | self . blackman . push (v)) ; self . fft_size = fft_size ; } } pub fn smoothing_time_constant (& self) -> f64 { self . smoothing_time_constant } pub fn set_smoothing_time_constant (& mut self , value : f64) { assert_valid_smoothing_time_constant (value) ; self . smoothing_time_constant = value ; } pub fn min_decibels (& self) -> f64 { self . min_decibels } pub fn max_decibels (& self) -> f64 { self . max_decibels } pub fn set_decibels (& mut self , min : f64 , max : f64) { assert_valid_decibels (min , max) ; self . min_decibels = min ; self . max_decibels = max ; } pub fn frequency_bin_count (& self) -> usize { self . fft_size () / 2 } pub fn get_float_time_domain_data (& self , dst : & mut [f32]) { let fft_size = self . fft_size () ; self . ring_buffer . read (dst , fft_size) ; } pub fn get_byte_time_domain_data (& self , dst : & mut [u8]) { let fft_size = self . fft_size () ; let mut tmp = :: alloc :: vec :: from_elem (0. , dst . len ()) ; self . ring_buffer . read (& mut tmp , fft_size) ; dst . iter_mut () . zip (tmp . iter ()) . for_each (| (o , i) | { let scaled = 128. * (1. + i) ; let clamped = scaled . clamp (0. , 255.) ; * o = clamped as u8 ; }) ; } fn compute_fft (& mut self) { let fft_size = self . fft_size () ; let smoothing_time_constant = self . smoothing_time_constant () as f32 ; let r2c = self . fft_planner . lock () . unwrap () . plan_fft_forward (fft_size) ; let input = & mut self . fft_input [.. fft_size] ; let output = & mut self . fft_output [.. fft_size / 2 + 1] ; let scratch = & mut self . fft_scratch [.. r2c . get_scratch_len ()] ; let last_fft_output = & mut self . last_fft_output [.. fft_size / 2] ; self . ring_buffer . read (input , fft_size) ; input . iter_mut () . zip (self . blackman . iter ()) . for_each (| (i , b) | * i *= * b) ; r2c . process_with_scratch (input , output , scratch) . unwrap () ; let normalize_factor = 1. / fft_size as f32 ; last_fft_output . iter_mut () . zip (output . iter ()) . for_each (| (o , c) | { let norm = c . norm () * normalize_factor ; let value = smoothing_time_constant * * o + (1. - smoothing_time_constant) * norm ; * o = if value . is_finite () { value } else { 0. } ; }) ; } pub fn get_float_frequency_data (& mut self , dst : & mut [f32] , current_time : f64) { let frequency_bin_count = self . frequency_bin_count () ; if current_time != self . last_fft_time { self . compute_fft () ; self . last_fft_time = current_time ; } let len = dst . len () . min (frequency_bin_count) ; dst . iter_mut () . take (len) . zip (self . last_fft_output . iter ()) . for_each (| (v , b) | * v = 20. * b . log10 ()) ; } pub fn get_byte_frequency_data (& mut self , dst : & mut [u8] , current_time : f64) { let frequency_bin_count = self . frequency_bin_count () ; let min_decibels = self . min_decibels () as f32 ; let max_decibels = self . max_decibels () as f32 ; if current_time != self . last_fft_time { self . compute_fft () ; self . last_fft_time = current_time ; } let len = dst . len () . min (frequency_bin_count) ; dst . iter_mut () . take (len) . zip (self . last_fft_output . iter ()) . for_each (| (v , b) | { let db = 20. * b . log10 () ; let scaled = 255. / (max_decibels - min_decibels) * (db - min_decibels) ; let clamped = scaled . clamp (0. , 255.) ; * v = clamped as u8 ; }) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: context :: AudioNodeId ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: node :: { ChannelConfigInner , ChannelCountMode , ChannelInterpretation , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: graph :: Graph ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: render :: AudioProcessor ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::message",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl OneshotNotify { # [doc = \" Emit the notification\"] pub fn send (self) { match self { Self :: Sync (s) => s . send (()) . ok () , Self :: Async (s) => s . send (()) . ok () , } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: io :: { Read , Seek , SeekFrom } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: { AudioBuffer , ChannelData } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: audio :: AudioBufferRef ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: audio :: Signal ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: codecs :: { Decoder , DecoderOptions , FinalizeResult } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: conv :: FromSample ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: errors :: Error as SymphoniaError ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: formats :: { FormatOptions , FormatReader } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: meta :: MetadataOptions ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use symphonia :: core :: probe :: Hint ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < R : Read > MediaInput < R > { pub fn new (input : R) -> Self { Self { input } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < R : Read > Read for MediaInput < R > { fn read (& mut self , buf : & mut [u8]) -> std :: io :: Result < usize > { self . input . read (buf) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < R > Seek for MediaInput < R > { fn seek (& mut self , _pos : SeekFrom) -> std :: io :: Result < u64 > { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError - MediaInput does not support seeking\")) ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < R : Read + Send + Sync > symphonia :: core :: io :: MediaSource for MediaInput < R > { fn is_seekable (& self) -> bool { false } fn byte_len (& self) -> Option < u64 > { None } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MediaDecoder { # [doc = \" Try to construct a new instance from a `Read` implementer\"] # [doc = \"\"] # [doc = \" # Errors\"] # [doc = \"\"] # [doc = \" This method returns an Error in various cases (IO, mime sniffing, decoding).\"] pub fn try_new < R : std :: io :: Read + Send + Sync + 'static > (input : R) -> Result < Self , Box < dyn std :: error :: Error + Send + Sync > > { let input = Box :: new (MediaInput :: new (input)) ; let stream = symphonia :: core :: io :: MediaSourceStream :: new (input , Default :: default ()) ; let hint = Hint :: new () ; let format_opts : FormatOptions = Default :: default () ; let metadata_opts : MetadataOptions = Default :: default () ; let decoder_opts = DecoderOptions { verify : true } ; let probed = symphonia :: default :: get_probe () . format (& hint , stream , & format_opts , & metadata_opts) ? ; let format = probed . format ; let track = format . default_track () . ok_or (SymphoniaError :: Unsupported (\"no default media track available\")) ? ; let track_index = format . tracks () . iter () . position (| t | t . id == track . id) . unwrap () ; let decoder = symphonia :: default :: get_codecs () . make (& track . codec_params , & decoder_opts) ? ; Ok (Self { format , decoder , track_index , packet_count : 0 }) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::decoding",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Iterator for MediaDecoder { type Item = Result < AudioBuffer , Box < dyn Error + Send + Sync > > ; fn next (& mut self) -> Option < Self :: Item > { let Self { format , decoder , track_index , packet_count } = self ; let track = format . tracks () . get (* track_index) ? ; let track_id = track . id ; loop { let packet = match format . next_packet () { Err (err) => { if let SymphoniaError :: IoError (err) = & err { if err . kind () == std :: io :: ErrorKind :: UnexpectedEof { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Decoding finished after {0} packet(s)\" , packet_count) , lvl , & (\"web_audio_api::decoding\" , \"web_audio_api::decoding\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/decoding.rs\") , 137u32 , ()) ; } } ; let FinalizeResult { verify_ok } = decoder . finalize () ; if verify_ok == Some (false) { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Verification of decoded data failed\") , lvl , & (\"web_audio_api::decoding\" , \"web_audio_api::decoding\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/decoding.rs\") , 140u32 , ()) ; } } ; } return None ; } } { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Failed to fetch next packet following packet #{0}: {1}\" , packet_count , err) , lvl , & (\"web_audio_api::decoding\" , \"web_audio_api::decoding\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/decoding.rs\") , 145u32 , ()) ; } } ; return Some (Err (Box :: new (err))) ; } Ok (packet) => { * packet_count += 1 ; packet } } ; let packet_track_id = packet . track_id () ; if packet_track_id != track_id { { let lvl = :: log :: Level :: Debug ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Skipping packet from other track {0} while decoding track {1}\" , packet_track_id , track_id) , lvl , & (\"web_audio_api::decoding\" , \"web_audio_api::decoding\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/decoding.rs\") , 159u32 , ()) ; } } ; continue ; } match decoder . decode (& packet) { Ok (input) => { let output = convert_buf (input) ; return Some (Ok (output)) ; } Err (SymphoniaError :: DecodeError (err)) => { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"Failed to decode packet #{0}: {1}\" , packet_count , err) , lvl , & (\"web_audio_api::decoding\" , \"web_audio_api::decoding\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/decoding.rs\") , 173u32 , ()) ; } } ; } Err (SymphoniaError :: IoError (err)) => { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"I/O error while decoding packet #{0}: {1}\" , packet_count , err) , lvl , & (\"web_audio_api::decoding\" , \"web_audio_api::decoding\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/decoding.rs\") , 177u32 , ()) ; } } ; } Err (err) => { return Some (Err (Box :: new (err))) ; } } ; } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: path :: PathBuf ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: atomic :: { AtomicBool , Ordering } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: sync :: Arc ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use creek :: { ReadDiskStream , SeekMode , SymphoniaDecoder } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crossbeam_channel :: { Receiver , Sender } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: { AtomicF64 , AudioBuffer , RENDER_QUANTUM_SIZE } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for RTSStream { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"RTSStream\") . field (\"number_of_channels\" , & self . number_of_channels) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl std :: fmt :: Debug for MediaElement { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"MediaElement\") . field (\"stream\" , & self . stream) . field (\"current_time\" , & self . current_time ()) . field (\"loop\" , & self . loop_ ()) . field (\"paused\" , & self . paused ()) . field (\"playback_rate\" , & self . playback_rate ()) . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl MediaElement { # [doc = \" Create a new instance for a given file path\"] pub fn new < P : Into < PathBuf > > (file : P) -> Result < Self , Box < dyn Error > > { let mut read_disk_stream = ReadDiskStream :: < SymphoniaDecoder > :: new (file , 0 , Default :: default ()) ? ; let number_of_channels = read_disk_stream . info () . num_channels as usize ; let _ = read_disk_stream . cache (0 , 0) ; read_disk_stream . seek (0 , SeekMode :: default ()) ? ; read_disk_stream . block_until_ready () ? ; let (sender , receiver) = crossbeam_channel :: bounded (32) ; let current_time = Arc :: new (AtomicF64 :: new (0.)) ; let loop_ = Arc :: new (AtomicBool :: new (false)) ; let paused = Arc :: new (AtomicBool :: new (true)) ; let playback_rate = Arc :: new (AtomicF64 :: new (1.)) ; let rts_stream = RTSStream { stream : read_disk_stream , number_of_channels , current_time : Arc :: clone (& current_time) , receiver , loop_ : Arc :: clone (& loop_) , paused : Arc :: clone (& paused) , playback_rate : Arc :: clone (& playback_rate) , } ; Ok (Self { stream : Some (rts_stream) , current_time , sender , loop_ , paused , playback_rate , }) } pub (crate) fn take_stream (& mut self) -> Option < RTSStream > { self . stream . take () } pub fn current_time (& self) -> f64 { self . current_time . load (Ordering :: SeqCst) } pub fn set_current_time (& self , value : f64) { let _ = self . sender . send (MediaElementAction :: Seek (value)) ; } pub fn loop_ (& self) -> bool { self . loop_ . load (Ordering :: SeqCst) } pub fn set_loop (& self , value : bool) { let _ = self . sender . send (MediaElementAction :: SetLoop (value)) ; } pub fn play (& self) { let _ = self . sender . send (MediaElementAction :: Play) ; } pub fn pause (& self) { let _ = self . sender . send (MediaElementAction :: Pause) ; } pub fn paused (& self) -> bool { self . paused . load (Ordering :: SeqCst) } pub fn playback_rate (& self) -> f64 { self . playback_rate . load (Ordering :: SeqCst) } pub fn set_playback_rate (& self , value : f64) { let _ = self . sender . send (MediaElementAction :: SetPlaybackRate (value)) ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::media_element",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl Iterator for RTSStream { type Item = Result < AudioBuffer , Box < dyn Error + Send + Sync > > ; fn next (& mut self) -> Option < Self :: Item > { let sample_rate = self . stream . info () . sample_rate . unwrap () as f32 ; if let Ok (msg) = self . receiver . try_recv () { use MediaElementAction :: * ; match msg { Seek (value) => { self . current_time . store (value , Ordering :: SeqCst) ; let frame = (value * sample_rate as f64) as usize ; self . stream . seek (frame , SeekMode :: default ()) . unwrap () ; } SetLoop (value) => { self . loop_ . store (value , Ordering :: SeqCst) ; } Play => self . paused . store (false , Ordering :: SeqCst) , Pause => self . paused . store (true , Ordering :: SeqCst) , SetPlaybackRate (value) => self . playback_rate . store (value , Ordering :: SeqCst) , } ; } if self . paused . load (Ordering :: SeqCst) { let silence = AudioBuffer :: from (:: alloc :: vec :: from_elem (:: alloc :: vec :: from_elem (0. , RENDER_QUANTUM_SIZE) , self . number_of_channels) , sample_rate) ; return Some (Ok (silence)) ; } let playback_rate = self . playback_rate . load (Ordering :: SeqCst) . abs () ; let _reverse = playback_rate < 0. ; let samples = (RENDER_QUANTUM_SIZE as f64 * playback_rate) as usize ; let next = match self . stream . read (samples) { Ok (data) => { let channels : Vec < _ > = (0 .. data . num_channels ()) . map (| i | data . read_channel (i) . to_vec ()) . collect () ; let buf = AudioBuffer :: from (channels , sample_rate * playback_rate as f32) ; if self . loop_ . load (Ordering :: SeqCst) && data . reached_end_of_file () { self . stream . seek (0 , SeekMode :: default ()) . unwrap () ; self . current_time . store (0. , Ordering :: SeqCst) ; } else { let current_time = self . current_time . load (Ordering :: SeqCst) ; self . current_time . store (current_time + (RENDER_QUANTUM_SIZE as f64 / sample_rate as f64) , Ordering :: SeqCst) ; } Ok (buf) } Err (e) => Err (Box :: new (e) as _) , } ; Some (next) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::resampling",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use std :: error :: Error ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::resampling",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: buffer :: { AudioBuffer , AudioBufferOptions } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::resampling",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "use crate :: AudioBufferIter ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::resampling",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < M : AudioBufferIter > Resampler < M > { pub fn new (sample_rate : f32 , sample_len : usize , input : M) -> Self { Self { sample_rate , sample_len , input , buffer : None } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::resampling",
        "sources": [
          "Normal"
        ],
        "is_module_public": false
      },
      "item": "impl < M : AudioBufferIter > Iterator for Resampler < M > { type Item = Result < AudioBuffer , Box < dyn Error + Send + Sync > > ; fn next (& mut self) -> Option < Self :: Item > { let mut buffer = match self . buffer . take () { None => match self . input . next () { None => return None , Some (Err (e)) => return Some (Err (e)) , Some (Ok (mut data)) => { data . resample (self . sample_rate) ; data } } , Some (data) => data , } ; while buffer . length () < self . sample_len { match self . input . next () { None => { let options = AudioBufferOptions { number_of_channels : buffer . number_of_channels () , length : self . sample_len - buffer . length () , sample_rate : self . sample_rate , } ; let padding = AudioBuffer :: new (options) ; buffer . extend (& padding) ; return Some (Ok (buffer)) ; } Some (Err (e)) => return Some (Err (e)) , Some (Ok (mut data)) => { data . resample (self . sample_rate) ; buffer . extend (& data) } } } if buffer . length () == self . sample_len { return Some (Ok (buffer)) ; } self . buffer = Some (buffer . split_off (self . sample_len)) ; Some (Ok (buffer)) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "pub use crate :: render :: AudioWorkletGlobalScope ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: context :: { AudioContextRegistration , AudioParamId , BaseAudioContext , } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: node :: { AudioNode , AudioNodeOptions , ChannelConfig } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: param :: { AudioParam , AudioParamDescriptor } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: render :: { AudioProcessor , AudioRenderQuantum } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use crate :: { MessagePort , MAX_CHANNELS } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: any :: Any ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: collections :: HashMap ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "use std :: ops :: { Deref , DerefMut } ;"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Accessor for current [`AudioParam`] values\"] pub struct AudioParamValues < 'a > { values : crate :: render :: AudioParamValues < 'a > , map : & 'a HashMap < String , AudioParamId > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < 'a > std :: fmt :: Debug for AudioParamValues < 'a > { fn fmt (& self , f : & mut std :: fmt :: Formatter < '_ >) -> std :: fmt :: Result { f . debug_struct (\"AudioParamValues\") . finish_non_exhaustive () } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < 'a > AudioParamValues < 'a > { # [doc = \" Get the computed values for the given [`AudioParam`]\"] # [doc = \"\"] # [doc = \" For k-rate params or if the (a-rate) parameter is constant for this block, it will provide\"] # [doc = \" a slice of length 1. In other cases, i.e. a-rate param with scheduled automations it will\"] # [doc = \" provide a slice of length equal to the render quantum size (default: 128)\"] # [allow (clippy :: missing_panics_doc)] pub fn get (& 'a self , name : & str) -> impl Deref < Target = [f32] > + 'a { let id = self . map . get (name) . unwrap () ; self . values . get (id) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Audio processing code that runs on the audio rendering thread.\"] pub trait AudioWorkletProcessor { # [doc = \" Constructor options for the audio processor\"] # [doc = \"\"] # [doc = \" This holds any user-defined data that may be used to initialize custom\"] # [doc = \" properties in an AudioWorkletProcessor instance that is associated with the\"] # [doc = \" AudioWorkletNode.\"] type ProcessorOptions : Send ; # [doc = \" Constructor of the [`AudioWorkletProcessor`] instance (to be executed in the render thread)\"] fn constructor (opts : Self :: ProcessorOptions) -> Self where Self : Sized ; # [doc = \" List of [`AudioParam`]s for this audio processor\"] # [doc = \"\"] # [doc = \" A default implementation is provided that supplies no parameters.\"] fn parameter_descriptors () -> Vec < AudioParamDescriptor > where Self : Sized { :: alloc :: vec :: Vec :: new () } # [doc = \" Audio processing function\"] # [doc = \"\"] # [doc = \" # Arguments\"] # [doc = \"\"] # [doc = \" - inputs: readonly array of input buffers\"] # [doc = \" - outputs: array of output buffers\"] # [doc = \" - params: available [`AudioParam`] values for this processor\"] # [doc = \" - scope: AudioWorkletGlobalScope object with current frame, timestamp, sample rate\"] # [doc = \"\"] # [doc = \" # Return value\"] # [doc = \"\"] # [doc = \" The return value (bool) of this callback controls the lifetime of the processor.\"] # [doc = \"\"] # [doc = \" - return `false` when the node only transforms their inputs, and as such can be removed when\"] # [doc = \" the inputs are disconnected (e.g. GainNode)\"] # [doc = \" - return `true` for some time when the node still outputs after the inputs are disconnected\"] # [doc = \" (e.g. DelayNode)\"] # [doc = \" - return `true` as long as this node is a source of output (e.g. OscillatorNode)\"] fn process < 'a , 'b > (& mut self , inputs : & 'b [& 'a [& 'a [f32]]] , outputs : & 'b mut [& 'a mut [& 'a mut [f32]]] , params : AudioParamValues < 'b > , scope : & 'b AudioWorkletGlobalScope) -> bool ; # [doc = \" Handle incoming messages from the linked AudioNode\"] # [doc = \"\"] # [doc = \" By overriding this method you can add a handler for messages sent from the control thread\"] # [doc = \" via the AudioWorkletNode MessagePort.\"] # [doc = \"\"] # [doc = \" Receivers are supposed to consume the content of `msg`. The content of `msg` might\"] # [doc = \" also be replaced by cruft that needs to be deallocated outside of the render thread\"] # [doc = \" afterwards, e.g. when replacing an internal buffer.\"] # [doc = \"\"] # [doc = \" This method is just a shim of the full\"] # [doc = \" [`MessagePort`](https://webaudio.github.io/web-audio-api/#dom-audioworkletprocessor-port)\"] # [doc = \" `onmessage` functionality of the AudioWorkletProcessor.\"] fn onmessage (& mut self , _msg : & mut dyn Any) { { let lvl = :: log :: Level :: Warn ; if lvl <= :: log :: STATIC_MAX_LEVEL && lvl <= :: log :: max_level () { :: log :: __private_api :: log (format_args ! (\"AudioWorkletProcessor: Ignoring incoming message\") , lvl , & (\"web_audio_api::worklet\" , \"web_audio_api::worklet\" , \"/Volumes/mac-J/larpoux/.cargo/registry/src/index.crates.io-6f17d22bba15001f/web-audio-api-1.0.0-rc.6/src/worklet.rs\") , 108u32 , ()) ; } } ; } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" Options for constructing an [`AudioWorkletNode`]\"] pub struct AudioWorkletNodeOptions < C > { # [doc = \" This is used to initialize the value of the AudioNode numberOfInputs attribute.\"] pub number_of_inputs : usize , # [doc = \" This is used to initialize the value of the AudioNode numberOfOutputs attribute.\"] pub number_of_outputs : usize , # [doc = \" This array is used to configure the number of channels in each output.\"] pub output_channel_count : Vec < usize > , # [doc = \" This is a list of user-defined key-value pairs that are used to set the initial value of an\"] # [doc = \" AudioParam with the matched name in the AudioWorkletNode.\"] pub parameter_data : HashMap < String , f64 > , # [doc = \" This holds any user-defined data that may be used to initialize custom properties in an\"] # [doc = \" AudioWorkletProcessor instance that is associated with the AudioWorkletNode.\"] pub processor_options : C , # [doc = \" Channel config options\"] pub audio_node_options : AudioNodeOptions , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl < C : :: core :: clone :: Clone > :: core :: clone :: Clone for AudioWorkletNodeOptions < C > { # [inline] fn clone (& self) -> AudioWorkletNodeOptions < C > { AudioWorkletNodeOptions { number_of_inputs : :: core :: clone :: Clone :: clone (& self . number_of_inputs) , number_of_outputs : :: core :: clone :: Clone :: clone (& self . number_of_outputs) , output_channel_count : :: core :: clone :: Clone :: clone (& self . output_channel_count) , parameter_data : :: core :: clone :: Clone :: clone (& self . parameter_data) , processor_options : :: core :: clone :: Clone :: clone (& self . processor_options) , audio_node_options : :: core :: clone :: Clone :: clone (& self . audio_node_options) , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl < C : :: core :: fmt :: Debug > :: core :: fmt :: Debug for AudioWorkletNodeOptions < C > { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { let names : & 'static _ = & [\"number_of_inputs\" , \"number_of_outputs\" , \"output_channel_count\" , \"parameter_data\" , \"processor_options\" , \"audio_node_options\"] ; let values : & [& dyn :: core :: fmt :: Debug] = & [& self . number_of_inputs , & self . number_of_outputs , & self . output_channel_count , & self . parameter_data , & self . processor_options , & & self . audio_node_options] ; :: core :: fmt :: Formatter :: debug_struct_fields_finish (f , \"AudioWorkletNodeOptions\" , names , values) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < C : Default > Default for AudioWorkletNodeOptions < C > { fn default () -> Self { Self { number_of_inputs : 1 , number_of_outputs : 1 , output_channel_count : Vec :: new () , parameter_data : HashMap :: new () , processor_options : C :: default () , audio_node_options : AudioNodeOptions :: default () , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [doc = \" A user-defined AudioNode which lives in the control thread\"] # [doc = \"\"] # [doc = \" - MDN documentation: <https://developer.mozilla.org/en-US/docs/Web/API/AudioWorkletNode>\"] # [doc = \" - specification: <https://webaudio.github.io/web-audio-api/#AudioWorkletNode>\"] # [doc = \"\"] # [doc = \" # Examples\"] # [doc = \"\"] # [doc = \" - `cargo run --release --example worklet`\"] # [doc = \" - `cargo run --release --example worklet_message_port`\"] # [doc = \" - `cargo run --release --example worklet_bitcrusher`\"] # [doc = \"\"] pub struct AudioWorkletNode { registration : AudioContextRegistration , channel_config : ChannelConfig , number_of_inputs : usize , number_of_outputs : usize , audio_param_map : HashMap < String , AudioParam > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "# [automatically_derived] impl :: core :: fmt :: Debug for AudioWorkletNode { # [inline] fn fmt (& self , f : & mut :: core :: fmt :: Formatter) -> :: core :: fmt :: Result { :: core :: fmt :: Formatter :: debug_struct_field5_finish (f , \"AudioWorkletNode\" , \"registration\" , & self . registration , \"channel_config\" , & self . channel_config , \"number_of_inputs\" , & self . number_of_inputs , \"number_of_outputs\" , & self . number_of_outputs , \"audio_param_map\" , & & self . audio_param_map) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioNode for AudioWorkletNode { fn registration (& self) -> & AudioContextRegistration { & self . registration } fn channel_config (& self) -> & ChannelConfig { & self . channel_config } fn number_of_inputs (& self) -> usize { self . number_of_inputs } fn number_of_outputs (& self) -> usize { self . number_of_outputs } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl AudioWorkletNode { # [doc = \" Construct a new AudioWorkletNode\"] # [doc = \"\"] # [doc = \" # Panics\"] # [doc = \"\"] # [doc = \" This function panics when\"] # [doc = \" - the number of inputs and the number of outputs of the supplied options are both equal to\"] # [doc = \" zero.\"] # [doc = \" - any of the output channel counts is equal to zero or larger than 32 ([`MAX_CHANNELS`])\"] pub fn new < P : AudioWorkletProcessor + 'static > (context : & impl BaseAudioContext , options : AudioWorkletNodeOptions < P :: ProcessorOptions >) -> Self { let AudioWorkletNodeOptions { number_of_inputs , number_of_outputs , output_channel_count , parameter_data , processor_options , audio_node_options : channel_config } = options ; if ! (number_of_inputs != 0 || number_of_outputs != 0) { { :: core :: panicking :: panic_fmt (format_args ! (\"NotSupportedError: number of inputs and outputs cannot both be zero\")) ; } } ; let output_channel_count = if output_channel_count . is_empty () { if number_of_inputs == 1 && number_of_outputs == 1 { :: alloc :: vec :: Vec :: new () } else { :: alloc :: vec :: from_elem (1 , number_of_outputs) } } else { output_channel_count . iter () . copied () . for_each (crate :: assert_valid_number_of_channels) ; match (& output_channel_count . len () , & number_of_outputs) { (left_val , right_val) => { if ! (* left_val == * right_val) { let kind = :: core :: panicking :: AssertKind :: Eq ; :: core :: panicking :: assert_failed (kind , & * left_val , & * right_val , :: core :: option :: Option :: Some (format_args ! (\"IndexSizeError: outputChannelCount.length should equal numberOfOutputs\"))) ; } } } ; output_channel_count } ; let number_of_output_channels = if output_channel_count . is_empty () { MAX_CHANNELS } else { output_channel_count . iter () . sum :: < usize > () } ; let node = context . base () . register (move | registration | { let mut node_param_map = HashMap :: new () ; let mut processor_param_map = HashMap :: new () ; for mut param_descriptor in P :: parameter_descriptors () { let name = std :: mem :: take (& mut param_descriptor . name) ; let (param , proc) = context . create_audio_param (param_descriptor , & registration) ; if let Some (value) = parameter_data . get (& name) { param . set_value (* value as f32) ; } node_param_map . insert (name . clone () , param) ; processor_param_map . insert (name , proc) ; } let node = AudioWorkletNode { registration , channel_config : channel_config . into () , number_of_inputs , number_of_outputs , audio_param_map : node_param_map , } ; let render : AudioWorkletRenderer < P > = AudioWorkletRenderer { processor : Processor :: new (processor_options) , audio_param_map : processor_param_map , output_channel_count , inputs_flat : Vec :: with_capacity (number_of_inputs * MAX_CHANNELS) , inputs_grouped : Vec :: with_capacity (number_of_inputs) , outputs_flat : Vec :: with_capacity (number_of_output_channels) , outputs_grouped : Vec :: with_capacity (number_of_outputs) , } ; (node , Box :: new (render)) }) ; node } # [doc = \" Collection of AudioParam objects with associated names of this node\"] # [doc = \"\"] # [doc = \" This map is populated from a list of [`AudioParamDescriptor`]s in the\"] # [doc = \" [`AudioWorkletProcessor`] class constructor at the instantiation.\"] pub fn parameters (& self) -> & HashMap < String , AudioParam > { & self . audio_param_map } # [doc = \" Message port to the processor in the render thread\"] # [doc = \"\"] # [doc = \" Every AudioWorkletNode has an associated port which is the [`MessagePort`]. It is connected\"] # [doc = \" to the port on the corresponding [`AudioWorkletProcessor`] object allowing bidirectional\"] # [doc = \" communication between the AudioWorkletNode and its AudioWorkletProcessor.\"] pub fn port (& self) -> MessagePort < '_ > { MessagePort :: from_node (self) } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "enum Processor < P : AudioWorkletProcessor > { Uninit (Option < P :: ProcessorOptions >) , Init (P) , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < P : AudioWorkletProcessor > Processor < P > { fn new (opts : P :: ProcessorOptions) -> Self { Self :: Uninit (Some (opts)) } fn load (& mut self) -> & mut dyn AudioWorkletProcessor < ProcessorOptions = P :: ProcessorOptions > { if let Processor :: Uninit (opts) = self { * self = Self :: Init (P :: constructor (opts . take () . unwrap ())) ; } match self { Self :: Init (p) => p , Self :: Uninit (_) => :: core :: panicking :: panic (\"internal error: entered unreachable code\") , } } }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "struct AudioWorkletRenderer < P : AudioWorkletProcessor > { processor : Processor < P > , audio_param_map : HashMap < String , AudioParamId > , output_channel_count : Vec < usize > , inputs_flat : Vec < & 'static [f32] > , inputs_grouped : Vec < & 'static [& 'static [f32]] > , outputs_flat : Vec < & 'static mut [f32] > , outputs_grouped : Vec < & 'static mut [& 'static mut [f32]] > , }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "unsafe impl < P : AudioWorkletProcessor > Send for AudioWorkletRenderer < P > { }"
    },
    {
      "meta": {
        "namespace": "web_audio_api::worklet",
        "sources": [
          "Normal"
        ],
        "is_module_public": true
      },
      "item": "impl < P : AudioWorkletProcessor > AudioProcessor for AudioWorkletRenderer < P > { fn process (& mut self , inputs : & [AudioRenderQuantum] , outputs : & mut [AudioRenderQuantum] , params : crate :: render :: AudioParamValues < '_ > , scope : & AudioWorkletGlobalScope) -> bool { let processor = self . processor . load () ; inputs . iter () . flat_map (| input | input . channels ()) . map (| input_channel | input_channel . as_ref ()) . map (| input_channel | unsafe { std :: mem :: transmute (input_channel) }) . for_each (| c | self . inputs_flat . push (c)) ; let mut inputs_flat = & self . inputs_flat [..] ; for input in inputs { let c = input . number_of_channels () ; let (left , right) = inputs_flat . split_at (c) ; let left_static = unsafe { std :: mem :: transmute (left) } ; self . inputs_grouped . push (left_static) ; inputs_flat = right ; } if self . output_channel_count . is_empty () { outputs [0] . set_number_of_channels (inputs [0] . number_of_channels ()) ; } else { outputs . iter_mut () . zip (self . output_channel_count . iter ()) . for_each (| (output , & channel_count) | output . set_number_of_channels (channel_count)) ; } let single_case = [inputs . first () . map (| i | i . number_of_channels ()) . unwrap_or_default ()] ; let output_channel_count = if self . output_channel_count . is_empty () { & single_case [..] } else { & self . output_channel_count [..] } ; outputs . iter_mut () . flat_map (| output | output . channels_mut ()) . map (| output_channel | output_channel . deref_mut ()) . map (| output_channel | unsafe { std :: mem :: transmute (output_channel) }) . for_each (| c | self . outputs_flat . push (c)) ; let mut outputs_flat = & mut self . outputs_flat [..] ; for c in output_channel_count { let (left , right) = outputs_flat . split_at_mut (* c) ; let left_static = unsafe { std :: mem :: transmute (left) } ; self . outputs_grouped . push (left_static) ; outputs_flat = right ; } let param_getter = AudioParamValues { values : params , map : & self . audio_param_map , } ; let tail_time = processor . process (& self . inputs_grouped [..] , & mut self . outputs_grouped [..] , param_getter , scope) ; self . inputs_grouped . clear () ; self . inputs_flat . clear () ; self . outputs_grouped . clear () ; self . outputs_flat . clear () ; tail_time } fn onmessage (& mut self , msg : & mut dyn Any) { self . processor . load () . onmessage (msg) } fn has_side_effects (& self) -> bool { true } }"
    }
  ]
}