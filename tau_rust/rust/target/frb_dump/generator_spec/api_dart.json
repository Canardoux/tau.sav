{
  "namespaced_items": {
    "crate::api::simple": {
      "funcs": [
        {
          "namespace": "crate::api::simple",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "/// Greeting the user.\n/// Calls several trace functions and call a rust program to play sinusoid sounds.\n",
          "func_expr": "Future<String> greet({required String name })",
          "func_impl": "RustLib.instance.api.crateApiSimpleGreet(name: name)",
          "func_params": [
            {
              "is_required": true,
              "type_str": "String",
              "name_str": "name",
              "default_value": ""
            }
          ],
          "func_return_type": "Future<String>",
          "src_lineno_pseudo": 147,
          "return_stream": null
        },
        {
          "namespace": "crate::api::simple",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "/// Initialisation of the tau_core rust library\n",
          "func_expr": "Future<bool> initTauCore()",
          "func_impl": "RustLib.instance.api.crateApiSimpleInitTauCore()",
          "func_params": [],
          "func_return_type": "Future<bool>",
          "src_lineno_pseudo": 79,
          "return_stream": null
        },
        {
          "namespace": "crate::api::simple",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Future<void> rustSetLogLevel({required int level })",
          "func_impl": "RustLib.instance.api.crateApiSimpleRustSetLogLevel(level: level)",
          "func_params": [
            {
              "is_required": true,
              "type_str": "int",
              "name_str": "level",
              "default_value": ""
            }
          ],
          "func_return_type": "Future<void>",
          "src_lineno_pseudo": 144,
          "return_stream": null
        },
        {
          "namespace": "crate::api::simple",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Stream<LogEntry> traceLogger()",
          "func_impl": "RustLib.instance.api.crateApiSimpleTraceLogger()",
          "func_params": [],
          "func_return_type": "Stream<LogEntry>",
          "src_lineno_pseudo": 55,
          "return_stream": {
            "field": {
              "ty": {
                "type": "Delegate",
                "safe_ident": "StreamSink_log_entry_Sse",
                "data": {
                  "StreamSink": {
                    "inner_ok": {
                      "type": "StructRef",
                      "safe_ident": "log_entry",
                      "data": {
                        "ident": "crate::api::simple/LogEntry",
                        "is_exception": false
                      }
                    },
                    "inner_err": {
                      "type": "Delegate",
                      "safe_ident": "AnyhowException",
                      "data": "AnyhowException"
                    },
                    "codec": "Sse"
                  }
                }
              },
              "name": {
                "rust_style": "sink",
                "dart_style": null
              },
              "is_final": true,
              "is_rust_public": null,
              "comments": [],
              "default": null,
              "settings": {
                "is_in_mirrored_enum": false
              }
            },
            "ty": {
              "inner_ok": {
                "type": "StructRef",
                "safe_ident": "log_entry",
                "data": {
                  "ident": "crate::api::simple/LogEntry",
                  "is_exception": false
                }
              },
              "inner_err": {
                "type": "Delegate",
                "safe_ident": "AnyhowException",
                "data": "AnyhowException"
              },
              "codec": "Sse"
            }
          }
        }
      ],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::api::simple",
          "class_name": "Level",
          "code": "enum Level {\n                    error,\nwarn,\ninfo,\ndebug,\ntrace,\n                    ;\n                    \n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::api::simple",
          "class_name": "LogEntry",
          "code": "class LogEntry  {\n                final int timeMillis;\nfinal String msg;\nfinal Level logLevel;\nfinal String lbl;\n\n                const LogEntry({required this.timeMillis ,required this.msg ,required this.logLevel ,required this.lbl ,});\n\n                \n                \n\n                \n        @override\n        int get hashCode => timeMillis.hashCode^msg.hashCode^logLevel.hashCode^lbl.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is LogEntry &&\n                runtimeType == other.runtimeType\n                && timeMillis == other.timeMillis&& msg == other.msg&& logLevel == other.logLevel&& lbl == other.lbl;\n        \n            }",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [],
      "imports": {
        "file_top": "",
        "import": "",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "crate::api::simple/send",
          "reason": "IgnoreBecauseNotDefinedTrait"
        }
      ],
      "needs_freezed": false
    },
    "crate::api::override_web_audio_api": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "AnalyserNodeExt",
          "code": "\n                abstract class AnalyserNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "AudioBufferSourceNodeExt",
          "code": "\n                abstract class AudioBufferSourceNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "AudioBufferSourceNodeScheduledSourceNodeMiscExt",
          "code": "\n                abstract class AudioBufferSourceNodeScheduledSourceNodeMiscExt {\n                     Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport 'media_element.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport 'media_element.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "AudioContextExt",
          "code": "\n                abstract class AudioContextExt {\n                     Future<MediaElementAudioSourceNode>  createMediaElementSource({required MyMediaElement mediaElement });\n\n\n Future<AudioBuffer>  decodeAudioDataSync({required String inputPath });\n\n\n Future<void>  setOnStateChange({required FutureOr<void> Function(Event) callback });\n\n\n Future<void>  setSinkId({required String sinkId });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "AudioDestinationNodeExt",
          "code": "\n                abstract class AudioDestinationNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "AudioParamExt",
          "code": "\n                abstract class AudioParamExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "BiquadFilterNodeExt",
          "code": "\n                abstract class BiquadFilterNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "ChannelMergerNodeExt",
          "code": "\n                abstract class ChannelMergerNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "ChannelSplitterNodeExt",
          "code": "\n                abstract class ChannelSplitterNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "ConstantSourceNodeExt",
          "code": "\n                abstract class ConstantSourceNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "ConstantSourceNodeScheduledSourceNodeMiscExt",
          "code": "\n                abstract class ConstantSourceNodeScheduledSourceNodeMiscExt {\n                     Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "ConvolverNodeExt",
          "code": "\n                abstract class ConvolverNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "DelayNodeExt",
          "code": "\n                abstract class DelayNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "DynamicsCompressorNodeExt",
          "code": "\n                abstract class DynamicsCompressorNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "EventExt",
          "code": "\n                abstract class EventExt {\n                     String get type;\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "GainNodeExt",
          "code": "\n                abstract class GainNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "IIRFilterNodeExt",
          "code": "\n                abstract class IIRFilterNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "MediaElementAudioSourceNodeExt",
          "code": "\n                abstract class MediaElementAudioSourceNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "MediaStreamAudioDestinationNodeExt",
          "code": "\n                abstract class MediaStreamAudioDestinationNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "MediaStreamAudioSourceNodeExt",
          "code": "\n                abstract class MediaStreamAudioSourceNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/media_streams.dart';\nimport '../third_party/web_audio_api/media_streams.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "MediaStreamExt",
          "code": "\n                abstract class MediaStreamExt {\n                     Future<List<MediaStreamTrack>>  getTracks();\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "MediaStreamTrackAudioSourceNodeExt",
          "code": "\n                abstract class MediaStreamTrackAudioSourceNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "OfflineAudioContextExt",
          "code": "\n                abstract class OfflineAudioContextExt {\n                     Future<void>  setOnComplete({required FutureOr<void> Function(OfflineAudioCompletionEvent) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "OscillatorNodeExt",
          "code": "\n                abstract class OscillatorNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "OscillatorNodeScheduledSourceNodeMiscExt",
          "code": "\n                abstract class OscillatorNodeScheduledSourceNodeMiscExt {\n                     Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "PannerNodeExt",
          "code": "\n                abstract class PannerNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "ScriptProcessorNodeExt",
          "code": "\n                abstract class ScriptProcessorNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "StereoPannerNodeExt",
          "code": "\n                abstract class StereoPannerNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api.dart';\nimport '../third_party/web_audio_api/worklet.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../third_party/web_audio_api/node.dart';\nimport '../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "WaveShaperNodeExt",
          "code": "\n                abstract class WaveShaperNodeExt {\n                     Future<void>  connect({required AudioNode dest });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::api::override_web_audio_api",
          "class_name": "WaveShaperNodeMiscExt",
          "code": "\n                abstract class WaveShaperNodeMiscExt {\n                     Future<Float32List?>  curve();\n\n\n                }\n                ",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [],
      "imports": {
        "file_top": "",
        "import": "",
        "part": ""
      },
      "preamble": "",
      "skips": [],
      "needs_freezed": false
    },
    "crate::api::media_element": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::api::media_element",
          "class_name": "MyMediaElement",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MyMediaElement>>\n                abstract class MyMediaElement implements RustOpaqueInterface {\n                     Future<double>  currentTime();\n\n\n Future<bool>  loop();\n\n\nfactory MyMediaElement({required String file })=>RustLib.instance.api.crateApiMediaElementMyMediaElementNew(file: file);\n\n\n Future<void>  pause();\n\n\n Future<bool>  paused();\n\n\n Future<void>  play();\n\n\n Future<double>  playbackRate();\n\n\n Future<void>  setCurrentTime({required double value });\n\n\n Future<void>  setLoop({required bool value });\n\n\n Future<void>  setPlaybackRate({required double value });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "\n            @sealed class MyMediaElementImpl extends RustOpaque implements MyMediaElement {\n                // Not to be used by end users\n                MyMediaElementImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MyMediaElementImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MyMediaElement,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MyMediaElement,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MyMediaElementPtr,\n                );\n\n                 Future<double>  currentTime()=>RustLib.instance.api.crateApiMediaElementMyMediaElementCurrentTime(that: this, );\n\n\n Future<bool>  loop()=>RustLib.instance.api.crateApiMediaElementMyMediaElementLoop(that: this, );\n\n\n Future<void>  pause()=>RustLib.instance.api.crateApiMediaElementMyMediaElementPause(that: this, );\n\n\n Future<bool>  paused()=>RustLib.instance.api.crateApiMediaElementMyMediaElementPaused(that: this, );\n\n\n Future<void>  play()=>RustLib.instance.api.crateApiMediaElementMyMediaElementPlay(that: this, );\n\n\n Future<double>  playbackRate()=>RustLib.instance.api.crateApiMediaElementMyMediaElementPlaybackRate(that: this, );\n\n\n Future<void>  setCurrentTime({required double value })=>RustLib.instance.api.crateApiMediaElementMyMediaElementSetCurrentTime(that: this, value: value);\n\n\n Future<void>  setLoop({required bool value })=>RustLib.instance.api.crateApiMediaElementMyMediaElementSetLoop(that: this, value: value);\n\n\n Future<void>  setPlaybackRate({required double value })=>RustLib.instance.api.crateApiMediaElementMyMediaElementSetPlaybackRate(that: this, value: value);\n\n\n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "",
        "part": ""
      },
      "preamble": "",
      "skips": [],
      "needs_freezed": false
    },
    "web_audio_api": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioBuffer",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioBuffer>>\n                abstract class AudioBuffer implements RustOpaqueInterface {\n                    /// Duration in seconds of the `AudioBuffer`\n Future<double>  duration();\n\n\n/// Convert raw samples to an AudioBuffer\n///\n/// The outer Vec determine the channels. The inner Vecs should have the same length.\n///\n/// # Panics\n///\n/// This function will panic if:\n/// - the given sample rate is zero\n/// - the given number of channels defined by `samples.len()`is outside the\n///   [1, 32] range, 32 being defined by the MAX_CHANNELS constant.\n/// - any of its items have different lengths\nstatic Future<AudioBuffer>  from({required List<Float32List> samples , required double sampleRate })=>RustLib.instance.api.webAudioApiAudioBufferFrom(samples: samples, sampleRate: sampleRate);\n\n\n/// Return a read-only copy of the underlying data of the channel\n///\n/// # Panics\n///\n/// This function will panic if:\n/// - the given channel number is greater than or equal to the given number of channels.\n Future<void>  getChannelData({required int channelNumber });\n\n\n/// Return a mutable slice of the underlying data of the channel\n///\n/// # Panics\n///\n/// This function will panic if:\n/// - the given channel number is greater than or equal to the given number of channels.\n Future<void>  getChannelDataMut({required int channelNumber });\n\n\n/// Number of samples per channel in this `AudioBuffer`\n Future<int>  length();\n\n\n  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.\n/// Allocate a silent audiobuffer with [`AudioBufferOptions`]\n///\n/// # Panics\n///\n/// This function will panic if:\n/// - the given sample rate is zero\n/// - the given number of channels is outside the [1, 32] range,\n/// 32 being defined by the MAX_CHANNELS constant.\nstatic Future<AudioBuffer>  newInstance({required AudioBufferOptions options })=>RustLib.instance.api.webAudioApiAudioBufferNew(options: options);\n\n\n/// Number of channels in this `AudioBuffer`\n Future<int>  numberOfChannels();\n\n\n/// Sample rate of this `AudioBuffer` in Hertz\n Future<double>  sampleRate();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioListener",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioListener>>\n                abstract class AudioListener implements RustOpaqueInterface {\n                     AudioParam get forwardX;\n\n\n AudioParam get forwardY;\n\n\n AudioParam get forwardZ;\n\n\n AudioParam get positionX;\n\n\n AudioParam get positionY;\n\n\n AudioParam get positionZ;\n\n\n AudioParam get upX;\n\n\n AudioParam get upY;\n\n\n AudioParam get upZ;\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/worklet.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport '../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioParam",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioParam>>\n                abstract class AudioParam implements RustOpaqueInterface, AudioNode, AudioParamExt {\n                    /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate();\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime });\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime });\n\n\n Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n Future<double>  defaultValue();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime });\n\n\n Future<double>  maxValue();\n\n\n Future<double>  minValue();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value });\n\n\n Future<void>  setChannelCount({required int v });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant });\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime });\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration });\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value;\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioProcessingEvent",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioProcessingEvent>>\n                abstract class AudioProcessingEvent implements RustOpaqueInterface {\n                     AudioBuffer get inputBuffer;\n\n\n AudioBuffer get outputBuffer;\n\n\n double get playbackTime;\n\n\n  set inputBuffer(AudioBuffer inputBuffer);\n\n\n  set outputBuffer(AudioBuffer outputBuffer);\n\n\n  set playbackTime(double playbackTime);\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioRenderCapacity",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioRenderCapacity>>\n                abstract class AudioRenderCapacity implements RustOpaqueInterface {\n                    /// Unset the EventHandler for [`AudioRenderCapacityEvent`].\n Future<void>  clearOnupdate();\n\n\n/// Start metric collection and analysis\n Future<void>  start({required AudioRenderCapacityOptions options });\n\n\n/// Stop metric collection and analysis\n Future<void>  stop();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioRenderCapacityEvent",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioRenderCapacityEvent>>\n                abstract class AudioRenderCapacityEvent implements RustOpaqueInterface {\n                     double get averageLoad;\n\n\n Event get event;\n\n\n double get peakLoad;\n\n\n double get timestamp;\n\n\n double get underrunRatio;\n\n\n  set averageLoad(double averageLoad);\n\n\n  set event(Event event);\n\n\n  set peakLoad(double peakLoad);\n\n\n  set timestamp(double timestamp);\n\n\n  set underrunRatio(double underrunRatio);\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "Event",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<Event>>\n                abstract class Event implements RustOpaqueInterface, EventExt {\n                     String get type;\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "OfflineAudioCompletionEvent",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<OfflineAudioCompletionEvent>>\n                abstract class OfflineAudioCompletionEvent implements RustOpaqueInterface {\n                     Event get event;\n\n\n AudioBuffer get renderedBuffer;\n\n\n  set event(Event event);\n\n\n  set renderedBuffer(AudioBuffer renderedBuffer);\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "PeriodicWave",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<PeriodicWave>>\n                abstract class PeriodicWave implements RustOpaqueInterface {\n                    static Future<PeriodicWave>  default_()=>RustLib.instance.api.webAudioApiPeriodicWaveDefault();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioBufferOptions",
          "code": "/// Options for constructing an [`AudioBuffer`]\nclass AudioBufferOptions  {\n                /// The number of channels for the buffer\nfinal int numberOfChannels;\n/// The length in sample frames of the buffer\nfinal int length;\n/// The sample rate in Hz for the buffer\nfinal double sampleRate;\n\n                const AudioBufferOptions({required this.numberOfChannels ,required this.length ,required this.sampleRate ,});\n\n                \n                \n\n                \n        @override\n        int get hashCode => numberOfChannels.hashCode^length.hashCode^sampleRate.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AudioBufferOptions &&\n                runtimeType == other.runtimeType\n                && numberOfChannels == other.numberOfChannels&& length == other.length&& sampleRate == other.sampleRate;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioParamDescriptor",
          "code": "/// Options for constructing an [`AudioParam`]\nclass AudioParamDescriptor  {\n                final String name;\nfinal AutomationRate automationRate;\nfinal double defaultValue;\nfinal double minValue;\nfinal double maxValue;\n\n                const AudioParamDescriptor({required this.name ,required this.automationRate ,required this.defaultValue ,required this.minValue ,required this.maxValue ,});\n\n                \n                \n\n                \n        @override\n        int get hashCode => name.hashCode^automationRate.hashCode^defaultValue.hashCode^minValue.hashCode^maxValue.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AudioParamDescriptor &&\n                runtimeType == other.runtimeType\n                && name == other.name&& automationRate == other.automationRate&& defaultValue == other.defaultValue&& minValue == other.minValue&& maxValue == other.maxValue;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AudioRenderCapacityOptions",
          "code": "/// Options for constructing an `AudioRenderCapacity`\nclass AudioRenderCapacityOptions  {\n                /// An update interval (in seconds) for dispatching [`AudioRenderCapacityEvent`]s\nfinal double updateInterval;\n\n                const AudioRenderCapacityOptions({required this.updateInterval ,});\n\n                static Future<AudioRenderCapacityOptions>  default_()=>RustLib.instance.api.webAudioApiAudioRenderCapacityOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => updateInterval.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AudioRenderCapacityOptions &&\n                runtimeType == other.runtimeType\n                && updateInterval == other.updateInterval;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "AutomationRate",
          "code": "/// Precision of AudioParam value calculation per render quantum\nenum AutomationRate {\n                    /// Audio Rate - sampled for each sample-frame of the block\na,\n/// Control Rate - sampled at the time of the very first sample-frame,\n/// then used for the entire block\nk,\n                    ;\n                    \n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api",
          "class_name": "PeriodicWaveOptions",
          "code": "/// Options for constructing a [`PeriodicWave`]\nclass PeriodicWaveOptions  {\n                /// The real parameter represents an array of cosine terms of Fourier series.\n///\n/// The first element (index 0) represents the DC-offset.\n/// This offset has to be given but will not be taken into account\n/// to build the custom periodic waveform.\n///\n/// The following elements (index 1 and more) represent the fundamental and\n/// harmonics of the periodic waveform.\nfinal Float32List? real;\n/// The imag parameter represents an array of sine terms of Fourier series.\n///\n/// The first element (index 0) will not be taken into account\n/// to build the custom periodic waveform.\n///\n/// The following elements (index 1 and more) represent the fundamental and\n/// harmonics of the periodic waveform.\nfinal Float32List? imag;\n/// By default PeriodicWave is build with normalization enabled (disable_normalization = false).\n/// In this case, a peak normalization is applied to the given custom periodic waveform.\n///\n/// If disable_normalization is enabled (disable_normalization = true), the normalization is\n/// defined by the periodic waveform characteristics (img, and real fields).\nfinal bool disableNormalization;\n\n                const PeriodicWaveOptions({this.real ,this.imag ,required this.disableNormalization ,});\n\n                static Future<PeriodicWaveOptions>  default_()=>RustLib.instance.api.webAudioApiPeriodicWaveOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => real.hashCode^imag.hashCode^disableNormalization.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is PeriodicWaveOptions &&\n                runtimeType == other.runtimeType\n                && real == other.real&& imag == other.imag&& disableNormalization == other.disableNormalization;\n        \n            }",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "class AudioParamProxyVariantAudioBufferSourceNodeDetune with SimpleDisposable implements AudioParam {\n            final AudioBufferSourceNode _upstream;\n\n            AudioParamProxyVariantAudioBufferSourceNodeDetune(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioBufferSourceNodePlaybackRate with SimpleDisposable implements AudioParam {\n            final AudioBufferSourceNode _upstream;\n\n            AudioParamProxyVariantAudioBufferSourceNodePlaybackRate(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerForwardX with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerForwardX(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerForwardY with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerForwardY(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerForwardZ with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerForwardZ(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerPositionX with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerPositionX(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerPositionY with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerPositionY(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerPositionZ with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerPositionZ(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerUpX with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerUpX(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerUpY with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerUpY(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantAudioListenerUpZ with SimpleDisposable implements AudioParam {\n            final AudioListener _upstream;\n\n            AudioParamProxyVariantAudioListenerUpZ(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantBiquadFilterNodeDetune with SimpleDisposable implements AudioParam {\n            final BiquadFilterNode _upstream;\n\n            AudioParamProxyVariantBiquadFilterNodeDetune(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantBiquadFilterNodeFrequency with SimpleDisposable implements AudioParam {\n            final BiquadFilterNode _upstream;\n\n            AudioParamProxyVariantBiquadFilterNodeFrequency(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantBiquadFilterNodeGain with SimpleDisposable implements AudioParam {\n            final BiquadFilterNode _upstream;\n\n            AudioParamProxyVariantBiquadFilterNodeGain(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantBiquadFilterNodeQ with SimpleDisposable implements AudioParam {\n            final BiquadFilterNode _upstream;\n\n            AudioParamProxyVariantBiquadFilterNodeQ(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantConstantSourceNodeOffset with SimpleDisposable implements AudioParam {\n            final ConstantSourceNode _upstream;\n\n            AudioParamProxyVariantConstantSourceNodeOffset(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantDelayNodeDelayTime with SimpleDisposable implements AudioParam {\n            final DelayNode _upstream;\n\n            AudioParamProxyVariantDelayNodeDelayTime(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantDynamicsCompressorNodeAttack with SimpleDisposable implements AudioParam {\n            final DynamicsCompressorNode _upstream;\n\n            AudioParamProxyVariantDynamicsCompressorNodeAttack(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantDynamicsCompressorNodeKnee with SimpleDisposable implements AudioParam {\n            final DynamicsCompressorNode _upstream;\n\n            AudioParamProxyVariantDynamicsCompressorNodeKnee(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantDynamicsCompressorNodeRatio with SimpleDisposable implements AudioParam {\n            final DynamicsCompressorNode _upstream;\n\n            AudioParamProxyVariantDynamicsCompressorNodeRatio(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantDynamicsCompressorNodeRelease with SimpleDisposable implements AudioParam {\n            final DynamicsCompressorNode _upstream;\n\n            AudioParamProxyVariantDynamicsCompressorNodeRelease(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantDynamicsCompressorNodeThreshold with SimpleDisposable implements AudioParam {\n            final DynamicsCompressorNode _upstream;\n\n            AudioParamProxyVariantDynamicsCompressorNodeThreshold(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantGainNodeGain with SimpleDisposable implements AudioParam {\n            final GainNode _upstream;\n\n            AudioParamProxyVariantGainNodeGain(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantOscillatorNodeDetune with SimpleDisposable implements AudioParam {\n            final OscillatorNode _upstream;\n\n            AudioParamProxyVariantOscillatorNodeDetune(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantOscillatorNodeFrequency with SimpleDisposable implements AudioParam {\n            final OscillatorNode _upstream;\n\n            AudioParamProxyVariantOscillatorNodeFrequency(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantPannerNodeOrientationX with SimpleDisposable implements AudioParam {\n            final PannerNode _upstream;\n\n            AudioParamProxyVariantPannerNodeOrientationX(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantPannerNodeOrientationY with SimpleDisposable implements AudioParam {\n            final PannerNode _upstream;\n\n            AudioParamProxyVariantPannerNodeOrientationY(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantPannerNodeOrientationZ with SimpleDisposable implements AudioParam {\n            final PannerNode _upstream;\n\n            AudioParamProxyVariantPannerNodeOrientationZ(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantPannerNodePositionX with SimpleDisposable implements AudioParam {\n            final PannerNode _upstream;\n\n            AudioParamProxyVariantPannerNodePositionX(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantPannerNodePositionY with SimpleDisposable implements AudioParam {\n            final PannerNode _upstream;\n\n            AudioParamProxyVariantPannerNodePositionY(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantPannerNodePositionZ with SimpleDisposable implements AudioParam {\n            final PannerNode _upstream;\n\n            AudioParamProxyVariantPannerNodePositionZ(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "class AudioParamProxyVariantStereoPannerNodePan with SimpleDisposable implements AudioParam {\n            final StereoPannerNode _upstream;\n\n            AudioParamProxyVariantStereoPannerNodePan(this._upstream);\n\n            /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n        }",
        "\n            @sealed class AudioBufferImpl extends RustOpaque implements AudioBuffer {\n                // Not to be used by end users\n                AudioBufferImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioBufferImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioBuffer,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioBuffer,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioBufferPtr,\n                );\n\n                /// Duration in seconds of the `AudioBuffer`\n Future<double>  duration()=>RustLib.instance.api.webAudioApiAudioBufferDuration(that: this, );\n\n\n/// Return a read-only copy of the underlying data of the channel\n///\n/// # Panics\n///\n/// This function will panic if:\n/// - the given channel number is greater than or equal to the given number of channels.\n Future<void>  getChannelData({required int channelNumber })=>RustLib.instance.api.webAudioApiAudioBufferGetChannelData(that: this, channelNumber: channelNumber);\n\n\n/// Return a mutable slice of the underlying data of the channel\n///\n/// # Panics\n///\n/// This function will panic if:\n/// - the given channel number is greater than or equal to the given number of channels.\n Future<void>  getChannelDataMut({required int channelNumber })=>RustLib.instance.api.webAudioApiAudioBufferGetChannelDataMut(that: this, channelNumber: channelNumber);\n\n\n/// Number of samples per channel in this `AudioBuffer`\n Future<int>  length()=>RustLib.instance.api.webAudioApiAudioBufferLength(that: this, );\n\n\n/// Number of channels in this `AudioBuffer`\n Future<int>  numberOfChannels()=>RustLib.instance.api.webAudioApiAudioBufferNumberOfChannels(that: this, );\n\n\n/// Sample rate of this `AudioBuffer` in Hertz\n Future<double>  sampleRate()=>RustLib.instance.api.webAudioApiAudioBufferSampleRate(that: this, );\n\n\n            }",
        "\n            @sealed class AudioListenerImpl extends RustOpaque implements AudioListener {\n                // Not to be used by end users\n                AudioListenerImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioListenerImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioListener,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioListener,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioListenerPtr,\n                );\n\n                 AudioParam get forwardX=>AudioParamProxyVariantAudioListenerForwardX(this);\n\n\n AudioParam get forwardY=>AudioParamProxyVariantAudioListenerForwardY(this);\n\n\n AudioParam get forwardZ=>AudioParamProxyVariantAudioListenerForwardZ(this);\n\n\n AudioParam get positionX=>AudioParamProxyVariantAudioListenerPositionX(this);\n\n\n AudioParam get positionY=>AudioParamProxyVariantAudioListenerPositionY(this);\n\n\n AudioParam get positionZ=>AudioParamProxyVariantAudioListenerPositionZ(this);\n\n\n AudioParam get upX=>AudioParamProxyVariantAudioListenerUpX(this);\n\n\n AudioParam get upY=>AudioParamProxyVariantAudioListenerUpY(this);\n\n\n AudioParam get upZ=>AudioParamProxyVariantAudioListenerUpZ(this);\n\n\n            }",
        "\n            @sealed class AudioParamImpl extends RustOpaque implements AudioParam {\n                // Not to be used by end users\n                AudioParamImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioParamImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioParam,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioParam,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioParamPtr,\n                );\n\n                /// Current value of the automation rate of the AudioParam\n Future<AutomationRate>  automationRate()=>RustLib.instance.api.webAudioApiAudioParamAutomationRate(that: this, );\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time` and the automation value that would have happened at\n/// that time is then propagated for all future time.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelAndHoldAtTime({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelAndHoldAtTime(that: this, cancelTime: cancelTime);\n\n\n/// Cancels all scheduled parameter changes with times greater than or equal\n/// to `cancel_time`.\n///\n/// # Panics\n///\n/// Will panic if `cancel_time` is negative\n Future<void>  cancelScheduledValues({required double cancelTime })=>RustLib.instance.api.webAudioApiAudioParamCancelScheduledValues(that: this, cancelTime: cancelTime);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiAudioParamChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiAudioParamChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiAudioParamChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiAudioParamChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiAudioParamClearOnprocessorerror(that: this, );\n\n\n Future<double>  defaultValue()=>RustLib.instance.api.webAudioApiAudioParamDefaultValue(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiAudioParamDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiAudioParamDisconnectOutput(that: this, output: output);\n\n\n/// Schedules an exponential continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` is zero\n/// - `end_time` is negative\n Future<void>  exponentialRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamExponentialRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiAudioParamFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Schedules a linear continuous change in parameter value from the\n/// previous scheduled parameter value to the given value.\n///\n/// # Panics\n///\n/// Will panic if `end_time` is negative\n Future<void>  linearRampToValueAtTime({required double value , required double endTime })=>RustLib.instance.api.webAudioApiAudioParamLinearRampToValueAtTime(that: this, value: value, endTime: endTime);\n\n\n Future<double>  maxValue()=>RustLib.instance.api.webAudioApiAudioParamMaxValue(that: this, );\n\n\n Future<double>  minValue()=>RustLib.instance.api.webAudioApiAudioParamMinValue(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiAudioParamNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiAudioParamRegistration(that: this, );\n\n\n/// Update the current value of the automation rate of the AudioParam\n///\n/// # Panics\n///\n/// Some nodes have automation rate constraints and may panic when updating the value.\n Future<void>  setAutomationRate({required AutomationRate value })=>RustLib.instance.api.webAudioApiAudioParamSetAutomationRate(that: this, value: value);\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelCountMode(that: this, v: v);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiAudioParamSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiAudioParamSetOnProcessorError(that: this, callback: callback);\n\n\n/// Start exponentially approaching the target value at the given time with\n/// a rate having the given time constant.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `start_time` is negative\n/// - `time_constant` is negative\n Future<void>  setTargetAtTime({required double value , required double startTime , required double timeConstant })=>RustLib.instance.api.webAudioApiAudioParamSetTargetAtTime(that: this, value: value, startTime: startTime, timeConstant: timeConstant);\n\n\n/// Set the value of the `AudioParam`.\n///\n/// Is equivalent to calling the `set_value_at_time` method with the current\n/// AudioContext's currentTime\n  set value(double value)=>RustLib.instance.api.webAudioApiAudioParamSetValue(that: this, value: value);\n\n\n/// Schedules a parameter value change at the given time.\n///\n/// # Panics\n///\n/// Will panic if `start_time` is negative\n Future<void>  setValueAtTime({required double value , required double startTime })=>RustLib.instance.api.webAudioApiAudioParamSetValueAtTime(that: this, value: value, startTime: startTime);\n\n\n/// Sets an array of arbitrary parameter values starting at the given time\n/// for the given duration.\n///\n/// # Panics\n///\n/// Will panic if:\n/// - `value` length is less than 2\n/// - `start_time` is negative\n/// - `duration` is negative or equal to zero\n Future<void>  setValueCurveAtTime({required List<double> values , required double startTime , required double duration })=>RustLib.instance.api.webAudioApiAudioParamSetValueCurveAtTime(that: this, values: values, startTime: startTime, duration: duration);\n\n\n/// Retrieve the current value of the `AudioParam`.\n double get value=>RustLib.instance.api.webAudioApiAudioParamValue(that: this, );\n\n\n            }",
        "\n            @sealed class AudioProcessingEventImpl extends RustOpaque implements AudioProcessingEvent {\n                // Not to be used by end users\n                AudioProcessingEventImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioProcessingEventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioProcessingEvent,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioProcessingEvent,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioProcessingEventPtr,\n                );\n\n                 AudioBuffer get inputBuffer=>RustLib.instance.api.webAudioApiAudioProcessingEventAutoAccessorGetInputBuffer(that: this, );\n\n\n AudioBuffer get outputBuffer=>RustLib.instance.api.webAudioApiAudioProcessingEventAutoAccessorGetOutputBuffer(that: this, );\n\n\n double get playbackTime=>RustLib.instance.api.webAudioApiAudioProcessingEventAutoAccessorGetPlaybackTime(that: this, );\n\n\n  set inputBuffer(AudioBuffer inputBuffer)=>RustLib.instance.api.webAudioApiAudioProcessingEventAutoAccessorSetInputBuffer(that: this, inputBuffer: inputBuffer);\n\n\n  set outputBuffer(AudioBuffer outputBuffer)=>RustLib.instance.api.webAudioApiAudioProcessingEventAutoAccessorSetOutputBuffer(that: this, outputBuffer: outputBuffer);\n\n\n  set playbackTime(double playbackTime)=>RustLib.instance.api.webAudioApiAudioProcessingEventAutoAccessorSetPlaybackTime(that: this, playbackTime: playbackTime);\n\n\n            }",
        "\n            @sealed class AudioRenderCapacityImpl extends RustOpaque implements AudioRenderCapacity {\n                // Not to be used by end users\n                AudioRenderCapacityImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioRenderCapacityImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioRenderCapacity,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioRenderCapacity,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioRenderCapacityPtr,\n                );\n\n                /// Unset the EventHandler for [`AudioRenderCapacityEvent`].\n Future<void>  clearOnupdate()=>RustLib.instance.api.webAudioApiAudioRenderCapacityClearOnupdate(that: this, );\n\n\n/// Start metric collection and analysis\n Future<void>  start({required AudioRenderCapacityOptions options })=>RustLib.instance.api.webAudioApiAudioRenderCapacityStart(that: this, options: options);\n\n\n/// Stop metric collection and analysis\n Future<void>  stop()=>RustLib.instance.api.webAudioApiAudioRenderCapacityStop(that: this, );\n\n\n            }",
        "\n            @sealed class AudioRenderCapacityEventImpl extends RustOpaque implements AudioRenderCapacityEvent {\n                // Not to be used by end users\n                AudioRenderCapacityEventImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioRenderCapacityEventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioRenderCapacityEvent,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioRenderCapacityEvent,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioRenderCapacityEventPtr,\n                );\n\n                 double get averageLoad=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorGetAverageLoad(that: this, );\n\n\n Event get event=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorGetEvent(that: this, );\n\n\n double get peakLoad=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorGetPeakLoad(that: this, );\n\n\n double get timestamp=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorGetTimestamp(that: this, );\n\n\n double get underrunRatio=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorGetUnderrunRatio(that: this, );\n\n\n  set averageLoad(double averageLoad)=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorSetAverageLoad(that: this, averageLoad: averageLoad);\n\n\n  set event(Event event)=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorSetEvent(that: this, event: event);\n\n\n  set peakLoad(double peakLoad)=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorSetPeakLoad(that: this, peakLoad: peakLoad);\n\n\n  set timestamp(double timestamp)=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorSetTimestamp(that: this, timestamp: timestamp);\n\n\n  set underrunRatio(double underrunRatio)=>RustLib.instance.api.webAudioApiAudioRenderCapacityEventAutoAccessorSetUnderrunRatio(that: this, underrunRatio: underrunRatio);\n\n\n            }",
        "\n            @sealed class EventImpl extends RustOpaque implements Event {\n                // Not to be used by end users\n                EventImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                EventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_Event,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_Event,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_EventPtr,\n                );\n\n                 String get type=>RustLib.instance.api.webAudioApiEventType(that: this, );\n\n\n            }",
        "\n            @sealed class OfflineAudioCompletionEventImpl extends RustOpaque implements OfflineAudioCompletionEvent {\n                // Not to be used by end users\n                OfflineAudioCompletionEventImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                OfflineAudioCompletionEventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_OfflineAudioCompletionEvent,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_OfflineAudioCompletionEvent,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_OfflineAudioCompletionEventPtr,\n                );\n\n                 Event get event=>RustLib.instance.api.webAudioApiOfflineAudioCompletionEventAutoAccessorGetEvent(that: this, );\n\n\n AudioBuffer get renderedBuffer=>RustLib.instance.api.webAudioApiOfflineAudioCompletionEventAutoAccessorGetRenderedBuffer(that: this, );\n\n\n  set event(Event event)=>RustLib.instance.api.webAudioApiOfflineAudioCompletionEventAutoAccessorSetEvent(that: this, event: event);\n\n\n  set renderedBuffer(AudioBuffer renderedBuffer)=>RustLib.instance.api.webAudioApiOfflineAudioCompletionEventAutoAccessorSetRenderedBuffer(that: this, renderedBuffer: renderedBuffer);\n\n\n            }",
        "\n            @sealed class PeriodicWaveImpl extends RustOpaque implements PeriodicWave {\n                // Not to be used by end users\n                PeriodicWaveImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                PeriodicWaveImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_PeriodicWave,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_PeriodicWave,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_PeriodicWavePtr,\n                );\n\n                \n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/worklet.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\nimport '../frb_generated.dart';\nimport '../frb_generated.dart';\nimport 'web_audio_api/node.dart';\nimport 'web_audio_api/node.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api/AtomicF32",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api/AtomicF64",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api/ErrorEvent",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api/MediaElement",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api/MessagePort",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api/load",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api/load",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api/new",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api/new",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api/store",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api/store",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        }
      ],
      "needs_freezed": false
    },
    "web_audio_api::worklet": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "import 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::worklet",
          "class_name": "AudioWorkletNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioWorkletNode>>\n                abstract class AudioWorkletNode implements RustOpaqueInterface, AudioNode {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n/// Collection of AudioParam objects with associated names of this node\n///\n/// This map is populated from a list of [`AudioParamDescriptor`]s in the\n/// [`AudioWorkletProcessor`] class constructor at the instantiation.\n Future<void>  parameters();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::worklet",
          "class_name": "AudioWorkletProcessor",
          "code": "\n                abstract class AudioWorkletProcessor {\n                    \n                }\n                ",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "\n            @sealed class AudioWorkletNodeImpl extends RustOpaque implements AudioWorkletNode {\n                // Not to be used by end users\n                AudioWorkletNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioWorkletNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioWorkletNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioWorkletNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioWorkletNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeDisconnectOutput(that: this, output: output);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeNumberOfOutputs(that: this, );\n\n\n/// Collection of AudioParam objects with associated names of this node\n///\n/// This map is populated from a list of [`AudioParamDescriptor`]s in the\n/// [`AudioWorkletProcessor`] class constructor at the instantiation.\n Future<void>  parameters()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeParameters(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiWorkletAudioWorkletNodeSetChannelInterpretation(that: this, v: v);\n\n\n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import 'node.dart';\nimport 'node.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api::worklet/AudioParamValues",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::worklet/AudioWorkletNodeOptions",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::worklet/AudioWorkletRenderer",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::worklet/Processor",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::worklet/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/constructor",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::worklet/default",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api::worklet/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/has_side_effects",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/keys",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api::worklet/new",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::worklet/onmessage",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/onmessage",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::worklet/port",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::worklet/process",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::worklet/process",
          "reason": "IgnoreBecauseFunctionGeneric"
        }
      ],
      "needs_freezed": false
    },
    "crate::api::zozo": {
      "funcs": [
        {
          "namespace": "crate::api::zozo",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Future<int> sum({required int a , required int b })",
          "func_impl": "RustLib.instance.api.crateApiZozoSum(a: a, b: b)",
          "func_params": [
            {
              "is_required": true,
              "type_str": "int",
              "name_str": "a",
              "default_value": ""
            },
            {
              "is_required": true,
              "type_str": "int",
              "name_str": "b",
              "default_value": ""
            }
          ],
          "func_return_type": "Future<int>",
          "src_lineno_pseudo": 355,
          "return_stream": null
        },
        {
          "namespace": "crate::api::zozo",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Future<int> sumLongRunning({required int a , required int b })",
          "func_impl": "RustLib.instance.api.crateApiZozoSumLongRunning(a: a, b: b)",
          "func_params": [
            {
              "is_required": true,
              "type_str": "int",
              "name_str": "a",
              "default_value": ""
            },
            {
              "is_required": true,
              "type_str": "int",
              "name_str": "b",
              "default_value": ""
            }
          ],
          "func_return_type": "Future<int>",
          "src_lineno_pseudo": 357,
          "return_stream": null
        }
      ],
      "classes": [],
      "extra_impl_code": [],
      "imports": {
        "file_top": "",
        "import": "",
        "part": ""
      },
      "preamble": "",
      "skips": [],
      "needs_freezed": false
    },
    "crate::api::mimi": {
      "funcs": [
        {
          "namespace": "crate::api::mimi",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Future<String> mimi()",
          "func_impl": "RustLib.instance.api.crateApiMimiMimi()",
          "func_params": [],
          "func_return_type": "Future<String>",
          "src_lineno_pseudo": 1159,
          "return_stream": null
        }
      ],
      "classes": [],
      "extra_impl_code": [],
      "imports": {
        "file_top": "",
        "import": "",
        "part": ""
      },
      "preamble": "",
      "skips": [],
      "needs_freezed": false
    },
    "web_audio_api::media_devices": {
      "funcs": [
        {
          "namespace": "web_audio_api::media_devices",
          "header": {
            "file_top": "",
            "import": "import 'media_streams.dart';\nimport 'media_streams.dart';\n",
            "part": ""
          },
          "func_comments": "/// Prompt for permission to use a media input (audio only)\n///\n/// This produces a [`MediaStream`] with tracks containing the requested types of media, which can\n/// be used inside a [`MediaStreamAudioSourceNode`](crate::node::MediaStreamAudioSourceNode).\n///\n/// It is okay for the `MediaStream` struct to go out of scope, any corresponding stream will still be\n/// kept alive and emit audio buffers. Call the `close()` method if you want to stop the media\n/// input and release all system resources.\n///\n/// This function operates synchronously, which may be undesirable on the control thread. An async\n/// version is currently not implemented.\n///\n/// # Example\n///\n/// ```no_run\n/// use web_audio_api::context::{BaseAudioContext, AudioContext};\n/// use web_audio_api::context::{AudioContextLatencyCategory, AudioContextOptions};\n/// use web_audio_api::media_devices;\n/// use web_audio_api::media_devices::MediaStreamConstraints;\n/// use web_audio_api::node::AudioNode;\n///\n/// let context = AudioContext::default();\n/// let mic = media_devices::get_user_media_sync(MediaStreamConstraints::Audio);\n///\n/// // register as media element in the audio context\n/// let background = context.create_media_stream_source(&mic);\n///\n/// // connect the node directly to the destination node (speakers)\n/// background.connect(&context.destination());\n///\n/// // enjoy listening\n/// std::thread::sleep(std::time::Duration::from_secs(4));\n/// ```\n",
          "func_expr": "Future<MediaStream> getUserMediaSync({required MediaStreamConstraints constraints })",
          "func_impl": "RustLib.instance.api.webAudioApiMediaDevicesGetUserMediaSync(constraints: constraints)",
          "func_params": [
            {
              "is_required": true,
              "type_str": "MediaStreamConstraints",
              "name_str": "constraints",
              "default_value": ""
            }
          ],
          "func_return_type": "Future<MediaStream>",
          "src_lineno_pseudo": 3408,
          "return_stream": null
        }
      ],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::media_devices",
          "class_name": "MediaStreamConstraints",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamConstraints>>\n                abstract class MediaStreamConstraints implements RustOpaqueInterface {\n                    \n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::media_devices",
          "class_name": "MediaTrackConstraints",
          "code": "/// Desired media stream track settings for [`MediaTrackConstraints`]\nclass MediaTrackConstraints  {\n                final double? sampleRate;\nfinal double? latency;\nfinal int? channelCount;\nfinal String? deviceId;\n\n                const MediaTrackConstraints({this.sampleRate ,this.latency ,this.channelCount ,this.deviceId ,});\n\n                static Future<MediaTrackConstraints>  default_()=>RustLib.instance.api.webAudioApiMediaDevicesMediaTrackConstraintsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => sampleRate.hashCode^latency.hashCode^channelCount.hashCode^deviceId.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is MediaTrackConstraints &&\n                runtimeType == other.runtimeType\n                && sampleRate == other.sampleRate&& latency == other.latency&& channelCount == other.channelCount&& deviceId == other.deviceId;\n        \n            }",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "\n            @sealed class MediaStreamConstraintsImpl extends RustOpaque implements MediaStreamConstraints {\n                // Not to be used by end users\n                MediaStreamConstraintsImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaStreamConstraintsImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaStreamConstraints,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamConstraints,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamConstraintsPtr,\n                );\n\n                \n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import 'media_streams.dart';\nimport 'media_streams.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api::media_devices/DeviceId",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_devices/MediaDeviceInfo",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_devices/MediaDeviceInfoKind",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_devices/assert_receiver_is_total_eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/device_id",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api::media_devices/enumerate_devices_sync",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::media_devices/eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/from",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/group_id",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api::media_devices/hash",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/hash",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_devices/kind",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        },
        {
          "name": "web_audio_api::media_devices/label",
          "reason": "IgnoreBecauseOwnerTyShouldIgnore"
        }
      ],
      "needs_freezed": false
    },
    "web_audio_api::media_streams": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "import 'node.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::media_streams",
          "class_name": "MediaStream",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStream>>\n                abstract class MediaStream implements RustOpaqueInterface, MediaStreamExt {\n                     Future<List<MediaStreamTrack>>  getTracks();\n\n\nstatic Future<MediaStream>  fromTracks({required List<MediaStreamTrack> tracks })=>RustLib.instance.api.webAudioApiMediaStreamsMediaStreamFromTracks(tracks: tracks);\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::media_streams",
          "class_name": "MediaStreamTrack",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamTrack>>\n                abstract class MediaStreamTrack implements RustOpaqueInterface {\n                     Future<void>  close();\n\n\n Future<MediaStreamTrackState>  readyState();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::media_streams",
          "class_name": "MediaStreamTrackState",
          "code": "/// Ready-state of a [`MediaStreamTrack`]\nenum MediaStreamTrackState {\n                    /// The track is active (the track's underlying media source is making a best-effort attempt to\n/// provide data in real time).\nlive,\n/// The track has ended (the track's underlying media source is no longer providing data, and\n/// will never provide more data for this track). Once a track enters this state, it never\n/// exits it.\nended,\n                    ;\n                    \n                }",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "class MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream with SimpleDisposable implements MediaStream {\n            final MediaStreamAudioDestinationNode _upstream;\n\n            MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream(this._upstream);\n\n             Future<List<MediaStreamTrack>>  getTracks()=>RustLib.instance.api.webAudioApiMediaStreamsMediaStreamFrbOverrideGetTracks(that: this, );\n\n\n        }",
        "\n            @sealed class MediaStreamImpl extends RustOpaque implements MediaStream {\n                // Not to be used by end users\n                MediaStreamImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaStreamImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaStream,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStream,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamPtr,\n                );\n\n                 Future<List<MediaStreamTrack>>  getTracks()=>RustLib.instance.api.webAudioApiMediaStreamsMediaStreamFrbOverrideGetTracks(that: this, );\n\n\n            }",
        "\n            @sealed class MediaStreamTrackImpl extends RustOpaque implements MediaStreamTrack {\n                // Not to be used by end users\n                MediaStreamTrackImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaStreamTrackImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaStreamTrack,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamTrack,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamTrackPtr,\n                );\n\n                 Future<void>  close()=>RustLib.instance.api.webAudioApiMediaStreamsMediaStreamTrackClose(that: this, );\n\n\n Future<MediaStreamTrackState>  readyState()=>RustLib.instance.api.webAudioApiMediaStreamsMediaStreamTrackReadyState(that: this, );\n\n\n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import 'node.dart';\nimport '../../frb_generated.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api::media_streams/MediaStreamTrackInner",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_streams/MediaStreamTrackIter",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_streams/assert_receiver_is_total_eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_streams/from_iter",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::media_streams/iter",
          "reason": "Err"
        },
        {
          "name": "web_audio_api::media_streams/next",
          "reason": "IgnoreBecauseNotDefinedTrait"
        }
      ],
      "needs_freezed": false
    },
    "crate::frb_generated": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::frb_generated",
          "class_name": "AudioNodeImplementor",
          "code": "@freezed\n                sealed class AudioNodeImplementor with _$AudioNodeImplementor  {\n                    const AudioNodeImplementor._();\n\n                     const factory AudioNodeImplementor.variant0(  AnalyserNode field0,) = AudioNodeImplementor_Variant0;\n const factory AudioNodeImplementor.variant1(  AudioBufferSourceNode field0,) = AudioNodeImplementor_Variant1;\n const factory AudioNodeImplementor.variant2(  AudioDestinationNode field0,) = AudioNodeImplementor_Variant2;\n const factory AudioNodeImplementor.variant3(  AudioParam field0,) = AudioNodeImplementor_Variant3;\n const factory AudioNodeImplementor.variant4(  AudioWorkletNode field0,) = AudioNodeImplementor_Variant4;\n const factory AudioNodeImplementor.variant5(  BiquadFilterNode field0,) = AudioNodeImplementor_Variant5;\n const factory AudioNodeImplementor.variant6(  ChannelMergerNode field0,) = AudioNodeImplementor_Variant6;\n const factory AudioNodeImplementor.variant7(  ChannelSplitterNode field0,) = AudioNodeImplementor_Variant7;\n const factory AudioNodeImplementor.variant8(  ConstantSourceNode field0,) = AudioNodeImplementor_Variant8;\n const factory AudioNodeImplementor.variant9(  ConvolverNode field0,) = AudioNodeImplementor_Variant9;\n const factory AudioNodeImplementor.variant10(  DelayNode field0,) = AudioNodeImplementor_Variant10;\n const factory AudioNodeImplementor.variant11(  DynamicsCompressorNode field0,) = AudioNodeImplementor_Variant11;\n const factory AudioNodeImplementor.variant12(  GainNode field0,) = AudioNodeImplementor_Variant12;\n const factory AudioNodeImplementor.variant13(  IirFilterNode field0,) = AudioNodeImplementor_Variant13;\n const factory AudioNodeImplementor.variant14(  MediaElementAudioSourceNode field0,) = AudioNodeImplementor_Variant14;\n const factory AudioNodeImplementor.variant15(  MediaStreamAudioDestinationNode field0,) = AudioNodeImplementor_Variant15;\n const factory AudioNodeImplementor.variant16(  MediaStreamAudioSourceNode field0,) = AudioNodeImplementor_Variant16;\n const factory AudioNodeImplementor.variant17(  MediaStreamTrackAudioSourceNode field0,) = AudioNodeImplementor_Variant17;\n const factory AudioNodeImplementor.variant18(  OscillatorNode field0,) = AudioNodeImplementor_Variant18;\n const factory AudioNodeImplementor.variant19(  PannerNode field0,) = AudioNodeImplementor_Variant19;\n const factory AudioNodeImplementor.variant20(  ScriptProcessorNode field0,) = AudioNodeImplementor_Variant20;\n const factory AudioNodeImplementor.variant21(  StereoPannerNode field0,) = AudioNodeImplementor_Variant21;\n const factory AudioNodeImplementor.variant22(  WaveShaperNode field0,) = AudioNodeImplementor_Variant22;\n\n                    \n                }",
          "needs_freezed": true
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::frb_generated",
          "class_name": "Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum",
          "code": "@freezed\n                sealed class Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum with _$Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum  {\n                    const Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum._();\n\n                     const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant0(  AudioBufferSourceNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant0;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant1(  AudioBufferSourceNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant1;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant2(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant2;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant3(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant3;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant4(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant4;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant5(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant5;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant6(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant6;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant7(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant7;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant8(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant8;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant9(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant9;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant10(  AudioListener field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant10;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant11(  BiquadFilterNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant11;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant12(  BiquadFilterNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant12;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant13(  BiquadFilterNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant13;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant14(  BiquadFilterNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant14;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant15(  ConstantSourceNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant15;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant16(  DelayNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant16;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant17(  DynamicsCompressorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant17;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant18(  DynamicsCompressorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant18;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant19(  DynamicsCompressorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant19;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant20(  DynamicsCompressorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant20;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant21(  DynamicsCompressorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant21;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant22(  GainNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant22;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant23(  OscillatorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant23;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant24(  OscillatorNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant24;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant25(  PannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant25;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant26(  PannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant26;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant27(  PannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant27;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant28(  PannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant28;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant29(  PannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant29;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant30(  PannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant30;\n const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum.variant31(  StereoPannerNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerAudioParamProxyEnum_Variant31;\n\n                    \n                }",
          "needs_freezed": true
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "crate::frb_generated",
          "class_name": "Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum",
          "code": "@freezed\n                sealed class Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum with _$Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum  {\n                    const Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum._();\n\n                     const factory Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum.variant0(  MediaStreamAudioDestinationNode field0,) = Auto_Ref_RustOpaque_flutter_rust_bridgefor_generatedRustAutoOpaqueInnerMediaStreamProxyEnum_Variant0;\n\n                    \n                }",
          "needs_freezed": true
        }
      ],
      "extra_impl_code": [],
      "imports": {
        "file_top": "",
        "import": "import 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api.dart';\nimport 'third_party/web_audio_api.dart';\nimport 'third_party/web_audio_api/worklet.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\nimport 'third_party/web_audio_api/node.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [],
      "needs_freezed": true
    },
    "web_audio_api::context": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "import 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'media_streams.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../../frb_generated.dart';\nimport 'node.dart';\nimport 'media_streams.dart';\nimport 'media_streams.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../../api/media_element.dart';\nimport 'node.dart';\nimport '../../api/media_element.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioContext",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioContext>>\n                abstract class AudioContext implements RustOpaqueInterface, AudioContextExt, BaseAudioContext {\n                    /// This represents the number of seconds of processing latency incurred by\n/// the `AudioContext` passing the audio from the `AudioDestinationNode`\n/// to the audio subsystem.\n Future<double>  baseLatency();\n\n\n/// Unset the callback to run when the audio sink has changed\n Future<void>  clearOnsinkchange();\n\n\n/// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange();\n\n\n/// Closes the `AudioContext`, releasing the system resources being used.\n///\n/// This will not automatically release all `AudioContext`-created objects, but will suspend\n/// the progression of the currentTime, and stop processing audio data.\n///\n/// # Panics\n///\n/// Will panic when this function is called multiple times\n Future<void>  close();\n\n\n/// Closes the `AudioContext`, releasing the system resources being used.\n///\n/// This will not automatically release all `AudioContext`-created objects, but will suspend\n/// the progression of the currentTime, and stop processing audio data.\n///\n/// This function operates synchronously and blocks the current thread until the audio thread\n/// has stopped processing.\n///\n/// # Panics\n///\n/// Will panic when this function is called multiple times\n Future<void>  closeSync();\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser();\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest });\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter();\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate });\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource();\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs });\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs });\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource();\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver();\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime });\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor();\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain();\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback });\n\n\n/// Creates a [`MediaStreamAudioDestinationNode`](node::MediaStreamAudioDestinationNode)\n Future<MediaStreamAudioDestinationNode>  createMediaStreamDestination();\n\n\n/// Creates a [`MediaStreamAudioSourceNode`](node::MediaStreamAudioSourceNode) from a\n/// [`MediaStream`]\n Future<MediaStreamAudioSourceNode>  createMediaStreamSource({required MediaStream media });\n\n\n/// Creates a [`MediaStreamTrackAudioSourceNode`](node::MediaStreamTrackAudioSourceNode) from a\n/// [`MediaStreamTrack`]\n Future<MediaStreamTrackAudioSourceNode>  createMediaStreamTrackSource({required MediaStreamTrack media });\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator();\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner();\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options });\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels });\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner();\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper();\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime();\n\n\nstatic Future<AudioContext>  default_()=>RustLib.instance.api.webAudioApiContextAudioContextDefault();\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination();\n\n\n Future<MediaElementAudioSourceNode>  createMediaElementSource({required MyMediaElement mediaElement });\n\n\n Future<AudioBuffer>  decodeAudioDataSync({required String inputPath });\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener();\n\n\n/// Creates and returns a new `AudioContext` object.\n///\n/// This will play live audio on the default output device.\n///\n/// ```no_run\n/// use web_audio_api::context::{AudioContext, AudioContextOptions};\n///\n/// // Request a sample rate of 44.1 kHz and default latency (buffer size 128, if available)\n/// let opts = AudioContextOptions {\n///     sample_rate: Some(44100.),\n///     ..AudioContextOptions::default()\n/// };\n///\n/// // Setup the audio context that will emit to your speakers\n/// let context = AudioContext::new(opts);\n///\n/// // Alternatively, use the default constructor to get the best settings for your hardware\n/// // let context = AudioContext::default();\n/// ```\n///\n/// # Panics\n///\n/// The `AudioContext` constructor will panic when an invalid `sinkId` is provided in the\n/// `AudioContextOptions`. In a future version, a `try_new` constructor will be introduced that\n/// never panics.\nfactory AudioContext({required AudioContextOptions options })=>RustLib.instance.api.webAudioApiContextAudioContextNew(options: options);\n\n\n/// The estimation in seconds of audio output latency, i.e., the interval\n/// between the time the UA requests the host system to play a buffer and\n/// the time at which the first sample in the buffer is actually processed\n/// by the audio output device.\n Future<double>  outputLatency();\n\n\n/// Returns an [`AudioRenderCapacity`] instance associated with an AudioContext.\n Future<AudioRenderCapacity>  renderCapacity();\n\n\n/// Resumes the progression of time in an audio context that has previously been\n/// suspended/paused.\n///\n/// This function operates synchronously and blocks the current thread until the audio thread\n/// has started processing again.\n///\n/// # Panics\n///\n/// Will panic if:\n///\n/// * The audio device is not available\n/// * For a `BackendSpecificError`\n Future<void>  resumeSync();\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate();\n\n\n Future<void>  setOnStateChange({required FutureOr<void> Function(Event) callback });\n\n\n Future<void>  setSinkId({required String sinkId });\n\n\n/// Identifier or the information of the current audio output device.\n///\n/// The initial value is `\"\"`, which means the default audio output device.\n Future<String>  sinkId();\n\n\n/// Returns state of current context\n Future<AudioContextState>  state();\n\n\n/// Suspends the progression of time in the audio context.\n///\n/// This will temporarily halt audio hardware access and reducing CPU/battery usage in the\n/// process.\n///\n/// # Panics\n///\n/// Will panic if:\n///\n/// * The audio device is not available\n/// * For a `BackendSpecificError`\n Future<void>  suspend();\n\n\n/// Suspends the progression of time in the audio context.\n///\n/// This will temporarily halt audio hardware access and reducing CPU/battery usage in the\n/// process.\n///\n/// This function operates synchronously and blocks the current thread until the audio thread\n/// has stopped processing.\n///\n/// # Panics\n///\n/// Will panic if:\n///\n/// * The audio device is not available\n/// * For a `BackendSpecificError`\n Future<void>  suspendSync();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioContextRegistration",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioContextRegistration>>\n                abstract class AudioContextRegistration implements RustOpaqueInterface {\n                    \n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioParamId",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioParamId>>\n                abstract class AudioParamId implements RustOpaqueInterface {\n                    \n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "ConcreteBaseAudioContext",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ConcreteBaseAudioContext>>\n                abstract class ConcreteBaseAudioContext implements RustOpaqueInterface, BaseAudioContext {\n                    /// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange();\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser();\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest });\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter();\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate });\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource();\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs });\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs });\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource();\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver();\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime });\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor();\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain();\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback });\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator();\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner();\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options });\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels });\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner();\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper();\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime();\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination();\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener();\n\n\n/// Inform render thread that this node can act as a cycle breaker\n Future<void>  markCycleBreaker({required AudioContextRegistration reg });\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate();\n\n\n/// Returns state of current context\n Future<AudioContextState>  state();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "OfflineAudioContext",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<OfflineAudioContext>>\n                abstract class OfflineAudioContext implements RustOpaqueInterface, BaseAudioContext, OfflineAudioContextExt {\n                    /// Unset the callback to run when the rendering has completed\n Future<void>  clearOncomplete();\n\n\n/// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange();\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser();\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest });\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter();\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate });\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource();\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs });\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs });\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource();\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver();\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime });\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor();\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain();\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback });\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator();\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner();\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options });\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels });\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner();\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper();\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime();\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination();\n\n\n/// get the length of rendering audio buffer\n Future<int>  length();\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener();\n\n\n  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.\n/// Creates an `OfflineAudioContext` instance\n///\n/// # Arguments\n///\n/// * `channels` - number of output channels to render\n/// * `length` - length of the rendering audio buffer\n/// * `sample_rate` - output sample rate\nstatic Future<OfflineAudioContext>  newInstance({required int numberOfChannels , required int length , required double sampleRate })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextNew(numberOfChannels: numberOfChannels, length: length, sampleRate: sampleRate);\n\n\n/// Resumes the progression of the OfflineAudioContext's currentTime when it has been suspended\n///\n/// # Panics\n///\n/// Panics when the context is closed or rendering has not started\n Future<void>  resume();\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate();\n\n\n Future<void>  setOnComplete({required FutureOr<void> Function(OfflineAudioCompletionEvent) callback });\n\n\n/// Given the current connections and scheduled changes, starts rendering audio.\n///\n/// Rendering is purely CPU bound and contains no `await` points, so calling this method will\n/// block the executor until completion or until the context is suspended.\n///\n/// This method will only adhere to scheduled suspensions via [`Self::suspend`] and will\n/// ignore those provided via [`Self::suspend_sync`].\n///\n/// # Panics\n///\n/// Panics if this method is called multiple times.\n Future<AudioBuffer>  startRendering();\n\n\n/// Given the current connections and scheduled changes, starts rendering audio.\n///\n/// This function will block the current thread and returns the rendered `AudioBuffer`\n/// synchronously.\n///\n/// This method will only adhere to scheduled suspensions via [`Self::suspend_sync`] and\n/// will ignore those provided via [`Self::suspend`].\n///\n/// # Panics\n///\n/// Panics if this method is called multiple times\n Future<AudioBuffer>  startRenderingSync();\n\n\n/// Returns state of current context\n Future<AudioContextState>  state();\n\n\n/// Schedules a suspension of the time progression in the audio context at the specified time\n/// and returns a promise\n///\n/// The specified time is quantized and rounded up to the render quantum size.\n///\n/// # Panics\n///\n/// Panics if the quantized frame number\n///\n/// - is negative or\n/// - is less than or equal to the current time or\n/// - is greater than or equal to the total render duration or\n/// - is scheduled by another suspend for the same time\n///\n/// # Example usage\n///\n/// ```rust\n/// use futures::{executor, join};\n/// use futures::FutureExt as _;\n/// use std::sync::Arc;\n///\n/// use web_audio_api::context::BaseAudioContext;\n/// use web_audio_api::context::OfflineAudioContext;\n/// use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\n///\n/// let context = Arc::new(OfflineAudioContext::new(1, 512, 44_100.));\n/// let context_clone = Arc::clone(&context);\n///\n/// let suspend_promise = context.suspend(128. / 44_100.).then(|_| async move {\n///     let mut src = context_clone.create_constant_source();\n///     src.connect(&context_clone.destination());\n///     src.start();\n///     context_clone.resume().await;\n/// });\n///\n/// let render_promise = context.start_rendering();\n///\n/// let buffer = executor::block_on(async move { join!(suspend_promise, render_promise).1 });\n/// assert_eq!(buffer.number_of_channels(), 1);\n/// assert_eq!(buffer.length(), 512);\n/// ```\n Future<void>  suspend({required double suspendTime });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "BaseAudioContext",
          "code": "\n                abstract class BaseAudioContext {\n                    /// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange();\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser();\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest });\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter();\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate });\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource();\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs });\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs });\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource();\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver();\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime });\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor();\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain();\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback });\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator();\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner();\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options });\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels });\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner();\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper();\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime();\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination();\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener();\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate();\n\n\n/// Returns state of current context\n Future<AudioContextState>  state();\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioContextLatencyCategory",
          "code": "@freezed\n                sealed class AudioContextLatencyCategory with _$AudioContextLatencyCategory  {\n                    const AudioContextLatencyCategory._();\n\n                     /// Balance audio output latency and power consumption.\nconst factory AudioContextLatencyCategory.balanced() = AudioContextLatencyCategory_Balanced;\n /// Provide the lowest audio output latency possible without glitching. This is the default.\nconst factory AudioContextLatencyCategory.interactive() = AudioContextLatencyCategory_Interactive;\n /// Prioritize sustained playback without interruption over audio output latency.\n///\n/// Lowest power consumption.\nconst factory AudioContextLatencyCategory.playback() = AudioContextLatencyCategory_Playback;\n /// Specify the number of seconds of latency\n///\n/// This latency is not guaranteed to be applied, it depends on the audio hardware capabilities\nconst factory AudioContextLatencyCategory.custom(  double field0,) = AudioContextLatencyCategory_Custom;\n\n                    static Future<AudioContextLatencyCategory>  default_()=>RustLib.instance.api.webAudioApiContextAudioContextLatencyCategoryDefault();\n\n\n                }",
          "needs_freezed": true
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioContextOptions",
          "code": "/// Specify the playback configuration for the [`AudioContext`] constructor.\n///\n/// All fields are optional and will default to the value best suited for interactive playback on\n/// your hardware configuration.\n///\n/// For future compatibility, it is best to construct a default implementation of this struct and\n/// set the fields you would like to override:\n/// ```\n/// use web_audio_api::context::AudioContextOptions;\n///\n/// // Request a sample rate of 44.1 kHz, leave other fields to their default values\n/// let opts = AudioContextOptions {\n///     sample_rate: Some(44100.),\n///     ..AudioContextOptions::default()\n/// };\nclass AudioContextOptions  {\n                /// Identify the type of playback, which affects tradeoffs between audio output latency and\n/// power consumption.\nfinal AudioContextLatencyCategory latencyHint;\n/// Sample rate of the audio context and audio output hardware. Use `None` for a default value.\nfinal double? sampleRate;\n/// The audio output device\n/// - use `\"\"` for the default audio output device\n/// - use `\"none\"` to process the audio graph without playing through an audio output device.\n/// - use `\"sinkId\"` to use the specified audio sink id, obtained with [`enumerate_devices_sync`]\nfinal String sinkId;\n/// Option to request a default, optimized or specific render quantum size. It is a hint that might not be honored.\nfinal AudioContextRenderSizeCategory renderSizeHint;\n\n                const AudioContextOptions({required this.latencyHint ,this.sampleRate ,required this.sinkId ,required this.renderSizeHint ,});\n\n                static Future<AudioContextOptions>  default_()=>RustLib.instance.api.webAudioApiContextAudioContextOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => latencyHint.hashCode^sampleRate.hashCode^sinkId.hashCode^renderSizeHint.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AudioContextOptions &&\n                runtimeType == other.runtimeType\n                && latencyHint == other.latencyHint&& sampleRate == other.sampleRate&& sinkId == other.sinkId&& renderSizeHint == other.renderSizeHint;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioContextRenderSizeCategory",
          "code": "/// This allows users to ask for a particular render quantum size.\n///\n/// Currently, only the default value is available\nenum AudioContextRenderSizeCategory {\n                    /// The default value of 128 frames\ndefault_,\n                    ;\n                    static Future<AudioContextRenderSizeCategory>  default_()=>RustLib.instance.api.webAudioApiContextAudioContextRenderSizeCategoryDefault();\n\n\n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::context",
          "class_name": "AudioContextState",
          "code": "/// Describes the current state of the `AudioContext`\nenum AudioContextState {\n                    /// This context is currently suspended (context time is not proceeding,\n/// audio hardware may be powered down/released).\nsuspended,\n/// Audio is being processed.\nrunning,\n/// This context has been released, and can no longer be used to process audio.\n/// All system audio resources have been released.\nclosed,\n                    ;\n                    \n                }",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "\n            @sealed class AudioContextImpl extends RustOpaque implements AudioContext {\n                // Not to be used by end users\n                AudioContextImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioContextImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioContext,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioContext,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioContextPtr,\n                );\n\n                /// This represents the number of seconds of processing latency incurred by\n/// the `AudioContext` passing the audio from the `AudioDestinationNode`\n/// to the audio subsystem.\n Future<double>  baseLatency()=>RustLib.instance.api.webAudioApiContextAudioContextBaseLatency(that: this, );\n\n\n/// Unset the callback to run when the audio sink has changed\n Future<void>  clearOnsinkchange()=>RustLib.instance.api.webAudioApiContextAudioContextClearOnsinkchange(that: this, );\n\n\n/// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange()=>RustLib.instance.api.webAudioApiContextAudioContextClearOnstatechange(that: this, );\n\n\n/// Closes the `AudioContext`, releasing the system resources being used.\n///\n/// This will not automatically release all `AudioContext`-created objects, but will suspend\n/// the progression of the currentTime, and stop processing audio data.\n///\n/// # Panics\n///\n/// Will panic when this function is called multiple times\n Future<void>  close()=>RustLib.instance.api.webAudioApiContextAudioContextClose(that: this, );\n\n\n/// Closes the `AudioContext`, releasing the system resources being used.\n///\n/// This will not automatically release all `AudioContext`-created objects, but will suspend\n/// the progression of the currentTime, and stop processing audio data.\n///\n/// This function operates synchronously and blocks the current thread until the audio thread\n/// has stopped processing.\n///\n/// # Panics\n///\n/// Will panic when this function is called multiple times\n Future<void>  closeSync()=>RustLib.instance.api.webAudioApiContextAudioContextCloseSync(that: this, );\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser()=>RustLib.instance.api.webAudioApiContextAudioContextCreateAnalyser(that: this, );\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest })=>RustLib.instance.api.webAudioApiContextAudioContextCreateAudioParam(that: this, opts: opts, dest: dest);\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter()=>RustLib.instance.api.webAudioApiContextAudioContextCreateBiquadFilter(that: this, );\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate })=>RustLib.instance.api.webAudioApiContextAudioContextCreateBuffer(that: this, numberOfChannels: numberOfChannels, length: length, sampleRate: sampleRate);\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource()=>RustLib.instance.api.webAudioApiContextAudioContextCreateBufferSource(that: this, );\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs })=>RustLib.instance.api.webAudioApiContextAudioContextCreateChannelMerger(that: this, numberOfInputs: numberOfInputs);\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs })=>RustLib.instance.api.webAudioApiContextAudioContextCreateChannelSplitter(that: this, numberOfOutputs: numberOfOutputs);\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource()=>RustLib.instance.api.webAudioApiContextAudioContextCreateConstantSource(that: this, );\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver()=>RustLib.instance.api.webAudioApiContextAudioContextCreateConvolver(that: this, );\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime })=>RustLib.instance.api.webAudioApiContextAudioContextCreateDelay(that: this, maxDelayTime: maxDelayTime);\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor()=>RustLib.instance.api.webAudioApiContextAudioContextCreateDynamicsCompressor(that: this, );\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain()=>RustLib.instance.api.webAudioApiContextAudioContextCreateGain(that: this, );\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback })=>RustLib.instance.api.webAudioApiContextAudioContextCreateIirFilter(that: this, feedforward: feedforward, feedback: feedback);\n\n\n/// Creates a [`MediaStreamAudioDestinationNode`](node::MediaStreamAudioDestinationNode)\n Future<MediaStreamAudioDestinationNode>  createMediaStreamDestination()=>RustLib.instance.api.webAudioApiContextAudioContextCreateMediaStreamDestination(that: this, );\n\n\n/// Creates a [`MediaStreamAudioSourceNode`](node::MediaStreamAudioSourceNode) from a\n/// [`MediaStream`]\n Future<MediaStreamAudioSourceNode>  createMediaStreamSource({required MediaStream media })=>RustLib.instance.api.webAudioApiContextAudioContextCreateMediaStreamSource(that: this, media: media);\n\n\n/// Creates a [`MediaStreamTrackAudioSourceNode`](node::MediaStreamTrackAudioSourceNode) from a\n/// [`MediaStreamTrack`]\n Future<MediaStreamTrackAudioSourceNode>  createMediaStreamTrackSource({required MediaStreamTrack media })=>RustLib.instance.api.webAudioApiContextAudioContextCreateMediaStreamTrackSource(that: this, media: media);\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator()=>RustLib.instance.api.webAudioApiContextAudioContextCreateOscillator(that: this, );\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner()=>RustLib.instance.api.webAudioApiContextAudioContextCreatePanner(that: this, );\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options })=>RustLib.instance.api.webAudioApiContextAudioContextCreatePeriodicWave(that: this, options: options);\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels })=>RustLib.instance.api.webAudioApiContextAudioContextCreateScriptProcessor(that: this, bufferSize: bufferSize, numberOfInputChannels: numberOfInputChannels, numberOfOutputChannels: numberOfOutputChannels);\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner()=>RustLib.instance.api.webAudioApiContextAudioContextCreateStereoPanner(that: this, );\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper()=>RustLib.instance.api.webAudioApiContextAudioContextCreateWaveShaper(that: this, );\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime()=>RustLib.instance.api.webAudioApiContextAudioContextCurrentTime(that: this, );\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination()=>RustLib.instance.api.webAudioApiContextAudioContextDestination(that: this, );\n\n\n Future<MediaElementAudioSourceNode>  createMediaElementSource({required MyMediaElement mediaElement })=>RustLib.instance.api.webAudioApiContextAudioContextFrbOverrideCreateMediaElementSource(that: this, mediaElement: mediaElement);\n\n\n Future<AudioBuffer>  decodeAudioDataSync({required String inputPath })=>RustLib.instance.api.webAudioApiContextAudioContextFrbOverrideDecodeAudioDataSync(that: this, inputPath: inputPath);\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener()=>RustLib.instance.api.webAudioApiContextAudioContextListener(that: this, );\n\n\n/// The estimation in seconds of audio output latency, i.e., the interval\n/// between the time the UA requests the host system to play a buffer and\n/// the time at which the first sample in the buffer is actually processed\n/// by the audio output device.\n Future<double>  outputLatency()=>RustLib.instance.api.webAudioApiContextAudioContextOutputLatency(that: this, );\n\n\n/// Returns an [`AudioRenderCapacity`] instance associated with an AudioContext.\n Future<AudioRenderCapacity>  renderCapacity()=>RustLib.instance.api.webAudioApiContextAudioContextRenderCapacity(that: this, );\n\n\n/// Resumes the progression of time in an audio context that has previously been\n/// suspended/paused.\n///\n/// This function operates synchronously and blocks the current thread until the audio thread\n/// has started processing again.\n///\n/// # Panics\n///\n/// Will panic if:\n///\n/// * The audio device is not available\n/// * For a `BackendSpecificError`\n Future<void>  resumeSync()=>RustLib.instance.api.webAudioApiContextAudioContextResumeSync(that: this, );\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate()=>RustLib.instance.api.webAudioApiContextAudioContextSampleRate(that: this, );\n\n\n Future<void>  setOnStateChange({required FutureOr<void> Function(Event) callback })=>RustLib.instance.api.webAudioApiContextAudioContextSetOnStateChange(that: this, callback: callback);\n\n\n Future<void>  setSinkId({required String sinkId })=>RustLib.instance.api.webAudioApiContextAudioContextSetSinkId(that: this, sinkId: sinkId);\n\n\n/// Identifier or the information of the current audio output device.\n///\n/// The initial value is `\"\"`, which means the default audio output device.\n Future<String>  sinkId()=>RustLib.instance.api.webAudioApiContextAudioContextSinkId(that: this, );\n\n\n/// Returns state of current context\n Future<AudioContextState>  state()=>RustLib.instance.api.webAudioApiContextAudioContextState(that: this, );\n\n\n/// Suspends the progression of time in the audio context.\n///\n/// This will temporarily halt audio hardware access and reducing CPU/battery usage in the\n/// process.\n///\n/// # Panics\n///\n/// Will panic if:\n///\n/// * The audio device is not available\n/// * For a `BackendSpecificError`\n Future<void>  suspend()=>RustLib.instance.api.webAudioApiContextAudioContextSuspend(that: this, );\n\n\n/// Suspends the progression of time in the audio context.\n///\n/// This will temporarily halt audio hardware access and reducing CPU/battery usage in the\n/// process.\n///\n/// This function operates synchronously and blocks the current thread until the audio thread\n/// has stopped processing.\n///\n/// # Panics\n///\n/// Will panic if:\n///\n/// * The audio device is not available\n/// * For a `BackendSpecificError`\n Future<void>  suspendSync()=>RustLib.instance.api.webAudioApiContextAudioContextSuspendSync(that: this, );\n\n\n            }",
        "\n            @sealed class AudioContextRegistrationImpl extends RustOpaque implements AudioContextRegistration {\n                // Not to be used by end users\n                AudioContextRegistrationImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioContextRegistrationImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioContextRegistration,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioContextRegistration,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioContextRegistrationPtr,\n                );\n\n                \n            }",
        "\n            @sealed class AudioParamIdImpl extends RustOpaque implements AudioParamId {\n                // Not to be used by end users\n                AudioParamIdImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioParamIdImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioParamId,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioParamId,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioParamIdPtr,\n                );\n\n                \n            }",
        "\n            @sealed class ConcreteBaseAudioContextImpl extends RustOpaque implements ConcreteBaseAudioContext {\n                // Not to be used by end users\n                ConcreteBaseAudioContextImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ConcreteBaseAudioContextImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ConcreteBaseAudioContext,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ConcreteBaseAudioContext,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ConcreteBaseAudioContextPtr,\n                );\n\n                /// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextClearOnstatechange(that: this, );\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateAnalyser(that: this, );\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateAudioParam(that: this, opts: opts, dest: dest);\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateBiquadFilter(that: this, );\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateBuffer(that: this, numberOfChannels: numberOfChannels, length: length, sampleRate: sampleRate);\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateBufferSource(that: this, );\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateChannelMerger(that: this, numberOfInputs: numberOfInputs);\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateChannelSplitter(that: this, numberOfOutputs: numberOfOutputs);\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateConstantSource(that: this, );\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateConvolver(that: this, );\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateDelay(that: this, maxDelayTime: maxDelayTime);\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateDynamicsCompressor(that: this, );\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateGain(that: this, );\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateIirFilter(that: this, feedforward: feedforward, feedback: feedback);\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateOscillator(that: this, );\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreatePanner(that: this, );\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreatePeriodicWave(that: this, options: options);\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateScriptProcessor(that: this, bufferSize: bufferSize, numberOfInputChannels: numberOfInputChannels, numberOfOutputChannels: numberOfOutputChannels);\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateStereoPanner(that: this, );\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCreateWaveShaper(that: this, );\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextCurrentTime(that: this, );\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextDestination(that: this, );\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextListener(that: this, );\n\n\n/// Inform render thread that this node can act as a cycle breaker\n Future<void>  markCycleBreaker({required AudioContextRegistration reg })=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextMarkCycleBreaker(that: this, reg: reg);\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextSampleRate(that: this, );\n\n\n/// Returns state of current context\n Future<AudioContextState>  state()=>RustLib.instance.api.webAudioApiContextConcreteBaseAudioContextState(that: this, );\n\n\n            }",
        "\n            @sealed class OfflineAudioContextImpl extends RustOpaque implements OfflineAudioContext {\n                // Not to be used by end users\n                OfflineAudioContextImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                OfflineAudioContextImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_OfflineAudioContext,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_OfflineAudioContext,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_OfflineAudioContextPtr,\n                );\n\n                /// Unset the callback to run when the rendering has completed\n Future<void>  clearOncomplete()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextClearOncomplete(that: this, );\n\n\n/// Unset the callback to run when the state of the AudioContext has changed\n Future<void>  clearOnstatechange()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextClearOnstatechange(that: this, );\n\n\n/// Creates a `AnalyserNode`\n Future<AnalyserNode>  createAnalyser()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateAnalyser(that: this, );\n\n\n/// Create an `AudioParam`.\n///\n/// Call this inside the `register` closure when setting up your `AudioNode`\n Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateAudioParam(that: this, opts: opts, dest: dest);\n\n\n/// Creates an `BiquadFilterNode` which implements a second order filter\n Future<BiquadFilterNode>  createBiquadFilter()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateBiquadFilter(that: this, );\n\n\n/// Create an new \"in-memory\" `AudioBuffer` with the given number of channels,\n/// length (i.e. number of samples per channel) and sample rate.\n///\n/// Note: In most cases you will want the sample rate to match the current\n/// audio context sample rate.\n Future<AudioBuffer>  createBuffer({required int numberOfChannels , required int length , required double sampleRate })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateBuffer(that: this, numberOfChannels: numberOfChannels, length: length, sampleRate: sampleRate);\n\n\n/// Creates an `AudioBufferSourceNode`\n Future<AudioBufferSourceNode>  createBufferSource()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateBufferSource(that: this, );\n\n\n/// Creates a `ChannelMergerNode`\n Future<ChannelMergerNode>  createChannelMerger({required int numberOfInputs })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateChannelMerger(that: this, numberOfInputs: numberOfInputs);\n\n\n/// Creates a `ChannelSplitterNode`\n Future<ChannelSplitterNode>  createChannelSplitter({required int numberOfOutputs })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateChannelSplitter(that: this, numberOfOutputs: numberOfOutputs);\n\n\n/// Creates an `ConstantSourceNode`, a source representing a constant value\n Future<ConstantSourceNode>  createConstantSource()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateConstantSource(that: this, );\n\n\n/// Creates an `ConvolverNode`, a processing node which applies linear convolution\n Future<ConvolverNode>  createConvolver()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateConvolver(that: this, );\n\n\n/// Creates a `DelayNode`, delaying the audio signal\n Future<DelayNode>  createDelay({required double maxDelayTime })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateDelay(that: this, maxDelayTime: maxDelayTime);\n\n\n/// Creates a `DynamicsCompressorNode`, compressing the audio signal\n Future<DynamicsCompressorNode>  createDynamicsCompressor()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateDynamicsCompressor(that: this, );\n\n\n/// Creates an `GainNode`, to control audio volume\n Future<GainNode>  createGain()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateGain(that: this, );\n\n\n/// Creates an `IirFilterNode`\n///\n/// # Arguments\n///\n/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.\n/// The maximum length of this array is 20\n Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateIirFilter(that: this, feedforward: feedforward, feedback: feedback);\n\n\n/// Creates an `OscillatorNode`, a source representing a periodic waveform.\n Future<OscillatorNode>  createOscillator()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateOscillator(that: this, );\n\n\n/// Creates a `PannerNode`\n Future<PannerNode>  createPanner()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreatePanner(that: this, );\n\n\n/// Creates a periodic wave\n///\n/// Please note that this constructor deviates slightly from the spec by requiring a single\n/// argument with the periodic wave options.\n Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreatePeriodicWave(that: this, options: options);\n\n\n/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);\n///\n/// # Panics\n///\n/// This function panics if:\n/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384\n/// - the number of input and output channels are both zero\n/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]\n Future<ScriptProcessorNode>  createScriptProcessor({required int bufferSize , required int numberOfInputChannels , required int numberOfOutputChannels })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateScriptProcessor(that: this, bufferSize: bufferSize, numberOfInputChannels: numberOfInputChannels, numberOfOutputChannels: numberOfOutputChannels);\n\n\n/// Creates an `StereoPannerNode` to pan a stereo output\n Future<StereoPannerNode>  createStereoPanner()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateStereoPanner(that: this, );\n\n\n/// Creates a `WaveShaperNode`\n Future<WaveShaperNode>  createWaveShaper()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCreateWaveShaper(that: this, );\n\n\n/// This is the time in seconds of the sample frame immediately following the last sample-frame\n/// in the block of audio most recently processed by the context’s rendering graph.\n Future<double>  currentTime()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextCurrentTime(that: this, );\n\n\n/// Returns an `AudioDestinationNode` representing the final destination of all audio in the\n/// context. It can be thought of as the audio-rendering device.\n Future<AudioDestinationNode>  destination()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextDestination(that: this, );\n\n\n/// get the length of rendering audio buffer\n Future<int>  length()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextLength(that: this, );\n\n\n/// Returns the `AudioListener` which is used for 3D spatialization\n Future<AudioListener>  listener()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextListener(that: this, );\n\n\n/// Resumes the progression of the OfflineAudioContext's currentTime when it has been suspended\n///\n/// # Panics\n///\n/// Panics when the context is closed or rendering has not started\n Future<void>  resume()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextResume(that: this, );\n\n\n/// The sample rate (in sample-frames per second) at which the `AudioContext` handles audio.\n Future<double>  sampleRate()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextSampleRate(that: this, );\n\n\n Future<void>  setOnComplete({required FutureOr<void> Function(OfflineAudioCompletionEvent) callback })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextSetOnComplete(that: this, callback: callback);\n\n\n/// Given the current connections and scheduled changes, starts rendering audio.\n///\n/// Rendering is purely CPU bound and contains no `await` points, so calling this method will\n/// block the executor until completion or until the context is suspended.\n///\n/// This method will only adhere to scheduled suspensions via [`Self::suspend`] and will\n/// ignore those provided via [`Self::suspend_sync`].\n///\n/// # Panics\n///\n/// Panics if this method is called multiple times.\n Future<AudioBuffer>  startRendering()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextStartRendering(that: this, );\n\n\n/// Given the current connections and scheduled changes, starts rendering audio.\n///\n/// This function will block the current thread and returns the rendered `AudioBuffer`\n/// synchronously.\n///\n/// This method will only adhere to scheduled suspensions via [`Self::suspend_sync`] and\n/// will ignore those provided via [`Self::suspend`].\n///\n/// # Panics\n///\n/// Panics if this method is called multiple times\n Future<AudioBuffer>  startRenderingSync()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextStartRenderingSync(that: this, );\n\n\n/// Returns state of current context\n Future<AudioContextState>  state()=>RustLib.instance.api.webAudioApiContextOfflineAudioContextState(that: this, );\n\n\n/// Schedules a suspension of the time progression in the audio context at the specified time\n/// and returns a promise\n///\n/// The specified time is quantized and rounded up to the render quantum size.\n///\n/// # Panics\n///\n/// Panics if the quantized frame number\n///\n/// - is negative or\n/// - is less than or equal to the current time or\n/// - is greater than or equal to the total render duration or\n/// - is scheduled by another suspend for the same time\n///\n/// # Example usage\n///\n/// ```rust\n/// use futures::{executor, join};\n/// use futures::FutureExt as _;\n/// use std::sync::Arc;\n///\n/// use web_audio_api::context::BaseAudioContext;\n/// use web_audio_api::context::OfflineAudioContext;\n/// use web_audio_api::node::{AudioNode, AudioScheduledSourceNode};\n///\n/// let context = Arc::new(OfflineAudioContext::new(1, 512, 44_100.));\n/// let context_clone = Arc::clone(&context);\n///\n/// let suspend_promise = context.suspend(128. / 44_100.).then(|_| async move {\n///     let mut src = context_clone.create_constant_source();\n///     src.connect(&context_clone.destination());\n///     src.start();\n///     context_clone.resume().await;\n/// });\n///\n/// let render_promise = context.start_rendering();\n///\n/// let buffer = executor::block_on(async move { join!(suspend_promise, render_promise).1 });\n/// assert_eq!(buffer.number_of_channels(), 1);\n/// assert_eq!(buffer.length(), 512);\n/// ```\n Future<void>  suspend({required double suspendTime })=>RustLib.instance.api.webAudioApiContextOfflineAudioContextSuspend(that: this, suspendTime: suspendTime);\n\n\n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../../api/media_element.dart';\nimport 'media_streams.dart';\nimport 'media_streams.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'media_streams.dart';\nimport 'node.dart';\nimport '../../api/media_element.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport 'node.dart';\nimport '../web_audio_api.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api::context/AudioNodeId",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::context/assert_receiver_is_total_eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/assert_receiver_is_total_eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/base",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::context/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/clone",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/decode_audio_data_sync",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::context/decode_audio_data_sync",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::context/decode_audio_data_sync",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::context/drop",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/eq",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/from",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/from",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/hash",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::context/set_onstatechange",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::context/set_onstatechange",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::context/set_onstatechange",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::context/set_onstatechange",
          "reason": "IgnoreBecauseFunctionGeneric"
        }
      ],
      "needs_freezed": true
    },
    "web_audio_api::node": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AnalyserNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AnalyserNode>>\n                abstract class AnalyserNode implements RustOpaqueInterface, AnalyserNodeExt, AudioNode {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n/// The size of the FFT used for frequency-domain analysis (in sample-frames)\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<int>  fftSize();\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// Number of bins in the FFT results, is half the FFT size\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<int>  frequencyBinCount();\n\n\n/// Maximum power value in the scaling range for the FFT analysis data for\n/// conversion to unsigned byte values. The default value is -30.\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<double>  maxDecibels();\n\n\n/// Minimum power value in the scaling range for the FFT analysis data for\n/// conversion to unsigned byte values. The default value is -100.\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<double>  minDecibels();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n/// Set FFT size\n///\n/// # Panics\n///\n/// This function panics if fft_size is not a power of two or not in the range [32, 32768]\n Future<void>  setFftSize({required int fftSize });\n\n\n/// Set max decibels\n///\n/// # Panics\n///\n/// This function panics if the value is set to a value less than or equal\n/// to min decibels.\n Future<void>  setMaxDecibels({required double value });\n\n\n/// Set min decibels\n///\n/// # Panics\n///\n/// This function panics if the value is set to a value more than or equal\n/// to max decibels.\n Future<void>  setMinDecibels({required double value });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n/// Set smoothing time constant\n///\n/// # Panics\n///\n/// This function panics if the value is set to a value less than 0 or more than 1.\n Future<void>  setSmoothingTimeConstant({required double value });\n\n\n/// Time averaging parameter with the last analysis frame.\n/// A value from 0 -> 1 where 0 represents no time averaging with the last\n/// analysis frame. The default value is 0.8.\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<double>  smoothingTimeConstant();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AudioBufferSourceNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioBufferSourceNode>>\n                abstract class AudioBufferSourceNode implements RustOpaqueInterface, AudioBufferSourceNodeExt, AudioBufferSourceNodeScheduledSourceNodeMiscExt, AudioNode, AudioScheduledSourceNode {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// K-rate [`AudioParam`] that defines a pitch transposition of the file,\n/// expressed in cents\n///\n/// see <https://en.wikipedia.org/wiki/Cent_(music)>\n AudioParam get detune;\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// Defines if the playback the [`AudioBuffer`] should be looped\n Future<bool>  loop();\n\n\n/// Defines the loop end point, in the time reference of the [`AudioBuffer`]\n Future<double>  loopEnd();\n\n\n/// Defines the loop start point, in the time reference of the [`AudioBuffer`]\n Future<double>  loopStart();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n/// K-rate [`AudioParam`] that defines the speed at which the [`AudioBuffer`]\n/// will be played, e.g.:\n/// - `0.5` will play the file at half speed\n/// - `-1` will play the file in reverse\n///\n/// Note that playback rate will also alter the pitch of the [`AudioBuffer`]\n AudioParam get playbackRate;\n\n\n/// Current playhead position in seconds within the [`AudioBuffer`].\n///\n/// This value is updated at the end of each render quantum.\n///\n/// Unofficial v2 API extension, not part of the spec yet.\n/// See also: <https://github.com/WebAudio/web-audio-api/issues/2397#issuecomment-709478405>\n Future<double>  position();\n\n\n Future<void>  registration();\n\n\n/// Provide an [`AudioBuffer`] as the source of data to be played bask\n///\n/// # Panics\n///\n/// Panics if a buffer has already been given to the source (though `new` or through\n/// `set_buffer`)\n Future<void>  setBuffer({required AudioBuffer audioBuffer });\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setLoop({required bool value });\n\n\n Future<void>  setLoopEnd({required double value });\n\n\n Future<void>  setLoopStart({required double value });\n\n\n Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n Future<void>  start();\n\n\n Future<void>  startAt({required double when });\n\n\n/// Start the playback at the given time and with a given offset\n///\n/// # Panics\n///\n/// Panics if the source was already started\n Future<void>  startAtWithOffset({required double start , required double offset });\n\n\n/// Start the playback at the given time, with a given offset, for a given duration\n///\n/// # Panics\n///\n/// Panics if the source was already started\n Future<void>  startAtWithOffsetAndDuration({required double start , required double offset , required double duration });\n\n\n Future<void>  stop();\n\n\n Future<void>  stopAt({required double when });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AudioDestinationNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioDestinationNode>>\n                abstract class AudioDestinationNode implements RustOpaqueInterface, AudioDestinationNodeExt, AudioNode {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// The maximum number of channels that the channelCount attribute can be set to (the max\n/// number of channels that the hardware is capable of supporting).\n/// <https://www.w3.org/TR/webaudio/#dom-audiodestinationnode-maxchannelcount>\n Future<int>  maxChannelCount();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n Future<void>  setChannelCount({required int v });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "BiquadFilterNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<BiquadFilterNode>>\n                abstract class BiquadFilterNode implements RustOpaqueInterface, AudioNode, BiquadFilterNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Returns the detune audio parameter\n AudioParam get detune;\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// Returns the frequency audio parameter\n AudioParam get frequency;\n\n\n/// Returns the gain audio parameter\n AudioParam get gain;\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n/// Returns the Q audio parameter\n AudioParam get q;\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n/// biquad filter type setter\n///\n/// # Arguments\n///\n/// * `type_` - the biquad filter type (lowpass, highpass,...)\n Future<void>  setType({required BiquadFilterType type });\n\n\n/// Returns the biquad filter type\n Future<BiquadFilterType>  type();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelConfig",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ChannelConfig>>\n                abstract class ChannelConfig implements RustOpaqueInterface {\n                    static Future<ChannelConfig>  default_()=>RustLib.instance.api.webAudioApiNodeChannelConfigDefault();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelMergerNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ChannelMergerNode>>\n                abstract class ChannelMergerNode implements RustOpaqueInterface, AudioNode, ChannelMergerNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n Future<void>  setChannelCount({required int count });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelSplitterNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ChannelSplitterNode>>\n                abstract class ChannelSplitterNode implements RustOpaqueInterface, AudioNode, ChannelSplitterNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n Future<void>  setChannelCount({required int count });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode });\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation interpretation });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ConstantSourceNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ConstantSourceNode>>\n                abstract class ConstantSourceNode implements RustOpaqueInterface, AudioNode, AudioScheduledSourceNode, ConstantSourceNodeExt, ConstantSourceNodeScheduledSourceNodeMiscExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n AudioParam get offset;\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n Future<void>  start();\n\n\n Future<void>  startAt({required double when });\n\n\n Future<void>  stop();\n\n\n Future<void>  stopAt({required double when });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ConvolverNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ConvolverNode>>\n                abstract class ConvolverNode implements RustOpaqueInterface, AudioNode, ConvolverNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// Denotes if the response buffer will be scaled with an equal-power normalization\n Future<bool>  normalize();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Set or update the impulse response buffer\n///\n/// # Panics\n///\n/// Panics when the sample rate of the provided AudioBuffer differs from the audio context\n/// sample rate.\n Future<void>  setBuffer({required AudioBuffer buffer });\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n/// Update the `normalize` setting. This will only have an effect when `set_buffer` is called.\n Future<void>  setNormalize({required bool value });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "DelayNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<DelayNode>>\n                abstract class DelayNode implements RustOpaqueInterface, AudioNode, DelayNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// A-rate [`AudioParam`] representing the amount of delay (in seconds) to apply.\n AudioParam get delayTime;\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "DynamicsCompressorNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<DynamicsCompressorNode>>\n                abstract class DynamicsCompressorNode implements RustOpaqueInterface, AudioNode, DynamicsCompressorNodeExt {\n                     AudioParam get attack;\n\n\n Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n AudioParam get knee;\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n AudioParam get ratio;\n\n\n Future<double>  reduction();\n\n\n Future<void>  registration();\n\n\n AudioParam get release;\n\n\n Future<void>  setChannelCount({required int count });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n AudioParam get threshold;\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "GainNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<GainNode>>\n                abstract class GainNode implements RustOpaqueInterface, AudioNode, GainNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n AudioParam get gain;\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "IirFilterNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<IIRFilterNode>>\n                abstract class IirFilterNode implements RustOpaqueInterface, AudioNode, IIRFilterNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "MediaElementAudioSourceNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaElementAudioSourceNode>>\n                abstract class MediaElementAudioSourceNode implements RustOpaqueInterface, AudioNode, MediaElementAudioSourceNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport 'media_streams.dart';\nimport 'media_streams.dart';\nimport 'media_streams.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "MediaStreamAudioDestinationNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamAudioDestinationNode>>\n                abstract class MediaStreamAudioDestinationNode implements RustOpaqueInterface, AudioNode, MediaStreamAudioDestinationNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n/// A [`MediaStream`] producing audio buffers with the same number of channels as the node\n/// itself\n Future<MediaStream>  stream();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "MediaStreamAudioSourceNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamAudioSourceNode>>\n                abstract class MediaStreamAudioSourceNode implements RustOpaqueInterface, AudioNode, MediaStreamAudioSourceNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "MediaStreamTrackAudioSourceNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaStreamTrackAudioSourceNode>>\n                abstract class MediaStreamTrackAudioSourceNode implements RustOpaqueInterface, AudioNode, MediaStreamTrackAudioSourceNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "OscillatorNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<OscillatorNode>>\n                abstract class OscillatorNode implements RustOpaqueInterface, AudioNode, AudioScheduledSourceNode, OscillatorNodeExt, OscillatorNodeScheduledSourceNodeMiscExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// A-rate [`AudioParam`] that defines a transposition according to the\n/// frequency, expressed in cents.\n///\n/// see <https://en.wikipedia.org/wiki/Cent_(music)>\n///\n/// The final frequency is calculated as follow: frequency * 2^(detune/1200)\n AudioParam get detune;\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n/// A-rate [`AudioParam`] that defines the fundamental frequency of the\n/// oscillator, expressed in Hz\n///\n/// The final frequency is calculated as follow: frequency * 2^(detune/1200)\n AudioParam get frequency;\n\n\n/// `OscillatorNode` is a source node. A source node is by definition with no input\n Future<int>  numberOfInputs();\n\n\n/// `OscillatorNode` is a mono source node.\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n/// Sets a `PeriodicWave` which describes a waveform to be used by the oscillator.\n///\n/// Calling this sets the oscillator type to `custom`, once set to `custom`\n/// the oscillator cannot be reverted back to a standard waveform.\n Future<void>  setPeriodicWave({required PeriodicWave periodicWave });\n\n\n/// Set the oscillator type\n///\n/// # Arguments\n///\n/// * `type_` - oscillator type (sine, square, triangle, sawtooth)\n///\n/// # Panics\n///\n/// if `type_` is `OscillatorType::Custom`\n Future<void>  setType({required OscillatorType type });\n\n\n Future<void>  start();\n\n\n Future<void>  startAt({required double when });\n\n\n Future<void>  stop();\n\n\n Future<void>  stopAt({required double when });\n\n\n/// Returns the oscillator type\n Future<OscillatorType>  type();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "PannerNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<PannerNode>>\n                abstract class PannerNode implements RustOpaqueInterface, AudioNode, PannerNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n Future<double>  coneInnerAngle();\n\n\n Future<double>  coneOuterAngle();\n\n\n Future<double>  coneOuterGain();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<DistanceModelType>  distanceModel();\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<double>  maxDistance();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n AudioParam get orientationX;\n\n\n AudioParam get orientationY;\n\n\n AudioParam get orientationZ;\n\n\n Future<PanningModelType>  panningModel();\n\n\n AudioParam get positionX;\n\n\n AudioParam get positionY;\n\n\n AudioParam get positionZ;\n\n\n Future<double>  refDistance();\n\n\n Future<void>  registration();\n\n\n Future<double>  rolloffFactor();\n\n\n Future<void>  setChannelCount({required int count });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setConeInnerAngle({required double value });\n\n\n Future<void>  setConeOuterAngle({required double value });\n\n\n/// Set the coneOuterGain attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is not in the range [0, 1]\n Future<void>  setConeOuterGain({required double value });\n\n\n Future<void>  setDistanceModel({required DistanceModelType value });\n\n\n/// Set the maxDistance attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is negative.\n Future<void>  setMaxDistance({required double value });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n Future<void>  setOrientation({required double x , required double y , required double z });\n\n\n Future<void>  setPanningModel({required PanningModelType value });\n\n\n Future<void>  setPosition({required double x , required double y , required double z });\n\n\n/// Set the refDistance attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is negative.\n Future<void>  setRefDistance({required double value });\n\n\n/// Set the rolloffFactor attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is negative.\n Future<void>  setRolloffFactor({required double value });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ScriptProcessorNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<ScriptProcessorNode>>\n                abstract class ScriptProcessorNode implements RustOpaqueInterface, AudioNode, ScriptProcessorNodeExt {\n                     Future<int>  bufferSize();\n\n\n Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when the AudioProcessingEvent is dispatched\n Future<void>  clearOnaudioprocess();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n Future<void>  registration();\n\n\n Future<void>  setChannelCount({required int count });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "StereoPannerNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<StereoPannerNode>>\n                abstract class StereoPannerNode implements RustOpaqueInterface, AudioNode, StereoPannerNodeExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n/// Returns the pan audio parameter\n AudioParam get pan;\n\n\n Future<void>  registration();\n\n\n Future<void>  setChannelCount({required int count });\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../../frb_generated.dart';\nimport '../../api/override_web_audio_api.dart';\nimport '../../api/override_web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "WaveShaperNode",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<WaveShaperNode>>\n                abstract class WaveShaperNode implements RustOpaqueInterface, AudioNode, WaveShaperNodeExt, WaveShaperNodeMiscExt {\n                     Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n Future<void>  connect({required AudioNode dest });\n\n\n Future<Float32List?>  curve();\n\n\n Future<int>  numberOfInputs();\n\n\n Future<int>  numberOfOutputs();\n\n\n/// Returns the `oversample` faactor of this node\n Future<OverSampleType>  oversample();\n\n\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n/// Set the distortion `curve` of this node\n///\n/// # Arguments\n///\n/// * `curve` - the desired distortion `curve`\n///\n/// # Panics\n///\n/// Panics if a curve has already been given to the source (though `new` or through\n/// `set_curve`)\n Future<void>  setCurve({required List<double> curve });\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback });\n\n\n/// set the `oversample` factor of this node\n///\n/// # Arguments\n///\n/// * `oversample` - the desired `OversampleType` variant\n Future<void>  setOversample({required OverSampleType oversample });\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AudioNode",
          "code": "\n                abstract class AudioNode {\n                    /// Config for up/down-mixing of input channels for this node.\n///\n/// Only when implementing the [`AudioNode`] trait manually, this struct is of any concern.\n Future<void>  channelConfig();\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount();\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode();\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation();\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror();\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect();\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output });\n\n\n/// The number of inputs feeding into the AudioNode. For source nodes, this will be 0.\n Future<int>  numberOfInputs();\n\n\n/// The number of outputs coming out of the AudioNode.\n Future<int>  numberOfOutputs();\n\n\n/// Handle of the associated [`BaseAudioContext`](crate::context::BaseAudioContext).\n///\n/// Only when implementing the AudioNode trait manually, this struct is of any concern.\n Future<void>  registration();\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v });\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v });\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AudioScheduledSourceNode",
          "code": "\n                abstract class AudioScheduledSourceNode {\n                    /// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended();\n\n\n/// Play immediately\n///\n/// # Panics\n///\n/// Panics if the source was already started\n Future<void>  start();\n\n\n/// Schedule playback start at given timestamp\n///\n/// # Panics\n///\n/// Panics if the source was already started\n Future<void>  startAt({required double when });\n\n\n/// Stop immediately\n///\n/// # Panics\n///\n/// Panics if the source was already stopped\n Future<void>  stop();\n\n\n/// Schedule playback stop at given timestamp\n///\n/// # Panics\n///\n/// Panics if the source was already stopped\n Future<void>  stopAt({required double when });\n\n\n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AnalyserOptions",
          "code": "/// Options for constructing an [`AnalyserNode`]\nclass AnalyserOptions  {\n                final int fftSize;\nfinal double maxDecibels;\nfinal double minDecibels;\nfinal double smoothingTimeConstant;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const AnalyserOptions({required this.fftSize ,required this.maxDecibels ,required this.minDecibels ,required this.smoothingTimeConstant ,required this.audioNodeOptions ,});\n\n                static Future<AnalyserOptions>  default_()=>RustLib.instance.api.webAudioApiNodeAnalyserOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => fftSize.hashCode^maxDecibels.hashCode^minDecibels.hashCode^smoothingTimeConstant.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AnalyserOptions &&\n                runtimeType == other.runtimeType\n                && fftSize == other.fftSize&& maxDecibels == other.maxDecibels&& minDecibels == other.minDecibels&& smoothingTimeConstant == other.smoothingTimeConstant&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AudioBufferSourceOptions",
          "code": "/// Options for constructing an [`AudioBufferSourceNode`]\nclass AudioBufferSourceOptions  {\n                final AudioBuffer? buffer;\nfinal double detune;\nfinal bool loop;\nfinal double loopStart;\nfinal double loopEnd;\nfinal double playbackRate;\n\n                const AudioBufferSourceOptions({this.buffer ,required this.detune ,required this.loop ,required this.loopStart ,required this.loopEnd ,required this.playbackRate ,});\n\n                static Future<AudioBufferSourceOptions>  default_()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => buffer.hashCode^detune.hashCode^loop.hashCode^loopStart.hashCode^loopEnd.hashCode^playbackRate.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AudioBufferSourceOptions &&\n                runtimeType == other.runtimeType\n                && buffer == other.buffer&& detune == other.detune&& loop == other.loop&& loopStart == other.loopStart&& loopEnd == other.loopEnd&& playbackRate == other.playbackRate;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "AudioNodeOptions",
          "code": "/// Options that can be used in constructing all AudioNodes.\nclass AudioNodeOptions  {\n                /// Desired number of channels for the [`AudioNode::channel_count`] attribute.\nfinal int channelCount;\n/// Desired mode for the [`AudioNode::channel_count_mode`] attribute.\nfinal ChannelCountMode channelCountMode;\n/// Desired mode for the [`AudioNode::channel_interpretation`] attribute.\nfinal ChannelInterpretation channelInterpretation;\n\n                const AudioNodeOptions({required this.channelCount ,required this.channelCountMode ,required this.channelInterpretation ,});\n\n                static Future<AudioNodeOptions>  default_()=>RustLib.instance.api.webAudioApiNodeAudioNodeOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => channelCount.hashCode^channelCountMode.hashCode^channelInterpretation.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is AudioNodeOptions &&\n                runtimeType == other.runtimeType\n                && channelCount == other.channelCount&& channelCountMode == other.channelCountMode&& channelInterpretation == other.channelInterpretation;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "BiquadFilterOptions",
          "code": "/// Options for constructing a [`BiquadFilterNode`]\nclass BiquadFilterOptions  {\n                final double q;\nfinal double detune;\nfinal double frequency;\nfinal double gain;\nfinal BiquadFilterType type;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const BiquadFilterOptions({required this.q ,required this.detune ,required this.frequency ,required this.gain ,required this.type ,required this.audioNodeOptions ,});\n\n                static Future<BiquadFilterOptions>  default_()=>RustLib.instance.api.webAudioApiNodeBiquadFilterOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => q.hashCode^detune.hashCode^frequency.hashCode^gain.hashCode^type.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is BiquadFilterOptions &&\n                runtimeType == other.runtimeType\n                && q == other.q&& detune == other.detune&& frequency == other.frequency&& gain == other.gain&& type == other.type&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "BiquadFilterType",
          "code": "/// Biquad filter types\nenum BiquadFilterType {\n                    /// Allows frequencies below the cutoff frequency to pass through and\n/// attenuates frequencies above the cutoff. (12dB/oct rolloff)\nlowpass,\n/// Frequencies above the cutoff frequency are passed through, but\n/// frequencies below the cutoff are attenuated. (12dB/oct rolloff)\nhighpass,\n/// Allows a range of frequencies to pass through and attenuates the\n/// frequencies below and above this frequency range.\nbandpass,\n/// Allows all frequencies through, except for a set of frequencies.\nnotch,\n/// Allows all frequencies through, but changes the phase relationship\n/// between the various frequencies.\nallpass,\n/// Allows all frequencies through, but adds a boost (or attenuation) to\n/// a range of frequencies.\npeaking,\n/// Allows all frequencies through, but adds a boost (or attenuation) to\n/// the lower frequencies.\nlowshelf,\n/// Allows all frequencies through, but adds a boost (or attenuation) to\n/// the higher frequencies.\nhighshelf,\n                    ;\n                    static Future<BiquadFilterType>  default_()=>RustLib.instance.api.webAudioApiNodeBiquadFilterTypeDefault();\n\n\n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelCountMode",
          "code": "/// How channels must be matched between the node's inputs and outputs.\nenum ChannelCountMode {\n                    /// `computedNumberOfChannels` is the maximum of the number of channels of all connections to an\n/// input. In this mode channelCount is ignored.\nmax,\n/// `computedNumberOfChannels` is determined as for \"max\" and then clamped to a maximum value of\n/// the given channelCount.\nclampedMax,\n/// `computedNumberOfChannels` is the exact value as specified by the channelCount.\nexplicit,\n                    ;\n                    \n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelInterpretation",
          "code": "/// The meaning of the channels, defining how audio up-mixing and down-mixing will happen.\nenum ChannelInterpretation {\n                    speakers,\ndiscrete,\n                    ;\n                    \n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelMergerOptions",
          "code": "/// Options for constructing a [`ChannelMergerNode`]\nclass ChannelMergerOptions  {\n                final int numberOfInputs;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const ChannelMergerOptions({required this.numberOfInputs ,required this.audioNodeOptions ,});\n\n                static Future<ChannelMergerOptions>  default_()=>RustLib.instance.api.webAudioApiNodeChannelMergerOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => numberOfInputs.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is ChannelMergerOptions &&\n                runtimeType == other.runtimeType\n                && numberOfInputs == other.numberOfInputs&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ChannelSplitterOptions",
          "code": "/// Options for constructing a [`ChannelSplitterNode`]\nclass ChannelSplitterOptions  {\n                final int numberOfOutputs;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const ChannelSplitterOptions({required this.numberOfOutputs ,required this.audioNodeOptions ,});\n\n                static Future<ChannelSplitterOptions>  default_()=>RustLib.instance.api.webAudioApiNodeChannelSplitterOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => numberOfOutputs.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is ChannelSplitterOptions &&\n                runtimeType == other.runtimeType\n                && numberOfOutputs == other.numberOfOutputs&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ConstantSourceOptions",
          "code": "/// Options for constructing an [`ConstantSourceNode`]\nclass ConstantSourceOptions  {\n                /// Initial parameter value of the constant signal\nfinal double offset;\n\n                const ConstantSourceOptions({required this.offset ,});\n\n                static Future<ConstantSourceOptions>  default_()=>RustLib.instance.api.webAudioApiNodeConstantSourceOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => offset.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is ConstantSourceOptions &&\n                runtimeType == other.runtimeType\n                && offset == other.offset;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "ConvolverOptions",
          "code": "/// `ConvolverNode` options\nclass ConvolverOptions  {\n                /// The desired buffer for the ConvolverNode\nfinal AudioBuffer? buffer;\n/// The opposite of the desired initial value for the normalize attribute\nfinal bool disableNormalization;\n/// AudioNode options\nfinal AudioNodeOptions audioNodeOptions;\n\n                const ConvolverOptions({this.buffer ,required this.disableNormalization ,required this.audioNodeOptions ,});\n\n                static Future<ConvolverOptions>  default_()=>RustLib.instance.api.webAudioApiNodeConvolverOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => buffer.hashCode^disableNormalization.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is ConvolverOptions &&\n                runtimeType == other.runtimeType\n                && buffer == other.buffer&& disableNormalization == other.disableNormalization&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "DelayOptions",
          "code": "/// Options for constructing a [`DelayNode`]\nclass DelayOptions  {\n                final double maxDelayTime;\nfinal double delayTime;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const DelayOptions({required this.maxDelayTime ,required this.delayTime ,required this.audioNodeOptions ,});\n\n                static Future<DelayOptions>  default_()=>RustLib.instance.api.webAudioApiNodeDelayOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => maxDelayTime.hashCode^delayTime.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is DelayOptions &&\n                runtimeType == other.runtimeType\n                && maxDelayTime == other.maxDelayTime&& delayTime == other.delayTime&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "DistanceModelType",
          "code": "/// Algorithm to reduce the volume of an audio source as it moves away from the listener\nenum DistanceModelType {\n                    linear,\ninverse,\nexponential,\n                    ;\n                    static Future<DistanceModelType>  default_()=>RustLib.instance.api.webAudioApiNodeDistanceModelTypeDefault();\n\n\n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "DynamicsCompressorOptions",
          "code": "/// Options for constructing a [`DynamicsCompressorNode`]\nclass DynamicsCompressorOptions  {\n                final double attack;\nfinal double knee;\nfinal double ratio;\nfinal double release;\nfinal double threshold;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const DynamicsCompressorOptions({required this.attack ,required this.knee ,required this.ratio ,required this.release ,required this.threshold ,required this.audioNodeOptions ,});\n\n                static Future<DynamicsCompressorOptions>  default_()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => attack.hashCode^knee.hashCode^ratio.hashCode^release.hashCode^threshold.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is DynamicsCompressorOptions &&\n                runtimeType == other.runtimeType\n                && attack == other.attack&& knee == other.knee&& ratio == other.ratio&& release == other.release&& threshold == other.threshold&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "GainOptions",
          "code": "/// Options for constructing a [`GainNode`]\nclass GainOptions  {\n                final double gain;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const GainOptions({required this.gain ,required this.audioNodeOptions ,});\n\n                static Future<GainOptions>  default_()=>RustLib.instance.api.webAudioApiNodeGainOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => gain.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is GainOptions &&\n                runtimeType == other.runtimeType\n                && gain == other.gain&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "OscillatorOptions",
          "code": "/// Options for constructing an [`OscillatorNode`]\nclass OscillatorOptions  {\n                /// The shape of the periodic waveform\nfinal OscillatorType type;\n/// The frequency of the fundamental frequency.\nfinal double frequency;\n/// A detuning value (in cents) which will offset the frequency by the given amount.\nfinal double detune;\n/// Optional custom waveform, if specified (set `type` to \"custom\")\nfinal PeriodicWave? periodicWave;\n/// channel config options\nfinal AudioNodeOptions audioNodeOptions;\n\n                const OscillatorOptions({required this.type ,required this.frequency ,required this.detune ,this.periodicWave ,required this.audioNodeOptions ,});\n\n                static Future<OscillatorOptions>  default_()=>RustLib.instance.api.webAudioApiNodeOscillatorOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => type.hashCode^frequency.hashCode^detune.hashCode^periodicWave.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is OscillatorOptions &&\n                runtimeType == other.runtimeType\n                && type == other.type&& frequency == other.frequency&& detune == other.detune&& periodicWave == other.periodicWave&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "OscillatorType",
          "code": "/// Type of the waveform rendered by an `OscillatorNode`\nenum OscillatorType {\n                    /// Sine wave\nsine,\n/// Square wave\nsquare,\n/// Sawtooth wave\nsawtooth,\n/// Triangle wave\ntriangle,\n/// type used when periodic_wave is specified\ncustom,\n                    ;\n                    static Future<OscillatorType>  default_()=>RustLib.instance.api.webAudioApiNodeOscillatorTypeDefault();\n\n\n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "OverSampleType",
          "code": "/// enumerates the oversampling rate available for `WaveShaperNode`\nenum OverSampleType {\n                    /// No oversampling is applied\nnone,\n/// Oversampled by a factor of 2\nx2,\n/// Oversampled by a factor of 4\nx4,\n                    ;\n                    static Future<OverSampleType>  default_()=>RustLib.instance.api.webAudioApiNodeOverSampleTypeDefault();\n\n\n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "PannerOptions",
          "code": "/// Options for constructing a [`PannerNode`]\nclass PannerOptions  {\n                final PanningModelType panningModel;\nfinal DistanceModelType distanceModel;\nfinal double positionX;\nfinal double positionY;\nfinal double positionZ;\nfinal double orientationX;\nfinal double orientationY;\nfinal double orientationZ;\nfinal double refDistance;\nfinal double maxDistance;\nfinal double rolloffFactor;\nfinal double coneInnerAngle;\nfinal double coneOuterAngle;\nfinal double coneOuterGain;\nfinal AudioNodeOptions audioNodeOptions;\n\n                const PannerOptions({required this.panningModel ,required this.distanceModel ,required this.positionX ,required this.positionY ,required this.positionZ ,required this.orientationX ,required this.orientationY ,required this.orientationZ ,required this.refDistance ,required this.maxDistance ,required this.rolloffFactor ,required this.coneInnerAngle ,required this.coneOuterAngle ,required this.coneOuterGain ,required this.audioNodeOptions ,});\n\n                static Future<PannerOptions>  default_()=>RustLib.instance.api.webAudioApiNodePannerOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => panningModel.hashCode^distanceModel.hashCode^positionX.hashCode^positionY.hashCode^positionZ.hashCode^orientationX.hashCode^orientationY.hashCode^orientationZ.hashCode^refDistance.hashCode^maxDistance.hashCode^rolloffFactor.hashCode^coneInnerAngle.hashCode^coneOuterAngle.hashCode^coneOuterGain.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is PannerOptions &&\n                runtimeType == other.runtimeType\n                && panningModel == other.panningModel&& distanceModel == other.distanceModel&& positionX == other.positionX&& positionY == other.positionY&& positionZ == other.positionZ&& orientationX == other.orientationX&& orientationY == other.orientationY&& orientationZ == other.orientationZ&& refDistance == other.refDistance&& maxDistance == other.maxDistance&& rolloffFactor == other.rolloffFactor&& coneInnerAngle == other.coneInnerAngle&& coneOuterAngle == other.coneOuterAngle&& coneOuterGain == other.coneOuterGain&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "PanningModelType",
          "code": "/// Spatialization algorithm used to position the audio in 3D space\nenum PanningModelType {\n                    equalPower,\nhrtf,\n                    ;\n                    static Future<PanningModelType>  default_()=>RustLib.instance.api.webAudioApiNodePanningModelTypeDefault();\n\n\n                }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "StereoPannerOptions",
          "code": "/// Options for constructing a [`StereoPannerOptions`]\nclass StereoPannerOptions  {\n                /// initial value for the pan parameter\nfinal double pan;\n/// audio node options\nfinal AudioNodeOptions audioNodeOptions;\n\n                const StereoPannerOptions({required this.pan ,required this.audioNodeOptions ,});\n\n                static Future<StereoPannerOptions>  default_()=>RustLib.instance.api.webAudioApiNodeStereoPannerOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => pan.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is StereoPannerOptions &&\n                runtimeType == other.runtimeType\n                && pan == other.pan&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "namespace": "web_audio_api::node",
          "class_name": "WaveShaperOptions",
          "code": "/// `WaveShaperNode` options\nclass WaveShaperOptions  {\n                /// The distortion curve\nfinal Float32List? curve;\n/// Oversampling rate - default to `None`\nfinal OverSampleType oversample;\n/// audio node options\nfinal AudioNodeOptions audioNodeOptions;\n\n                const WaveShaperOptions({this.curve ,required this.oversample ,required this.audioNodeOptions ,});\n\n                static Future<WaveShaperOptions>  default_()=>RustLib.instance.api.webAudioApiNodeWaveShaperOptionsDefault();\n\n\n                \n\n                \n        @override\n        int get hashCode => curve.hashCode^oversample.hashCode^audioNodeOptions.hashCode;\n        \n\n                \n        @override\n        bool operator ==(Object other) =>\n            identical(this, other) ||\n            other is WaveShaperOptions &&\n                runtimeType == other.runtimeType\n                && curve == other.curve&& oversample == other.oversample&& audioNodeOptions == other.audioNodeOptions;\n        \n            }",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "\n            @sealed class AnalyserNodeImpl extends RustOpaque implements AnalyserNode {\n                // Not to be used by end users\n                AnalyserNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AnalyserNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AnalyserNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AnalyserNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AnalyserNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeDisconnectOutput(that: this, output: output);\n\n\n/// The size of the FFT used for frequency-domain analysis (in sample-frames)\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<int>  fftSize()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeFftSize(that: this, );\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Number of bins in the FFT results, is half the FFT size\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<int>  frequencyBinCount()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeFrequencyBinCount(that: this, );\n\n\n/// Maximum power value in the scaling range for the FFT analysis data for\n/// conversion to unsigned byte values. The default value is -30.\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<double>  maxDecibels()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeMaxDecibels(that: this, );\n\n\n/// Minimum power value in the scaling range for the FFT analysis data for\n/// conversion to unsigned byte values. The default value is -100.\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<double>  minDecibels()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeMinDecibels(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetChannelInterpretation(that: this, v: v);\n\n\n/// Set FFT size\n///\n/// # Panics\n///\n/// This function panics if fft_size is not a power of two or not in the range [32, 32768]\n Future<void>  setFftSize({required int fftSize })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetFftSize(that: this, fftSize: fftSize);\n\n\n/// Set max decibels\n///\n/// # Panics\n///\n/// This function panics if the value is set to a value less than or equal\n/// to min decibels.\n Future<void>  setMaxDecibels({required double value })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetMaxDecibels(that: this, value: value);\n\n\n/// Set min decibels\n///\n/// # Panics\n///\n/// This function panics if the value is set to a value more than or equal\n/// to max decibels.\n Future<void>  setMinDecibels({required double value })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetMinDecibels(that: this, value: value);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetOnProcessorError(that: this, callback: callback);\n\n\n/// Set smoothing time constant\n///\n/// # Panics\n///\n/// This function panics if the value is set to a value less than 0 or more than 1.\n Future<void>  setSmoothingTimeConstant({required double value })=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSetSmoothingTimeConstant(that: this, value: value);\n\n\n/// Time averaging parameter with the last analysis frame.\n/// A value from 0 -> 1 where 0 represents no time averaging with the last\n/// analysis frame. The default value is 0.8.\n///\n/// # Panics\n///\n/// This method may panic if the lock to the inner analyser is poisoned\n Future<double>  smoothingTimeConstant()=>RustLib.instance.api.webAudioApiNodeAnalyserNodeSmoothingTimeConstant(that: this, );\n\n\n            }",
        "\n            @sealed class AudioBufferSourceNodeImpl extends RustOpaque implements AudioBufferSourceNode {\n                // Not to be used by end users\n                AudioBufferSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioBufferSourceNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioBufferSourceNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioBufferSourceNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioBufferSourceNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeClearOnended(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeClearOnprocessorerror(that: this, );\n\n\n/// K-rate [`AudioParam`] that defines a pitch transposition of the file,\n/// expressed in cents\n///\n/// see <https://en.wikipedia.org/wiki/Cent_(music)>\n AudioParam get detune=>AudioParamProxyVariantAudioBufferSourceNodeDetune(this);\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Defines if the playback the [`AudioBuffer`] should be looped\n Future<bool>  loop()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoop(that: this, );\n\n\n/// Defines the loop end point, in the time reference of the [`AudioBuffer`]\n Future<double>  loopEnd()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoopEnd(that: this, );\n\n\n/// Defines the loop start point, in the time reference of the [`AudioBuffer`]\n Future<double>  loopStart()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeLoopStart(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeNumberOfOutputs(that: this, );\n\n\n/// K-rate [`AudioParam`] that defines the speed at which the [`AudioBuffer`]\n/// will be played, e.g.:\n/// - `0.5` will play the file at half speed\n/// - `-1` will play the file in reverse\n///\n/// Note that playback rate will also alter the pitch of the [`AudioBuffer`]\n AudioParam get playbackRate=>AudioParamProxyVariantAudioBufferSourceNodePlaybackRate(this);\n\n\n/// Current playhead position in seconds within the [`AudioBuffer`].\n///\n/// This value is updated at the end of each render quantum.\n///\n/// Unofficial v2 API extension, not part of the spec yet.\n/// See also: <https://github.com/WebAudio/web-audio-api/issues/2397#issuecomment-709478405>\n Future<double>  position()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodePosition(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeRegistration(that: this, );\n\n\n/// Provide an [`AudioBuffer`] as the source of data to be played bask\n///\n/// # Panics\n///\n/// Panics if a buffer has already been given to the source (though `new` or through\n/// `set_buffer`)\n Future<void>  setBuffer({required AudioBuffer audioBuffer })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetBuffer(that: this, audioBuffer: audioBuffer);\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setLoop({required bool value })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetLoop(that: this, value: value);\n\n\n Future<void>  setLoopEnd({required double value })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetLoopEnd(that: this, value: value);\n\n\n Future<void>  setLoopStart({required double value })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetLoopStart(that: this, value: value);\n\n\n Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetOnEnded(that: this, callback: callback);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeSetOnProcessorError(that: this, callback: callback);\n\n\n Future<void>  start()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStart(that: this, );\n\n\n Future<void>  startAt({required double when })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStartAt(that: this, when: when);\n\n\n/// Start the playback at the given time and with a given offset\n///\n/// # Panics\n///\n/// Panics if the source was already started\n Future<void>  startAtWithOffset({required double start , required double offset })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStartAtWithOffset(that: this, start: start, offset: offset);\n\n\n/// Start the playback at the given time, with a given offset, for a given duration\n///\n/// # Panics\n///\n/// Panics if the source was already started\n Future<void>  startAtWithOffsetAndDuration({required double start , required double offset , required double duration })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStartAtWithOffsetAndDuration(that: this, start: start, offset: offset, duration: duration);\n\n\n Future<void>  stop()=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStop(that: this, );\n\n\n Future<void>  stopAt({required double when })=>RustLib.instance.api.webAudioApiNodeAudioBufferSourceNodeStopAt(that: this, when: when);\n\n\n            }",
        "\n            @sealed class AudioDestinationNodeImpl extends RustOpaque implements AudioDestinationNode {\n                // Not to be used by end users\n                AudioDestinationNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                AudioDestinationNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_AudioDestinationNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_AudioDestinationNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_AudioDestinationNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n/// The maximum number of channels that the channelCount attribute can be set to (the max\n/// number of channels that the hardware is capable of supporting).\n/// <https://www.w3.org/TR/webaudio/#dom-audiodestinationnode-maxchannelcount>\n Future<int>  maxChannelCount()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeMaxChannelCount(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeRegistration(that: this, );\n\n\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeSetChannelCount(that: this, v: v);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeAudioDestinationNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class BiquadFilterNodeImpl extends RustOpaque implements BiquadFilterNode {\n                // Not to be used by end users\n                BiquadFilterNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                BiquadFilterNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_BiquadFilterNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_BiquadFilterNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_BiquadFilterNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeClearOnprocessorerror(that: this, );\n\n\n/// Returns the detune audio parameter\n AudioParam get detune=>AudioParamProxyVariantBiquadFilterNodeDetune(this);\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Returns the frequency audio parameter\n AudioParam get frequency=>AudioParamProxyVariantBiquadFilterNodeFrequency(this);\n\n\n/// Returns the gain audio parameter\n AudioParam get gain=>AudioParamProxyVariantBiquadFilterNodeGain(this);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeNumberOfOutputs(that: this, );\n\n\n/// Returns the Q audio parameter\n AudioParam get q=>AudioParamProxyVariantBiquadFilterNodeQ(this);\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeSetOnProcessorError(that: this, callback: callback);\n\n\n/// biquad filter type setter\n///\n/// # Arguments\n///\n/// * `type_` - the biquad filter type (lowpass, highpass,...)\n Future<void>  setType({required BiquadFilterType type })=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeSetType(that: this, type: type);\n\n\n/// Returns the biquad filter type\n Future<BiquadFilterType>  type()=>RustLib.instance.api.webAudioApiNodeBiquadFilterNodeType(that: this, );\n\n\n            }",
        "\n            @sealed class ChannelConfigImpl extends RustOpaque implements ChannelConfig {\n                // Not to be used by end users\n                ChannelConfigImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ChannelConfigImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ChannelConfig,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ChannelConfig,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ChannelConfigPtr,\n                );\n\n                \n            }",
        "\n            @sealed class ChannelMergerNodeImpl extends RustOpaque implements ChannelMergerNode {\n                // Not to be used by end users\n                ChannelMergerNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ChannelMergerNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ChannelMergerNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ChannelMergerNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ChannelMergerNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeRegistration(that: this, );\n\n\n Future<void>  setChannelCount({required int count })=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeSetChannelCount(that: this, count: count);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode })=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeSetChannelCountMode(that: this, mode: mode);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeChannelMergerNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class ChannelSplitterNodeImpl extends RustOpaque implements ChannelSplitterNode {\n                // Not to be used by end users\n                ChannelSplitterNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ChannelSplitterNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ChannelSplitterNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ChannelSplitterNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ChannelSplitterNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeRegistration(that: this, );\n\n\n Future<void>  setChannelCount({required int count })=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeSetChannelCount(that: this, count: count);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode })=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeSetChannelCountMode(that: this, mode: mode);\n\n\n Future<void>  setChannelInterpretation({required ChannelInterpretation interpretation })=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeSetChannelInterpretation(that: this, interpretation: interpretation);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeChannelSplitterNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class ConstantSourceNodeImpl extends RustOpaque implements ConstantSourceNode {\n                // Not to be used by end users\n                ConstantSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ConstantSourceNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ConstantSourceNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ConstantSourceNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ConstantSourceNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeClearOnended(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeNumberOfOutputs(that: this, );\n\n\n AudioParam get offset=>AudioParamProxyVariantConstantSourceNodeOffset(this);\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetOnEnded(that: this, callback: callback);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeSetOnProcessorError(that: this, callback: callback);\n\n\n Future<void>  start()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeStart(that: this, );\n\n\n Future<void>  startAt({required double when })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeStartAt(that: this, when: when);\n\n\n Future<void>  stop()=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeStop(that: this, );\n\n\n Future<void>  stopAt({required double when })=>RustLib.instance.api.webAudioApiNodeConstantSourceNodeStopAt(that: this, when: when);\n\n\n            }",
        "\n            @sealed class ConvolverNodeImpl extends RustOpaque implements ConvolverNode {\n                // Not to be used by end users\n                ConvolverNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ConvolverNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ConvolverNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ConvolverNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ConvolverNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeConvolverNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeConvolverNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeConvolverNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeConvolverNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeConvolverNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeConvolverNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeConvolverNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeConvolverNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n/// Denotes if the response buffer will be scaled with an equal-power normalization\n Future<bool>  normalize()=>RustLib.instance.api.webAudioApiNodeConvolverNodeNormalize(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeConvolverNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeConvolverNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeConvolverNodeRegistration(that: this, );\n\n\n/// Set or update the impulse response buffer\n///\n/// # Panics\n///\n/// Panics when the sample rate of the provided AudioBuffer differs from the audio context\n/// sample rate.\n Future<void>  setBuffer({required AudioBuffer buffer })=>RustLib.instance.api.webAudioApiNodeConvolverNodeSetBuffer(that: this, buffer: buffer);\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeConvolverNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeConvolverNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeConvolverNodeSetChannelInterpretation(that: this, v: v);\n\n\n/// Update the `normalize` setting. This will only have an effect when `set_buffer` is called.\n Future<void>  setNormalize({required bool value })=>RustLib.instance.api.webAudioApiNodeConvolverNodeSetNormalize(that: this, value: value);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeConvolverNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class DelayNodeImpl extends RustOpaque implements DelayNode {\n                // Not to be used by end users\n                DelayNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                DelayNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_DelayNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_DelayNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_DelayNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeDelayNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeDelayNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeDelayNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeDelayNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeDelayNodeClearOnprocessorerror(that: this, );\n\n\n/// A-rate [`AudioParam`] representing the amount of delay (in seconds) to apply.\n AudioParam get delayTime=>AudioParamProxyVariantDelayNodeDelayTime(this);\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeDelayNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeDelayNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeDelayNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeDelayNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeDelayNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeDelayNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeDelayNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeDelayNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeDelayNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeDelayNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class DynamicsCompressorNodeImpl extends RustOpaque implements DynamicsCompressorNode {\n                // Not to be used by end users\n                DynamicsCompressorNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                DynamicsCompressorNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_DynamicsCompressorNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_DynamicsCompressorNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_DynamicsCompressorNodePtr,\n                );\n\n                 AudioParam get attack=>AudioParamProxyVariantDynamicsCompressorNodeAttack(this);\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n AudioParam get knee=>AudioParamProxyVariantDynamicsCompressorNodeKnee(this);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeNumberOfOutputs(that: this, );\n\n\n AudioParam get ratio=>AudioParamProxyVariantDynamicsCompressorNodeRatio(this);\n\n\n Future<double>  reduction()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeReduction(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeRegistration(that: this, );\n\n\n AudioParam get release=>AudioParamProxyVariantDynamicsCompressorNodeRelease(this);\n\n\n Future<void>  setChannelCount({required int count })=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeSetChannelCount(that: this, count: count);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode })=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeSetChannelCountMode(that: this, mode: mode);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeDynamicsCompressorNodeSetOnProcessorError(that: this, callback: callback);\n\n\n AudioParam get threshold=>AudioParamProxyVariantDynamicsCompressorNodeThreshold(this);\n\n\n            }",
        "\n            @sealed class GainNodeImpl extends RustOpaque implements GainNode {\n                // Not to be used by end users\n                GainNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                GainNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_GainNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_GainNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_GainNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeGainNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeGainNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeGainNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeGainNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeGainNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeGainNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeGainNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeGainNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n AudioParam get gain=>AudioParamProxyVariantGainNodeGain(this);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeGainNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeGainNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeGainNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeGainNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeGainNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeGainNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeGainNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class IirFilterNodeImpl extends RustOpaque implements IirFilterNode {\n                // Not to be used by end users\n                IirFilterNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                IirFilterNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_IirFilterNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_IirFilterNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_IirFilterNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeIirFilterNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeIirFilterNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeIirFilterNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeIirFilterNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeIirFilterNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeIirFilterNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeIirFilterNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class MediaElementAudioSourceNodeImpl extends RustOpaque implements MediaElementAudioSourceNode {\n                // Not to be used by end users\n                MediaElementAudioSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaElementAudioSourceNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaElementAudioSourceNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaElementAudioSourceNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaElementAudioSourceNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeMediaElementAudioSourceNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class MediaStreamAudioDestinationNodeImpl extends RustOpaque implements MediaStreamAudioDestinationNode {\n                // Not to be used by end users\n                MediaStreamAudioDestinationNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaStreamAudioDestinationNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaStreamAudioDestinationNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamAudioDestinationNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamAudioDestinationNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioDestinationNodeSetOnProcessorError(that: this, callback: callback);\n\n\n/// A [`MediaStream`] producing audio buffers with the same number of channels as the node\n/// itself\n Future<MediaStream>  stream()=>Future.value(MediaStreamProxyVariantMediaStreamAudioDestinationNodeStream(this));\n\n\n            }",
        "\n            @sealed class MediaStreamAudioSourceNodeImpl extends RustOpaque implements MediaStreamAudioSourceNode {\n                // Not to be used by end users\n                MediaStreamAudioSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaStreamAudioSourceNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaStreamAudioSourceNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamAudioSourceNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamAudioSourceNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeMediaStreamAudioSourceNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class MediaStreamTrackAudioSourceNodeImpl extends RustOpaque implements MediaStreamTrackAudioSourceNode {\n                // Not to be used by end users\n                MediaStreamTrackAudioSourceNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaStreamTrackAudioSourceNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaStreamTrackAudioSourceNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaStreamTrackAudioSourceNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeMediaStreamTrackAudioSourceNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class OscillatorNodeImpl extends RustOpaque implements OscillatorNode {\n                // Not to be used by end users\n                OscillatorNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                OscillatorNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_OscillatorNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_OscillatorNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_OscillatorNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when the source node has stopped playing\n Future<void>  clearOnended()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeClearOnended(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeClearOnprocessorerror(that: this, );\n\n\n/// A-rate [`AudioParam`] that defines a transposition according to the\n/// frequency, expressed in cents.\n///\n/// see <https://en.wikipedia.org/wiki/Cent_(music)>\n///\n/// The final frequency is calculated as follow: frequency * 2^(detune/1200)\n AudioParam get detune=>AudioParamProxyVariantOscillatorNodeDetune(this);\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n/// A-rate [`AudioParam`] that defines the fundamental frequency of the\n/// oscillator, expressed in Hz\n///\n/// The final frequency is calculated as follow: frequency * 2^(detune/1200)\n AudioParam get frequency=>AudioParamProxyVariantOscillatorNodeFrequency(this);\n\n\n/// `OscillatorNode` is a source node. A source node is by definition with no input\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeNumberOfInputs(that: this, );\n\n\n/// `OscillatorNode` is a mono source node.\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnEnded({required FutureOr<void> Function(Event) callback })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetOnEnded(that: this, callback: callback);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetOnProcessorError(that: this, callback: callback);\n\n\n/// Sets a `PeriodicWave` which describes a waveform to be used by the oscillator.\n///\n/// Calling this sets the oscillator type to `custom`, once set to `custom`\n/// the oscillator cannot be reverted back to a standard waveform.\n Future<void>  setPeriodicWave({required PeriodicWave periodicWave })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetPeriodicWave(that: this, periodicWave: periodicWave);\n\n\n/// Set the oscillator type\n///\n/// # Arguments\n///\n/// * `type_` - oscillator type (sine, square, triangle, sawtooth)\n///\n/// # Panics\n///\n/// if `type_` is `OscillatorType::Custom`\n Future<void>  setType({required OscillatorType type })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeSetType(that: this, type: type);\n\n\n Future<void>  start()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeStart(that: this, );\n\n\n Future<void>  startAt({required double when })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeStartAt(that: this, when: when);\n\n\n Future<void>  stop()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeStop(that: this, );\n\n\n Future<void>  stopAt({required double when })=>RustLib.instance.api.webAudioApiNodeOscillatorNodeStopAt(that: this, when: when);\n\n\n/// Returns the oscillator type\n Future<OscillatorType>  type()=>RustLib.instance.api.webAudioApiNodeOscillatorNodeType(that: this, );\n\n\n            }",
        "\n            @sealed class PannerNodeImpl extends RustOpaque implements PannerNode {\n                // Not to be used by end users\n                PannerNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                PannerNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_PannerNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_PannerNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_PannerNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodePannerNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodePannerNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodePannerNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodePannerNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodePannerNodeClearOnprocessorerror(that: this, );\n\n\n Future<double>  coneInnerAngle()=>RustLib.instance.api.webAudioApiNodePannerNodeConeInnerAngle(that: this, );\n\n\n Future<double>  coneOuterAngle()=>RustLib.instance.api.webAudioApiNodePannerNodeConeOuterAngle(that: this, );\n\n\n Future<double>  coneOuterGain()=>RustLib.instance.api.webAudioApiNodePannerNodeConeOuterGain(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodePannerNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodePannerNodeDisconnectOutput(that: this, output: output);\n\n\n Future<DistanceModelType>  distanceModel()=>RustLib.instance.api.webAudioApiNodePannerNodeDistanceModel(that: this, );\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodePannerNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<double>  maxDistance()=>RustLib.instance.api.webAudioApiNodePannerNodeMaxDistance(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodePannerNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodePannerNodeNumberOfOutputs(that: this, );\n\n\n AudioParam get orientationX=>AudioParamProxyVariantPannerNodeOrientationX(this);\n\n\n AudioParam get orientationY=>AudioParamProxyVariantPannerNodeOrientationY(this);\n\n\n AudioParam get orientationZ=>AudioParamProxyVariantPannerNodeOrientationZ(this);\n\n\n Future<PanningModelType>  panningModel()=>RustLib.instance.api.webAudioApiNodePannerNodePanningModel(that: this, );\n\n\n AudioParam get positionX=>AudioParamProxyVariantPannerNodePositionX(this);\n\n\n AudioParam get positionY=>AudioParamProxyVariantPannerNodePositionY(this);\n\n\n AudioParam get positionZ=>AudioParamProxyVariantPannerNodePositionZ(this);\n\n\n Future<double>  refDistance()=>RustLib.instance.api.webAudioApiNodePannerNodeRefDistance(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodePannerNodeRegistration(that: this, );\n\n\n Future<double>  rolloffFactor()=>RustLib.instance.api.webAudioApiNodePannerNodeRolloffFactor(that: this, );\n\n\n Future<void>  setChannelCount({required int count })=>RustLib.instance.api.webAudioApiNodePannerNodeSetChannelCount(that: this, count: count);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode })=>RustLib.instance.api.webAudioApiNodePannerNodeSetChannelCountMode(that: this, mode: mode);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodePannerNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setConeInnerAngle({required double value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetConeInnerAngle(that: this, value: value);\n\n\n Future<void>  setConeOuterAngle({required double value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetConeOuterAngle(that: this, value: value);\n\n\n/// Set the coneOuterGain attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is not in the range [0, 1]\n Future<void>  setConeOuterGain({required double value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetConeOuterGain(that: this, value: value);\n\n\n Future<void>  setDistanceModel({required DistanceModelType value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetDistanceModel(that: this, value: value);\n\n\n/// Set the maxDistance attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is negative.\n Future<void>  setMaxDistance({required double value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetMaxDistance(that: this, value: value);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodePannerNodeSetOnProcessorError(that: this, callback: callback);\n\n\n Future<void>  setOrientation({required double x , required double y , required double z })=>RustLib.instance.api.webAudioApiNodePannerNodeSetOrientation(that: this, x: x, y: y, z: z);\n\n\n Future<void>  setPanningModel({required PanningModelType value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetPanningModel(that: this, value: value);\n\n\n Future<void>  setPosition({required double x , required double y , required double z })=>RustLib.instance.api.webAudioApiNodePannerNodeSetPosition(that: this, x: x, y: y, z: z);\n\n\n/// Set the refDistance attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is negative.\n Future<void>  setRefDistance({required double value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetRefDistance(that: this, value: value);\n\n\n/// Set the rolloffFactor attribute\n///\n/// # Panics\n///\n/// Panics if the provided value is negative.\n Future<void>  setRolloffFactor({required double value })=>RustLib.instance.api.webAudioApiNodePannerNodeSetRolloffFactor(that: this, value: value);\n\n\n            }",
        "\n            @sealed class ScriptProcessorNodeImpl extends RustOpaque implements ScriptProcessorNode {\n                // Not to be used by end users\n                ScriptProcessorNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                ScriptProcessorNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_ScriptProcessorNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_ScriptProcessorNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_ScriptProcessorNodePtr,\n                );\n\n                 Future<int>  bufferSize()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeBufferSize(that: this, );\n\n\n Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when the AudioProcessingEvent is dispatched\n Future<void>  clearOnaudioprocess()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeClearOnaudioprocess(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeNumberOfOutputs(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeRegistration(that: this, );\n\n\n Future<void>  setChannelCount({required int count })=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeSetChannelCount(that: this, count: count);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode })=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeSetChannelCountMode(that: this, mode: mode);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeScriptProcessorNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class StereoPannerNodeImpl extends RustOpaque implements StereoPannerNode {\n                // Not to be used by end users\n                StereoPannerNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                StereoPannerNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_StereoPannerNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_StereoPannerNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_StereoPannerNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeNumberOfOutputs(that: this, );\n\n\n/// Returns the pan audio parameter\n AudioParam get pan=>AudioParamProxyVariantStereoPannerNodePan(this);\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeRegistration(that: this, );\n\n\n Future<void>  setChannelCount({required int count })=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeSetChannelCount(that: this, count: count);\n\n\n Future<void>  setChannelCountMode({required ChannelCountMode mode })=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeSetChannelCountMode(that: this, mode: mode);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeSetChannelInterpretation(that: this, v: v);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeStereoPannerNodeSetOnProcessorError(that: this, callback: callback);\n\n\n            }",
        "\n            @sealed class WaveShaperNodeImpl extends RustOpaque implements WaveShaperNode {\n                // Not to be used by end users\n                WaveShaperNodeImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                WaveShaperNodeImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_WaveShaperNode,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_WaveShaperNode,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_WaveShaperNodePtr,\n                );\n\n                 Future<void>  channelConfig()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelConfig(that: this, );\n\n\n/// Represents an integer used to determine how many channels are used when up-mixing and\n/// down-mixing connections to any inputs to the node.\n Future<int>  channelCount()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelCount(that: this, );\n\n\n/// Represents an enumerated value describing the way channels must be matched between the\n/// node's inputs and outputs.\n Future<ChannelCountMode>  channelCountMode()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelCountMode(that: this, );\n\n\n/// Represents an enumerated value describing the meaning of the channels. This interpretation\n/// will define how audio up-mixing and down-mixing will happen.\n Future<ChannelInterpretation>  channelInterpretation()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeChannelInterpretation(that: this, );\n\n\n/// Unset the callback to run when an unhandled exception occurs in the audio processor.\n Future<void>  clearOnprocessorerror()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeClearOnprocessorerror(that: this, );\n\n\n/// Disconnects all outgoing connections from the AudioNode.\n Future<void>  disconnect()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeDisconnect(that: this, );\n\n\n/// Disconnects all outgoing connections at the given output port from the AudioNode.\n///\n/// # Panics\n///\n/// This function will panic when\n/// - if the output port is out of bounds for this node\n Future<void>  disconnectOutput({required int output })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeDisconnectOutput(that: this, output: output);\n\n\n Future<void>  connect({required AudioNode dest })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeFrbOverrideConnect(that: this, dest: dest);\n\n\n Future<Float32List?>  curve()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeFrbOverrideCurve(that: this, );\n\n\n Future<int>  numberOfInputs()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeNumberOfInputs(that: this, );\n\n\n Future<int>  numberOfOutputs()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeNumberOfOutputs(that: this, );\n\n\n/// Returns the `oversample` faactor of this node\n Future<OverSampleType>  oversample()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeOversample(that: this, );\n\n\n Future<void>  registration()=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeRegistration(that: this, );\n\n\n/// Update the `channel_count` attribute\n Future<void>  setChannelCount({required int v })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetChannelCount(that: this, v: v);\n\n\n/// Update the `channel_count_mode` attribute\n Future<void>  setChannelCountMode({required ChannelCountMode v })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetChannelCountMode(that: this, v: v);\n\n\n/// Update the `channel_interpretation` attribute\n Future<void>  setChannelInterpretation({required ChannelInterpretation v })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetChannelInterpretation(that: this, v: v);\n\n\n/// Set the distortion `curve` of this node\n///\n/// # Arguments\n///\n/// * `curve` - the desired distortion `curve`\n///\n/// # Panics\n///\n/// Panics if a curve has already been given to the source (though `new` or through\n/// `set_curve`)\n Future<void>  setCurve({required List<double> curve })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetCurve(that: this, curve: curve);\n\n\n Future<void>  setOnProcessorError({required FutureOr<void> Function(String) callback })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetOnProcessorError(that: this, callback: callback);\n\n\n/// set the `oversample` factor of this node\n///\n/// # Arguments\n///\n/// * `oversample` - the desired `OversampleType` variant\n Future<void>  setOversample({required OverSampleType oversample })=>RustLib.instance.api.webAudioApiNodeWaveShaperNodeSetOversample(that: this, oversample: oversample);\n\n\n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport 'worklet.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../../frb_generated.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api::node/IIRFilterOptions",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::node/MediaElementAudioSourceOptions",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::node/MediaStreamAudioSourceOptions",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::node/MediaStreamRenderer",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::node/MediaStreamTrackAudioSourceOptions",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::node/ScriptProcessorOptions",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::node/channel_count",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/channel_count_mode",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/channel_interpretation",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/clear_onprocessorerror",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/connect",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/connect_from_output_to_input",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/context",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_dest_from_output_to_input",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/disconnect_output",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/process",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::node/set_onended",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/set_onended",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/set_onended",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/set_onended",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseNotAllowedOwner"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        },
        {
          "name": "web_audio_api::node/set_onprocessorerror",
          "reason": "IgnoreBecauseExplicitAttribute"
        }
      ],
      "needs_freezed": false
    },
    "crate::api::toto": {
      "funcs": [
        {
          "namespace": "crate::api::toto",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Future<String> toto()",
          "func_impl": "RustLib.instance.api.crateApiTotoToto()",
          "func_params": [],
          "func_return_type": "Future<String>",
          "src_lineno_pseudo": 309,
          "return_stream": null
        },
        {
          "namespace": "crate::api::toto",
          "header": {
            "file_top": "",
            "import": "",
            "part": ""
          },
          "func_comments": "",
          "func_expr": "Future<String> zozo()",
          "func_impl": "RustLib.instance.api.crateApiTotoZozo()",
          "func_params": [],
          "func_return_type": "Future<String>",
          "src_lineno_pseudo": 340,
          "return_stream": null
        }
      ],
      "classes": [],
      "extra_impl_code": [],
      "imports": {
        "file_top": "",
        "import": "",
        "part": ""
      },
      "preamble": "",
      "skips": [],
      "needs_freezed": false
    },
    "web_audio_api::media_recorder": {
      "funcs": [],
      "classes": [
        {
          "header": {
            "file_top": "",
            "import": "import '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\nimport '../web_audio_api.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::media_recorder",
          "class_name": "BlobEvent",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<BlobEvent>>\n                abstract class BlobEvent implements RustOpaqueInterface {\n                     Uint8List get blob;\n\n\n Event get event;\n\n\n double get timecode;\n\n\n  set blob(Uint8List blob);\n\n\n  set event(Event event);\n\n\n  set timecode(double timecode);\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        },
        {
          "header": {
            "file_top": "",
            "import": "import 'media_streams.dart';\nimport 'node.dart';\nimport '../../frb_generated.dart';\n",
            "part": ""
          },
          "namespace": "web_audio_api::media_recorder",
          "class_name": "MediaRecorder",
          "code": "\n                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<MediaRecorder>>\n                abstract class MediaRecorder implements RustOpaqueInterface {\n                     Future<void>  clearOndataavailable();\n\n\n Future<void>  clearOnerror();\n\n\n Future<void>  clearOnstop();\n\n\n  // HINT: Make it `#[frb(sync)]` to let it become the default constructor of Dart class.\n/// Creates a new `MediaRecorder` object, given a [`MediaStream`] to record.\n///\n/// Only supports WAV file format currently.\nstatic Future<MediaRecorder>  newInstance({required MediaStream stream })=>RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderNew(stream: stream);\n\n\n/// Begin recording media\n///\n/// # Panics\n///\n/// Will panic when the recorder has already started\n Future<void>  start();\n\n\n Future<void>  stop();\n\n\n\n                    \n                }\n                ",
          "needs_freezed": false
        }
      ],
      "extra_impl_code": [
        "\n            @sealed class BlobEventImpl extends RustOpaque implements BlobEvent {\n                // Not to be used by end users\n                BlobEventImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                BlobEventImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_BlobEvent,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_BlobEvent,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_BlobEventPtr,\n                );\n\n                 Uint8List get blob=>RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorGetBlob(that: this, );\n\n\n Event get event=>RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorGetEvent(that: this, );\n\n\n double get timecode=>RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorGetTimecode(that: this, );\n\n\n  set blob(Uint8List blob)=>RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorSetBlob(that: this, blob: blob);\n\n\n  set event(Event event)=>RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorSetEvent(that: this, event: event);\n\n\n  set timecode(double timecode)=>RustLib.instance.api.webAudioApiMediaRecorderBlobEventAutoAccessorSetTimecode(that: this, timecode: timecode);\n\n\n            }",
        "\n            @sealed class MediaRecorderImpl extends RustOpaque implements MediaRecorder {\n                // Not to be used by end users\n                MediaRecorderImpl.frbInternalDcoDecode(List<dynamic> wire):\n                    super.frbInternalDcoDecode(wire, _kStaticData);\n\n                // Not to be used by end users\n                MediaRecorderImpl.frbInternalSseDecode(BigInt ptr, int externalSizeOnNative):\n                    super.frbInternalSseDecode(ptr, externalSizeOnNative, _kStaticData);\n\n                static final _kStaticData = RustArcStaticData(\n                    rustArcIncrementStrongCount: RustLib.instance.api.rust_arc_increment_strong_count_MediaRecorder,\n                    rustArcDecrementStrongCount: RustLib.instance.api.rust_arc_decrement_strong_count_MediaRecorder,\n                    rustArcDecrementStrongCountPtr: RustLib.instance.api.rust_arc_decrement_strong_count_MediaRecorderPtr,\n                );\n\n                 Future<void>  clearOndataavailable()=>RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderClearOndataavailable(that: this, );\n\n\n Future<void>  clearOnerror()=>RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderClearOnerror(that: this, );\n\n\n Future<void>  clearOnstop()=>RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderClearOnstop(that: this, );\n\n\n/// Begin recording media\n///\n/// # Panics\n///\n/// Will panic when the recorder has already started\n Future<void>  start()=>RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderStart(that: this, );\n\n\n Future<void>  stop()=>RustLib.instance.api.webAudioApiMediaRecorderMediaRecorderStop(that: this, );\n\n\n            }"
      ],
      "imports": {
        "file_top": "",
        "import": "import '../web_audio_api.dart';\nimport 'media_streams.dart';\nimport '../web_audio_api.dart';\nimport 'node.dart';\nimport '../../frb_generated.dart';\n",
        "part": ""
      },
      "preamble": "",
      "skips": [
        {
          "name": "web_audio_api::media_recorder/MediaRecorderInner",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_recorder/RecordedData",
          "reason": "IgnoreBecauseTypeNotUsedByPub"
        },
        {
          "name": "web_audio_api::media_recorder/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_recorder/fmt",
          "reason": "IgnoreBecauseNotDefinedTrait"
        },
        {
          "name": "web_audio_api::media_recorder/set_ondataavailable",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::media_recorder/set_onerror",
          "reason": "IgnoreBecauseFunctionGeneric"
        },
        {
          "name": "web_audio_api::media_recorder/set_onstop",
          "reason": "IgnoreBecauseFunctionGeneric"
        }
      ],
      "needs_freezed": false
    }
  }
}