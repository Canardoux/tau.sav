// This file is automatically generated, so please do not edit it.
// Generated by `flutter_rust_bridge`@ 2.0.0-dev.40.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../frb_generated.dart';
import '../third_party/web_audio_api.dart';
import '../third_party/web_audio_api/context.dart';
import '../third_party/web_audio_api/context/online.dart';
import '../third_party/web_audio_api/media_streams.dart';
import '../third_party/web_audio_api/node.dart';
import 'audio_buffer.dart';
import 'media_element.dart';
import 'node/audio_buffer_source.dart';
import 'node/audio_destination_node.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';


            

            

            
                // Rust type: RustOpaqueMoi<flutter_rust_bridge::for_generated::RustAutoOpaqueInner<AudioContext>>
                abstract class AudioContext implements RustOpaqueInterface, BaseAudioContext {
                    /// Returns the [`BaseAudioContext`] concrete type associated with this `AudioContext`
 Future<void>  base();


/// This represents the number of seconds of processing latency incurred by
/// the `AudioContext` passing the audio from the `AudioDestinationNode`
/// to the audio subsystem.
 Future<double>  baseLatency();


/// Unset the callback to run when the audio sink has changed
 Future<void>  clearOnsinkchange();


/// Unset the callback to run when the state of the AudioContext has changed
 Future<void>  clearOnstatechange();


/// Closes the `AudioContext`, releasing the system resources being used.
///
/// This will not automatically release all `AudioContext`-created objects, but will suspend
/// the progression of the currentTime, and stop processing audio data.
///
/// # Panics
///
/// Will panic when this function is called multiple times
 Future<void>  close();


/// Closes the `AudioContext`, releasing the system resources being used.
///
/// This will not automatically release all `AudioContext`-created objects, but will suspend
/// the progression of the currentTime, and stop processing audio data.
///
/// This function operates synchronously and blocks the current thread until the audio thread
/// has stopped processing.
///
/// # Panics
///
/// Will panic when this function is called multiple times
 Future<void>  closeSync();


/// Creates a `AnalyserNode`
 Future<AnalyserNode>  createAnalyser();


/// Create an `AudioParam`.
///
/// Call this inside the `register` closure when setting up your `AudioNode`
 Future<(AudioParam,AudioParamId)>  createAudioParam({required AudioParamDescriptor opts , required AudioContextRegistration dest });


/// Creates an `BiquadFilterNode` which implements a second order filter
 Future<BiquadFilterNode>  createBiquadFilter();


/// Documentation of the behavior
 AudioBuffer  createBuffer({required BigInt numberOfChannels , required BigInt length , required double sampleRate });


/// Documentation of the behavior
 AudioBufferSourceNode  createBufferSource();


/// Creates a `ChannelMergerNode`
 Future<ChannelMergerNode>  createChannelMerger({required BigInt numberOfInputs });


/// Creates a `ChannelSplitterNode`
 Future<ChannelSplitterNode>  createChannelSplitter({required BigInt numberOfOutputs });


/// Creates an `ConstantSourceNode`, a source representing a constant value
 Future<ConstantSourceNode>  createConstantSource();


/// Creates an `ConvolverNode`, a processing node which applies linear convolution
 Future<ConvolverNode>  createConvolver();


/// Creates a `DelayNode`, delaying the audio signal
 Future<DelayNode>  createDelay({required double maxDelayTime });


/// Creates a `DynamicsCompressorNode`, compressing the audio signal
 Future<DynamicsCompressorNode>  createDynamicsCompressor();


/// Creates an `GainNode`, to control audio volume
 Future<GainNode>  createGain();


/// Creates an `IirFilterNode`
///
/// # Arguments
///
/// * `feedforward` - An array of the feedforward (numerator) coefficients for the transfer function of the IIR filter.
/// The maximum length of this array is 20
/// * `feedback` - An array of the feedback (denominator) coefficients for the transfer function of the IIR filter.
/// The maximum length of this array is 20
 Future<IirFilterNode>  createIirFilter({required List<double> feedforward , required List<double> feedback });


/// Creates a [`MediaElementAudioSourceNode`](node::MediaElementAudioSourceNode) from a
/// [`MediaElement`]
 Future<MediaElementAudioSourceNode>  createMediaElementSource({required MediaElement mediaElement });


/// Creates a [`MediaStreamAudioDestinationNode`](node::MediaStreamAudioDestinationNode)
 Future<MediaStreamAudioDestinationNode>  createMediaStreamDestination();


/// Creates a [`MediaStreamAudioSourceNode`](node::MediaStreamAudioSourceNode) from a
/// [`MediaStream`]
 Future<MediaStreamAudioSourceNode>  createMediaStreamSource({required MediaStream media });


/// Creates a [`MediaStreamTrackAudioSourceNode`](node::MediaStreamTrackAudioSourceNode) from a
/// [`MediaStreamTrack`]
 Future<MediaStreamTrackAudioSourceNode>  createMediaStreamTrackSource({required MediaStreamTrack media });


/// Creates an `OscillatorNode`, a source representing a periodic waveform.
 Future<OscillatorNode>  createOscillator();


/// Creates a `PannerNode`
 Future<PannerNode>  createPanner();


/// Creates a periodic wave
///
/// Please note that this constructor deviates slightly from the spec by requiring a single
/// argument with the periodic wave options.
 Future<PeriodicWave>  createPeriodicWave({required PeriodicWaveOptions options });


/// Creates an `ScriptProcessorNode` for custom audio processing (deprecated);
///
/// # Panics
///
/// This function panics if:
/// - `buffer_size` is not 256, 512, 1024, 2048, 4096, 8192, or 16384
/// - the number of input and output channels are both zero
/// - either of the channel counts exceed [`crate::MAX_CHANNELS`]
 Future<ScriptProcessorNode>  createScriptProcessor({required BigInt bufferSize , required BigInt numberOfInputChannels , required BigInt numberOfOutputChannels });


/// Creates an `StereoPannerNode` to pan a stereo output
 Future<StereoPannerNode>  createStereoPanner();


/// Creates a `WaveShaperNode`
 Future<WaveShaperNode>  createWaveShaper();


/// This is the time in seconds of the sample frame immediately following the last sample-frame
/// in the block of audio most recently processed by the contextâ€™s rendering graph.
 Future<double>  currentTime();


/// Returns an `AudioDestinationNode` representing the final destination of all audio in the
/// context. It can be thought of as the audio-rendering device.
 Future<AudioDestinationNode>  destination();


/// Returns the `AudioListener` which is used for 3D spatialization
 Future<AudioListener>  listener();


/// The constructor
/// Documentation of the behavior
factory AudioContext()=>RustLib.instance.api.crateApiAudioContextAudioContextNew();


/// The estimation in seconds of audio output latency, i.e., the interval
/// between the time the UA requests the host system to play a buffer and
/// the time at which the first sample in the buffer is actually processed
/// by the audio output device.
 Future<double>  outputLatency();


/// Returns an [`AudioRenderCapacity`] instance associated with an AudioContext.
 Future<AudioRenderCapacity>  renderCapacity();


/// Resumes the progression of time in an audio context that has previously been
/// suspended/paused.
///
/// # Panics
///
/// Will panic if:
///
/// * The audio device is not available
/// * For a `BackendSpecificError`
 Future<void>  resume();


/// Resumes the progression of time in an audio context that has previously been
/// suspended/paused.
///
/// This function operates synchronously and blocks the current thread until the audio thread
/// has started processing again.
///
/// # Panics
///
/// Will panic if:
///
/// * The audio device is not available
/// * For a `BackendSpecificError`
 Future<void>  resumeSync();


/// Documentation of the behavior
 double  sampleRate();


/// Update the current audio output device.
///
/// The provided `sink_id` string must match a device name `enumerate_devices_sync`.
///
/// Supplying `"none"` for the `sink_id` will process the audio graph without playing through an
/// audio output device.
///
/// This function operates synchronously and might block the current thread. An async version
/// is currently not implemented.
 Future<void>  setSinkIdSync({required String sinkId });


/// Identifier or the information of the current audio output device.
///
/// The initial value is `""`, which means the default audio output device.
 Future<String>  sinkId();


/// Returns state of current context
 Future<AudioContextState>  state();


/// Suspends the progression of time in the audio context.
///
/// This will temporarily halt audio hardware access and reducing CPU/battery usage in the
/// process.
///
/// # Panics
///
/// Will panic if:
///
/// * The audio device is not available
/// * For a `BackendSpecificError`
 Future<void>  suspend();


/// Suspends the progression of time in the audio context.
///
/// This will temporarily halt audio hardware access and reducing CPU/battery usage in the
/// process.
///
/// This function operates synchronously and blocks the current thread until the audio thread
/// has stopped processing.
///
/// # Panics
///
/// Will panic if:
///
/// * The audio device is not available
/// * For a `BackendSpecificError`
 Future<void>  suspendSync();



                    
                }
                
            